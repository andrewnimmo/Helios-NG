head	1.21;
access;
symbols
	Helios_1_3_1:1.21
	Helios_C40_1_3_Official_Release:1.20
	Alenia_release:1.16
	C40_Field_Test_2:1.10
	C40_Field_Test_R1:1.6;
locks; strict;
comment	@-- @;


1.21
date	93.10.04.12.12.37;	author paul;	state Exp;
branches;
next	1.20;

1.20
date	93.04.01.16.56.18;	author nick;	state Exp;
branches;
next	1.19;

1.19
date	93.01.26.18.35.02;	author paul;	state Exp;
branches;
next	1.18;

1.18
date	93.01.26.10.07.27;	author paul;	state Exp;
branches;
next	1.17;

1.17
date	93.01.25.09.06.28;	author paul;	state Exp;
branches;
next	1.16;

1.16
date	92.11.20.15.43.46;	author paul;	state Exp;
branches;
next	1.15;

1.15
date	92.11.18.14.37.00;	author paul;	state Exp;
branches;
next	1.14;

1.14
date	92.11.12.20.54.42;	author paul;	state Exp;
branches;
next	1.13;

1.13
date	92.11.12.17.17.25;	author paul;	state Exp;
branches;
next	1.12;

1.12
date	92.11.09.15.43.21;	author nickc;	state Exp;
branches;
next	1.11;

1.11
date	92.11.09.15.32.43;	author nickc;	state Exp;
branches;
next	1.10;

1.10
date	92.09.25.09.37.18;	author paul;	state Exp;
branches;
next	1.9;

1.9
date	92.09.23.17.21.54;	author paul;	state Exp;
branches;
next	1.8;

1.8
date	92.08.18.09.54.42;	author paul;	state Exp;
branches;
next	1.7;

1.7
date	92.07.30.18.30.29;	author paul;	state Exp;
branches;
next	1.6;

1.6
date	92.06.30.19.23.59;	author paul;	state Exp;
branches;
next	1.5;

1.5
date	92.06.26.17.59.02;	author paul;	state Exp;
branches;
next	1.4;

1.4
date	92.06.19.18.24.53;	author paul;	state Exp;
branches;
next	1.3;

1.3
date	92.06.16.08.47.28;	author paul;	state Exp;
branches;
next	1.2;

1.2
date	92.04.21.09.54.56;	author paul;	state Exp;
branches;
next	1.1;

1.1
date	91.12.03.11.53.02;	author paul;	state Exp;
branches;
next	;


desc
@c40 asm interrupt associated functions
@


1.21
log
@added support for max dispatch latency test
@
text
@/*
 * File:	c40intr.a
 * Subsystem:	'C40 executive
 * Author:	P.A.Beskeen
 * Date:	Nov '91
 *
 * Description: `C40 Helios executive interrupt related functions.
 *
 *
 * RcsId: $Id: c40intr.a,v 1.20 1993/04/01 16:56:18 nick Exp $
 *
 * (C) Copyright 1991 Perihelion Software Ltd.
 * 
 * RcsLog: $Log: c40intr.a,v $
-- Revision 1.20  1993/04/01  16:56:18  nick
-- Functions SetIIFBits(), ClrIIFBits() and WriteTCR added.
--
-- Revision 1.19  1993/01/26  18:35:02  paul
-- fixed assembler bug that allowed nonsense cmpi NULL, *ar2++ to be parsed.
-- Fixed assembler and changed source - how did this ever work? timesliceing
-- should have caused threads to be lost?
--
-- Revision 1.18  1993/01/26  10:07:27  paul
-- optimised time slice and reduced generic interrupt handlers dispatch
-- latency.
--
-- Revision 1.17  1993/01/25  09:06:28  paul
-- minor tidies + IR0 is now preserved
--
-- Revision 1.16  1992/11/20  15:43:46  paul
-- address base reg IR0 is now defined to be a constant, user code must
-- not change its value.
-- interrupt routines now assume that IR0 is correct
--
-- Revision 1.15  1992/11/18  14:37:00  paul
-- fixed up interrupt handlers to stop assuming IR0 is 0, instead they assume
-- GetExecRoot (tvtp) is synonymous with the std C address base
--
-- Revision 1.14  1992/11/12  20:54:42  paul
-- made C40Word/CAddress compatible with IR0 != 0
--
-- Revision 1.13  1992/11/12  17:17:25  paul
-- now used generic cpustate.m
--
-- Revision 1.12  1992/11/09  15:43:21  nickc
-- temporary fix until Paul produces new version of cpustate.h
--
-- Revision 1.11  1992/11/09  15:32:43  nickc
-- applied patch as per PB instructions
--
-- Revision 1.10  1992/09/25  09:37:18  paul
-- changed to use gexec.m
--
-- Revision 1.9  1992/09/23  17:21:54  paul
-- added NMI interrupt handler support
--
-- Revision 1.8  1992/08/18  09:54:42  paul
-- added generic interrupt handler initialisation and stub code
--
-- Revision 1.7  1992/07/30  18:30:29  paul
-- added thread timing support
--
-- Revision 1.6  1992/06/30  19:23:59  paul
-- removed debug
-- ,
--
-- Revision 1.5  1992/06/26  17:59:02  paul
-- changed from a fixed timeslice quantum to a variable one
--
-- Revision 1.4  1992/06/19  18:24:53  paul
-- removed some debugging, optimised and fixed timeslice interrupt handler
--
-- Revision 1.3  1992/06/16  08:47:28  paul
-- cleaned up code and optimised slightly
--
-- Revision 1.2  1992/04/21  09:54:56  paul
-- alpha version
--
 */


include ../gexec.m	-- Executive manifests
include c40intr.m
include c40mmap.m
include cpustate.m
include module.m


-- word IntsAreEnabled(void);
--
-- Returns TRUE if ints are enabled globally else false
--
-- Called from C so must conform to PCS

	Function IntsAreEnabled

	bud	R_LR
		ldi	ST, R_A1result
		and	ST_GIE, R_A1result
		lsh	-13, R_A1result		-- set bit result to TRUE (1)


_if _false [	-- C now uses inline opcode macros (event.h)
-- void IntsOn(void);
--
-- Enable interrupts globally
--
-- Called from C so must conform to PCS

	Function IntsOn

	bud	R_LR
		or	ST_GIE, st	-- global interrupt enable bit set
		nop
		nop

-- void IntsOff(void);
--
-- Disable interrupts globally
--
-- Called from C so must conform to PCS


	Function IntsOff

	bud	R_LR
		andn	ST_GIE, st	-- global interrupt enable bit zeroed
		nop
		nop

-- void ClockIntsOn(void);
--
-- Enable time slicer clock interrupts
--
-- Called from C so must conform to PCS

	Function ClockIntsOn

	or	IIE_ETINT0, iie		-- timer 0 enabled
	b	R_LR


-- void ClockIntsOff(void);
--
-- Disable time slicer clock interrupts
--
-- Called from C so must conform to PCS

	Function ClockIntsOff

	andn	IIE_ETINT0, iie		-- timer 0 disabled
	b	R_LR

]

-- void SetIIFBits(bits);
--
-- Set some bits in the IIF register
--
--
	Function SetIIFBits

	bud	R_LR
		or	R0,IIF
		nop
		nop


-- void ClrIIFBits(bits);
--
-- Clear some bits in the IIF register
--
--
	Function ClrIIFBits

	bud	R_LR
		andn	R0,IIF
		nop
		nop

-- int WriteTCR( int tcr )
--
--
	Function WriteTCR

	ldi	R_ADDR1,r10		-- save R_ADDR1

	ldhi	0x10,R_ADDR1		-- R_ADDR1 = 0x100000 = GMCR address
	ldi	*R_ADDR1,r1		-- r1 = old GMCR value
	ldhi	0x1dea,r2		-- r2 = 0x1dea0050 = new GMCR value
	or	0x0050,r2
	sti	r2,*R_ADDR1		-- set GMCR

	ldhi	0x8000,R_ATMP		-- put G0 address in R_ATMP
	ldi	iif,r2			-- r2 = saved IIF
	ldi	2,iif			-- iif = 2
	ldi	*R_ATMP,r3		-- r3 = old tcr

	sti	r0,*R_ATMP		-- *R_ATMP = new tcr
	nop				-- give it time to settle
	nop
	nop
	nop

	ldi	r2,iif			-- iif = original value
	sti	r1,*R_ADDR1		-- restore GMCR
	ldi	r10,R_ADDR1		-- restore R_ADDR1

	ldi	r3,r0			-- r0 = old tcr (return value)
	and	0xFF,r0			-- return only ls 8 bits

	bu	R_LR			-- and return


-- void StartTimeSlicer(void)
--
-- Starts the time slicer.
-- 
-- Initialise time slicer clock to call `SliceIntrHandler' every
-- millisecond . Once set up, the clock is reset and slicer
-- interrupts are enabled.
-- Assumes system stack pointer and interrupt vector table already initialised
--
-- Called from C so must conform to PCS


	Function StartTimeSlicer

_def	start_timer	[(tcr_io|tcr_go|tcr_hld|tcr_clksrc)]
_def	halt_timer	[(tcr_io|tcr_clksrc)]
_def	continue_timer	[(tcr_io|tcr_hld|tcr_clksrc)]

	-- Initialise clock interrupt and handler

	-- get address of time slice interrupt handler
	ldabs16 SliceIntrHandler R_TMP1

	-- Get interrupt vector table
	ldep	ivtp, R_ATMP

	-- Set interrupt vector for clock 0 to SliceIntrHandler
	sti	R_TMP1, *+R_ATMP(iv_tint0)	-- store in clk0 interrupt vect.

	-- Set up timer 0 period register
	-- e.g.	33Mhz = 60.60606060 nanosecond H1 cycle time
	--	timer resolution = H1 * 2 = 121.21212121 nanosecond units
	--	period for 1 millisecond interrupt = 1000000 / resolution
	--	1 millisecond = 8250 timer ticks
	-- In TIM-40 systems this value is calulated from ID ROM info

	-- Load clock tick value for 1 millisecond
	GetExecRoot R_ATMP				-- address of ExecRoot
	-- load IDROM value for number of clock ticks in 1 millisecond
	ldi	*+R_ATMP(ExecRoot.ID_ROM + IDROM.TIMER0_PERIOD), R_TMP1
	ldaperi	timer0_control R_ATMP
	sti	R_TMP1, *+R_ATMP(timer_period)		-- st in clk0 period reg
	stik	0, *+R_ATMP(timer_count)		-- zero counter

	bUd	R_LR	-- delayed branch
		-- setup clk0 control reg
		-- use internal clock, reset it and let it go
		-- set TCLK0 pin to general I/O output
		-- set output low = access local RAM rather than TIM-40 ID ROM
		ldi	start_timer, R_TMP1
		sti	R_TMP1, *+R_ATMP(timer_control)	-- st in clk0 ctrl reg

		-- enable clock 0 interrupts
		or	IIE_ETINT0, iie


-- Time slicer clock interrupt handler
-- 
-- This is entered directly from the timer 0 interrupt vector.
-- Interrupts are disabled and the return address is pointed to by
-- the system stack pointer.
--
-- Assumes clock 0 interrupt every millisecond.
--
-- The code is organised so that the most likely set of circumstances causes
-- no branches until the RETI is hit. i.e. There will usually be items on
-- the timer Q, but they will not usually need waking up and the interrupt
-- will not usually require the current thread to be timesliced. Also
-- the minimum number of registers are stacked.
--
-- @@@@@@ This code should be re-organised to minimise interrupt latency, the
-- potentially longest path should be optimised by removing any branches
-- from this path (reduce pipeline stalling).

	-- Exported to c40linkio.a for LinkRx/Tx dispatch.
	export	extern_slice_now

SliceIntrHandler:
	-- save minimal state
	push	ST
	push	R_BASE
	push	ar0	-- used exclusively as ExecRoot pointer
	push	ar1
	push	ar2

	-- if any regs are added to the stack update this manifest
	_def	'num_stacked_regs	5

_test _defp 'LATENCYTEST [	-- used to check Max interrupt latency
	ldaperi timer0_control ar2
	or	ST_SET_COND, st		-- Set cond codes for all registers

	ldi	halt_timer, ar0		-- hold timer so we can read count
	sti	ar0, *+ar2(timer_control)

	ldi	continue_timer, ar0	-- resume timer control bits
	ldi	*+ar2(timer_count), ar1	-- read current count

	sti	ar0, *+ar2(timer_control) -- resume timer

	-- ar0 = address of ExecRoot
	GetExecRoot ar0

	subi	10/2, ar1	-- subtract the handler overhead
				-- 10 instructions in handler / timer clock

	ldi	*+ar0(ExecRoot.MaxLatency), ar2

	cmpi	ar2, ar1
	bLSd	smaller_latency
	        -- Increment ExecRoot usec timer by 1 millisecond.
	        -- ar2 = incremented ExecRoot timer value
        	ldi     *+ar0(ExecRoot.Timer), ar2
	        addi    ONEMILLISEC, ar2
	        sti     ar2, *+ar0(ExecRoot.Timer)

	-- Save new max intr. latency seen + PC of interrupted thread.
	sti	ar1, *+ar0(ExecRoot.MaxLatency)
	ldi	SP, ar1
	ldi	*-ar1(4), ar1	-- get stacked PC
	sti	ar1, *+ar0(ExecRoot.MaxLatencyPC)
	b	conttimerhandler
smaller_latency:
	sti	ar1, *+ar0(ExecRoot.Latency)
conttimerhandler:
][
	-- ar0 = address of ExecRoot
	GetExecRoot ar0

	or	ST_SET_COND, st		-- Set cond codes for all registers

        -- increment ExecRoot usec timer by 1 millisecond
        -- ar2 = incremented ExecRoot timer value
        ldi     *+ar0(ExecRoot.Timer), ar2
        addi    ONEMILLISEC, ar2
        sti     ar2, *+ar0(ExecRoot.Timer)
]

_if _false [ -- used to check for SP bug corrupting stacked return address
	ldi	sp, ar0
	ldi	*-ar0(4), ar1

	ldhi	0x40, ar0
	cmpi	ar0, ar1
	bge	stopme

	GetExecRoot ar0
	cmpi	ar0, ar1
	ble	stopme

	-- may store value in ar1 in root struct if we are having problems
	-- determining what gets corrupted by an interrupt at the wrong time
]
	-- Load the C address base. This is needed when converting byte
	-- to word (MPtrs) pointers.
	ldi	*+ar0(ExecRoot.CAddressBase), R_BASE

        -- check timer Q for threads to reshedule
        -- ar1 = TimerQ SaveState pointer
        ldi     *+ar0(ExecRoot.TimerQ), ar1
        bZ      no_wakeups 	        -- empty TimerQ

        -- Check if top SaveState should be woken up now
	-- TimerQ SaveStates are in shortest time to wakeup order
	-- if (After(xroot->Timer, ss->wakeup) goto do_wakeups
	-- C40WordAddress ar1
	lsh	-2, ar1		 	-- convert ar1 BPTR to WPTR
	addi	R_BASE, ar1

        cmpi    *+ar1(SaveState.endtime), ar2
        bGE	do_wakeups

no_wakeups:
	-- When higher priority threads than the current one
	-- are on the run Q, we preemptively slice the current thread
	-- before its full timeslice is completed and immediately execute the
	-- higher priority thread(s).
	-- ar1 = current pri

	-- check if current thread is HIGHPRI (0). If so simply return.
	ldi	*+ar0(ExecRoot.CurrentPri), ar1
	bZ	IntrRet

	-- if higher priority is available - slice straight away
	cmpi	*+ar0(ExecRoot.HighestAvailPri), ar1
	bGT	slice_now

	-- check if timeslicing is enabled
	cmpi	0, *+ar0(ExecRoot.SliceEnabled)
	beq	IntrRet

	-- dec ticks until slice counter
	subi	1, *+ar0(ExecRoot.SliceTime), ar2	-- ar2 = number of ticks left
	sti	ar2, *+ar0(ExecRoot.SliceTime)

	-- If Timeslice has not yet expired then return from interrupt and
	-- continue thread.

	bLE	check_slice	-- if timeslice not exausted, continue
				-- else check if any other threads are on our
				-- priorities run Q, if so slice me.

IntrRet:
	pop	ar2
	pop	ar1
	pop	ar0
	pop	R_BASE
	pop	st
	retiU		-- enable interrupts and return from interrupt 


do_wakeups:
	push	ar3	-- need a few more regs
	push	ar4
	push	ar5

_if _defp 'accurate_but_not_deterministic [
	push	ar6	-- don't need ar6 if no loop at end

while_loop:
]

        -- If we get here the ar1 == (WPTR) SaveState is due for wakeup
	-- ar0 = ExecRoot
        -- ar1 = TimerQ SaveState to wakeup
        -- ar2 = current ExecRoot timer value

	-- Remove SaveState from timer Q
        -- ExecRoot->TimerQ = ss->next
_test _defp 'accurate_but_not_deterministic [
	ldi     *+ar1(SaveState.next), ar6	-- ar6 = ss->next (BPTR)
	ldi	*+ar1(SaveState.priority), ar3	-- ar3 = priority
	sti     ar6, *+ar0(ExecRoot.TimerQ)	-- xroot->TimerQ = ss->next
][
	-- can re-use ar4
	ldi     *+ar1(SaveState.next), ar4	-- ar4 = ss->next (BPTR)
	ldi	*+ar1(SaveState.priority), ar3	-- ar3 = priority
	sti     ar4, *+ar0(ExecRoot.TimerQ)	-- xroot->TimerQ = ss->next
]

	-- Check if new thread is higher than the HighestAvailPri
	--
	-- if (xroot->HighestAvailPri < ss->priority)
	cmpi	*+ar0(ExecRoot.HighestAvailPri), ar3
	bGEd	not_higherpri
	        -- Add SaveState to the tail of its priority's run Q
        	-- ar2 = &ExecRoot->Queues[priority].tail

		-- Get addr. of start of run Q's.
	        addi    ExecRoot.Queue0.tail, ar0, ar5
		-- ar5 = index into run Q table
		addi	ar3, ar5
		addi	ar3, ar5	-- &ExecRoot->Queue[0] + priority * 2 

	-- Keep a note of the highest priority thread available to schedule.
	--	xroot->HighestAvailPri = ss->priority;
	sti	ar3, *+ar0(ExecRoot.HighestAvailPri)

not_higherpri:
	-- Add SaveState to tail of run Q.
	-- do: q.tail = q.tail->next = ss
	--
	-- ar1 = SaveState (WPTR)
	-- ar5 = q.tail

	-- ar4 = (BPTR) SaveState
	-- C40CAddress ar1, ar4
	subi	R_BASE, ar1, ar4
	lsh	2, ar4

	-- ar3 = q.tail (WPTR)
	-- C40WordAddress *+ar5(0), ar3
	lsh	-2, *+ar5(0), ar3
	addi	R_BASE, ar3

	-- rest of instructions for adding to tail are in delay slots
	-- after next conditional delayed branch

	-- If a TimedWait()/TimedSuspend() thread times out then the status
	-- value must be left unmolested so that concurrent Resume()'s can
	-- detect that the thread is special - see Resume().

	-- if (ss->status != THREAD_TIMEDWAIT)
	--	ss->status = THREAD_RUNNABLE;

	cmpi	THREAD_TIMEDWAIT, *+ar1(SaveState.status)
	bEQd	skip_run_status
		sti	ar4, *+ar3(SaveState.next)	-- q.tail->next = ss
		sti	ar4, *ar5			-- q.tail = ss
		-- terminate Q at this SaveState
		stik	NULL, *+ar1(SaveState.next)	-- ss->next = NULL

	stik	THREAD_RUNNABLE, *+ar1(SaveState.status)

skip_run_status:

_test _defp 'accurate_but_not_deterministic [
	-- ar6 = ss->next at this point
	-- ss = xroot->TimerQ;
	ldi	ar6, ar1
        -- C40WordAddress ar1
	lsh	-2, ar1		 	-- convert ar1 BPTR to WPTR
	addi	R_BASE, ar1

	-- if (ss == NULL) break
	bZ	no_more_wakeups

        -- Check if the new top SaveState should be woken up now
        -- if (After(xroot->Timer, ss->wakeup) goto while_loop
        cmpi    *+ar1(SaveState.endtime), ar2
        bGE	while_loop
][
	-- Deterministic - wouldn't loop for 200 entries if they all needed
	-- scheduling, just once. But not as accurate as each concurrent wakeup
	-- could be > 1Ms out.
]

no_more_wakeups:
_if _defp 'accurate_but_not_deterministic [
	pop	ar6			-- only pop if we save
]
	bud	no_wakeups
		pop	ar5
		pop	ar4
		pop	ar3


check_slice:
	-- We reach this point if we know that no higher priorities are
	-- currently available to run. Therefore we are simply running
	-- round robin in this priorities Q. Therefore if we are the only
	-- thread on the Q, we can simply continue instead of slicing.
	--
	-- Entered with:
	--	ar0 = ExecRoot
	--	ar1 = current pri

	-- Get address of run Q for this priority into ar2.
	-- ar2 = &ExecRoot->Queue[pri].head
        addi    ExecRoot.Queue0.head, ar0, ar2	-- &xroot->Queue[0].head
	addi	ar1, ar2
	addi	ar1, ar2			-- ar2 =index into run Q

	-- Check if any other threads are at the same priority, if not
	-- just continue current thread.
	ldi	*ar2++, ar1			-- ++ now points ar2 at tail
	cmpi	NULL, ar1			-- check if Q is empty
	bNE	do_slice

	-- Only thread on Q so reset timeslice time and continue thread
	bud	IntrRet
		ldi	*+ar0(ExecRoot.TicksPerSlice), ar1
		nop
		sti	ar1, *+ar0(ExecRoot.SliceTime) 	


extern_slice_now:
	-- Time slicing mechanism entered here from external callers. This
	-- is currently just the LinkTx/Rx interrupt handlers.

	-- Entered with:
	--	ar1 = current pri
	--
	--	System stack must contain:
	--		ST
	--		IR0
	--		AR0-2

	-- Adjust stack to correct contents.
	pop	ar3

	-- Make sure ar0 holds expected address.
	GetExecRoot ar0

slice_now:
	-- If we get to this point then we are going to slice the current
	-- thread. This is achieved by adding its SaveState to the appropriate
	-- run Q, saving its CPU context into its SaveState and then jumping
	-- to the Dispatch()er.
	--
	-- Entered with:
	--	ar0 = ExecRoot
	--	ar1 = current pri

	-- Get address of run Q for this priority into ar2
	-- ar2 = &ExecRoot->Queue[pri].tail
        addi    ExecRoot.Queue0.tail, ar0, ar2	-- &xroot->Queue[0].tail
	addi	ar1, ar2
	addi	ar1, ar2			-- ar2 =index into run Q

do_slice:
	-- Place CPU context of thread into SaveState pointed to from
	-- ExecRoot->CurrentSaveArea.
	--
	-- Entered with:
	--	ar0 = ExecRoot
	--	ar2 = &ExecRoot->Queue[pri].tail (MPtr)
	--
	--	System stack contains:
	--		ST
	--		IR0
	--		AR0-2

	-- Add the SaveState to the appropriate run Q.

	push	ar3	-- Need a few more scratch regs
	push	ar4

	-- ar1 = current threads SaveState
	-- C40WordAddress *+ar0(ExecRoot.CurrentSaveArea), ar1
	lsh	-2, *+ar0(ExecRoot.CurrentSaveArea), ar1
	addi	R_BASE, ar1

	-- Add thread to tail of this priorities run Q.
	-- do: q.tail = q.tail->next = ss

	-- ar4 = (BPTR) SaveState
	-- C40CAddress ar1, ar4
	subi	R_BASE, ar1, ar4
	lsh	2, ar4

	-- ar3 = q.tail (WPTR) SaveState
	-- C40WordAddress *+ar2(0), ar3
	lsh	-2, *+ar2(0), ar3
	addi	R_BASE, ar3

	sti	ar4, *+ar3(SaveState.next)	-- q.tail->next = ss
	sti	ar4, *ar2			-- q.tail = ss

	-- Terminate Q at this SaveState.
	stik	NULL, *+ar1(SaveState.next)	-- ss->next = NULL

	-- oldss->CPUTimeTotal += difftimes(Timer(), oldss->LastTimeStamp);
	subi	*+ar1(SaveState.LastTimeStamp), *+ar0(ExecRoot.Timer), ar3
	addi	*+ar1(SaveState.CPUTimeTotal), ar3
	sti	ar3, *+ar1(SaveState.CPUTimeTotal)

	-- Note we should be restored via a RETI
	stik	THREAD_SLICED, *+ar1(SaveState.status)

	-- Save CPU state to threads SaveState structure.
	-- Required reg state:
	--	ar0 = ExecRoot
	--	ar1 = Current threads SaveState structure (WPTR)
	--	ar2-4 are stacked on SSP

	-- ar4 = ss->CPUcontext.PC
	addi	SaveState.CPUcontext + CPURegs.PC, ar1, ar4

	-- ar3 = Position of interrupted PC stored on system stack.
	-- = SSP - previously stacked regs - 2 for stacked ar3-4
	subi	num_stacked_regs + 2, R_SSP, ar3

	-- @@@@@@ If position of IR0 in SaveState is changed, we can optimise this
	-- code further (no need to save ir0, bigger rpts when saving rest of
	-- stacked registers).

	-- Move start of stacked state (PC, ST) to SaveState.
	-- Assumes PC, ST, are held contigously in SaveState
	ldi	*ar3++, ar2
	sti	ar2, *ar4++		-- interrupt return address

	ldi	*ar3++, ar2
	sti	ar2, *ar4++		-- status reg

	ldi	*ar3++, ar2		-- hold user R_BASE value

	-- Point stack at FP register SaveState area.
	-- 	- 1 to compensate for PUSH preincrement
	addi	SaveState.CPUcontext + CPURegs.A1 - 1, ar1, R_SSP

	-- PUSH unmolested registers into the SaveState.
	-- Assumes these registers are held in contigous locations in the
	-- SaveState. PUSH both the integer and float portions of the
	-- extended-precision registers.
	push	r0	pushf	r0
	push	r1	pushf	r1
	push	r2	pushf	r2
	push	r3	pushf	r3
	push	r4	pushf	r4
	push	r5	pushf	r5
	push	r6	pushf	r6
	push	r7	pushf	r7
	push	r8	pushf	r8
	push	r9	pushf	r9
	push	r10	pushf	r10
	push	r11	pushf	r11

	-- PUSH remaining registers.
	push	dp
	push	ar2		-- ar2 holds stacked user R_BASE
	push	ir1
	push	bk
	push	rs
	push	re
	push	rc

	-- Adjust system stack pointer back to pre-interrupt position.
	-- R_SSP = ar3 - 1 to adjust for push pre-increment, - 3 for 'pop'ed PC,
	-- ST and IR0.
	subi	1 + 3, ar3, R_SSP

	-- Move rest of stacked state (ar0-4) to SaveState
	-- Assumes AR0..AR7 are held contigously in SaveState
	-- can now corrupt r0 as it has been saved.

	ldi	*ar3++, r0		-- init first r0 value (ar0) 
					-- for // instr.

	rpts	3			-- actually repeats 4 times.
		ldi	*ar3++, r0 ||	-- sti occurs with old r0 value.
		sti	r0, *ar4++	-- ar0 - ar3

	sti	r0, *ar4++		-- store final r0 value (ar4)

	-- Save non stacked address regs (ar5-7)
	sti	ar5, *ar4++		-- ar5
	sti	ar6, *ar4++		-- ar6
	sti	ar7, *ar4++		-- ar7

	-- As we have just saved the machine state, we can now corrupt
	-- any register.
	-- Create skeleton C environment.
	-- R_USP = dispatch stack for safe timer interrupt during scheduler idle
	-- R_BASE = use standard system base (already set)
	-- R_A1 = NULL (arg to Dispatch())
	-- R_USE - not needed, as kernel never enables stack checking
	-- R_FP - not needed
	-- R_MT - not needed (kernel has no module table)
	-- R_LR - not needed (we will never return)

_test _defp 'LATENCYTEST [
	-- Set millisecond time, incase the latency is greater than 1Ms.
	-- Timer holds microsecond count, but resultion is only milleseconds.
	ldi	*+ar0(ExecRoot.Timer), ar1
	sti	ar1, *+ar0(ExecRoot.DispatchLatMs)

	-- Get address of semaphore.
	addi	ExecRoot.DispatchLatCheck, ar0, R_A1
	C40CAddress R_A1

	patchinstr(PATCHC40MASK24ADD, shift(-2, labelref(.HardenedSignal)),
		laj	0)
		-- Get address of stack for HardenedSignal/Dispatch(). This is
		-- a small stack that allows interrupts to occur safely while
		-- the dispatcher stays in its idle loop.
		ldi	ExecRoot.DispatchStack + DISPATCHSTACKSIZE - 1, R_USP
		addi	ar0, R_USP
		nop

	patchinstr(PATCHC40MASK24ADD, shift(-2, labelref(.Dispatch)),
		bud	0)
		ldi	NULL, R_A1	-- NULL *SaveState arg to Dispatch()
		nop
		nop
][
	-- jump to C implementation of Dispatch()er
	patchinstr(PATCHC40MASK24ADD, shift(-2, labelref(.Dispatch)),
		bud	0)
	
		-- Get address of stack for Dispatch(). This is a small stack
		-- that allows interrupts to occur safely while the dispatcher
		-- stays in its idle loop.
		ldi	ExecRoot.DispatchStack + DISPATCHSTACKSIZE - 1, R_USP
		addi	ar0, R_USP
		ldi	NULL, R_A1	-- NULL *SaveState arg to Dispatch()
]


-- void IdleUntilInterrupt(void);
--
-- Enable interrupts and idle until an interrupt occurs, then disable
-- interrupts again and return.
--
-- Called from C so must conform to PCS

	Function IdleUntilInterrupt

	idle			-- enable interrupts and wait for an interrupt
	AllIntsOff		-- disable interrupts globally again
	b	R_LR



-- void InitEventHandler(VoidFnPtr handler);
--
-- Initialise each interrupt vector to call the event handler passed.
-- The call must be done in a PCS conformant fashion.
-- The handler expects to be called with the number of the
-- vector number of the interrupt source.
--
-- Note that the C40 version will always call the RootEventHandler() whatever
-- ignoring the function pointer passed to this function.
--
-- Called from C so must conform to PCS

	Function InitEventHandler

        -- Point interrupt vector at correct handler stub

        -- get address of first interrupt handler stub
        ldabs16 IntrHandler0 R_A1

        -- get hold of interrupt vector base
        ldep    ivtp, R_ADDR1
                
	-- NMI
        -- store address of stub handler into interrupt vector.
        sti     R_A1, *+R_ADDR1(iv_nmi)		-- setup stub

	-- II0F0
	-- 5 = stub handler is 5 instructions long.
	addi	5, R_A1				-- inc to next handler
        sti     R_A1, *+R_ADDR1(iv_iiof0)	-- setup stub

	-- II0F1
	addi	5, R_A1				-- inc to next handler
        sti     R_A1, *+R_ADDR1(iv_iiof1)	-- setup stub

	-- II0F2
	addi	5, R_A1				-- inc to next handler
        sti     R_A1, *+R_ADDR1(iv_iiof2)	-- setup stub

	-- II0F3
	addi	5, R_A1				-- inc to next handler
        sti     R_A1, *+R_ADDR1(iv_iiof3)	-- setup stub

	-- TINT1
	addi	5, R_A1				-- inc to next handler
        sti     R_A1, *+R_ADDR1(iv_tint1)	-- setup stub

	b	R_LR


-- IntrHandlerX
--
-- These interrupt handlers handle the general interrupt vectors that
-- user programs can attach to with SetEvent.
--
-- The interrupt is vectored through a stub that loads the correct interrupt
-- vector number, and then proceeds into the general handler.


-- Interrupt handler for INTR_NMI
IntrHandler0:
        -- interrupt vectored to this point 
        push    R_ST                     -- MUST save ST here
        bud     GenHandler
		push	R_BASE
		push	R_ADDR1		-- save reg we're about to trash
		ldi	INTR_NMI, R_ADDR1

-- Interrupt handler for INTR_IIOF0
IntrHandler1:
        -- interrupt vectored to this point 
        push    R_ST                     -- MUST save ST here
        bud     GenHandler
		push	R_BASE
		push	R_ADDR1		-- save reg we're about to trash
		ldi	INTR_IIOF0, R_ADDR1

-- Interrupt handler for INTR_IIOF1
IntrHandler2:
        push    R_ST                     -- MUST save ST here
        bud     GenHandler
		push	R_BASE
		push	R_ADDR1		-- save reg we're about to trash
		ldi	INTR_IIOF1, R_ADDR1

-- Interrupt handler for INTR_IIOF2
IntrHandler3:
        push    R_ST                     -- MUST save ST here
        bud     GenHandler
		push	R_BASE
		push	R_ADDR1		-- save reg we're about to trash
		ldi	INTR_IIOF2, R_ADDR1

-- Interrupt handler for INTR_IIOF3
IntrHandler4:
        push    R_ST                     -- MUST save ST here
        bud     GenHandler
		push	R_BASE
		push	R_ADDR1		-- save reg we're about to trash
		ldi	INTR_IIOF3, R_ADDR1

-- Interrupt handler for INTR_TINT1
IntrHandler5:
        push    R_ST                     -- MUST save ST here
        bud     GenHandler
		push	R_BASE
		push	R_ADDR1		-- save reg we're about to trash
		ldi	INTR_TINT1, R_ADDR1


-- General interrupt handler
GenHandler:
	-- Save registers that will get trashed in a standard PCS environment
	-- The only registers we do not need to save are the variable (R_V?)
	-- ones that are saved upon entry.
	--
	-- @@@@@@ A major optimisation here would be to save the processor state
	-- into the current threads SaveState structure. If we subsequently
	-- decide to slice the thread, half the work has been done already,
	-- we would simply have to add the thread to the run Q and call the
	-- dispatcher.

	-- R_ST, R_BASE and R_ADDR1 have already been stacked

	push	R_ADDR2			-- ar1
	push	R_ADDR3			-- ar2

	push	R_ADDR4
	push	R_A1
	push	R_A2
	push	R_A3
	push	R_A4
	push	R_FT1		
	push	R_FT2
	push	R_T1
	push	R_LR
	push	R_TMP1
	push	R_TMP2
	push	R_TMP3
	push	R_MT
	push	R_ATMP
	push	R_USE
	push	R_USP
	push	R_FP

	-- Create skeleton C environment.
	-- R_USP = use R_SSP stack area as interrupts should not be re-enabled
	-- 	   also note that we set this at the end of the stack area as
	--	   C stack push downwards, whereas the system stack pushes up.
	-- R_BASE = base of C Addressable memory.
	-- R_A1 = interrupting vectors number set by stub
	-- R_USE = 0 so any stack checking in users code is ignored
	-- R_FP = 0 so backtraces wont get screwed up.
	-- R_MT - not needed by kernel, root handler will set user MT.
	-- R_LR - our return addr.
	-- R_ST - condition codes are set for all registers.

	ldi	R_ADDR1, R_A1		-- pass INTR_XXX arg to event handler

	or	ST_SET_COND, st		-- Set cond codes for all registers

	-- Reset system-wide C address base.
	GetExecRoot R_ATMP
	ldi	*+R_ATMP(ExecRoot.CAddressBase), R_BASE

	-- Set user stack to end of system stack area (USP pushes down).
	addi	ExecRoot.sizeof / 4, R_ATMP, R_USP
	addi	0x200-1, R_USP

	-- jump to C Root Event Handler
	patchinstr(PATCHC40MASK24ADD, shift(-2, labelref(.RootEventHandler)),
		laj	0)
		andn	0x200-1, R_USP
		ldi	NULL, R_USE
		ldi	NULL, R_FP

GenIntrReturn:
	-- Restore original state from system stack
	pop	R_FP
	pop	R_USP
	pop	R_USE
	pop	R_ATMP
	pop	R_MT
	pop	R_TMP3
	pop	R_TMP2
	pop	R_TMP1
	pop	R_LR
	pop	R_T1
	pop	R_FT2
	pop	R_FT1		
	pop	R_A4
	pop	R_A3
	pop	R_A2
        pop     R_A1
	pop	R_ADDR4

	-- Make sure that any higher priority threads that have just been
	-- resumed are run immediately.
	-- Stack remaining is the same as is required by the timeslicer.

	-- If we detect a higher priority thread than the current one is
	-- available, then we slice the current thread and call the
	-- dispatcher to run the higher priority thread.
	GetExecRoot ar0
	ldi	*+ar0(ExecRoot.CurrentPri), ar1
	cmpi	*+ar0(ExecRoot.HighestAvailPri), ar1
	bgt	slice_now

	-- Otherwise resume the interrupted thread.
	pop	R_ADDR3			-- ar2
	pop	R_ADDR2			-- ar1
	pop	R_ADDR1			-- ar0
	pop	R_BASE			-- ir0
        pop     R_ST

        retiU                           -- return from interrupt



-- int DefineExecErrorHandler(VoidFnPtr handler);
--
-- Attach the handler function to the processors exception vector. The function
-- called should form the root of the syncronous run-time signal handler.
-- i.e. any address/bus errors, div by 0, etc exceptions.
--
-- Called from C so must conform to PCS

	Function DefineExecErrorHandler

	-- C40 cannot do any of this so simply return!
	b	R_LR



-- end of c40intr.a
@


1.20
log
@Functions SetIIFBits(), ClrIIFBits() and WriteTCR added.
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.19 1993/01/26 18:35:02 paul Exp $
d15 3
d303 1
a303 1
_test _false [	-- used to check Max latency
d310 1
d312 2
a313 2
	ldi	continue_timer, ar0	-- resume timer
	sti	ar0, *+ar2(timer_control)
d318 2
a319 1
	subi	28, ar1			-- subtract the overhead
d322 4
a325 4
	
	cmpi	ar1, ar2
	bGEd	smaller_latency
	        -- increment ExecRoot usec timer by 1 millisecond
d331 1
a331 1
	-- save new max intr. latency seen + PC of interrupted thread
d336 2
a337 3

	-- save worst case Dispatch entry
	ldi	*+ar0(ExecRoot.DMAInts), ar1
d339 1
a339 2

smaller_latency:
d746 25
d781 1
a781 1

@


1.19
log
@fixed assembler bug that allowed nonsense cmpi NULL, *ar2++ to be parsed.
Fixed assembler and changed source - how did this ever work? timesliceing
should have caused threads to be lost?
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.18 1993/01/26 10:07:27 paul Exp $
d15 5
d152 58
@


1.18
log
@optimised time slice and reduced generic interrupt handlers dispatch
latency.
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.17 1993/01/25 09:06:28 paul Exp paul $
d15 4
d486 1
a486 1
	-- get address of run Q for this priority into ar2
d492 4
a495 4
	-- check if any other threads are at the same priority, if not
	-- just continue current thread
	cmpi	NULL, *ar2++			-- check if Q is empty
						-- ++ points ar2 at tail
d501 1
a502 1
		nop
a544 1
	--	ar1 = current pri (not strictly required)
@


1.17
log
@minor tidies
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.16 1992/11/20 15:43:46 paul Exp $
d15 3
d214 4
d219 3
d471 1
d477 4
a482 1
	-- ar1 = current pri
d500 19
d520 9
a529 1
	-- ar1 = current pri
d536 2
a537 3
	-- If we get to this point then we are going to slice the current
	-- thread, add its SaveState to the appropriate run Q, save its state
	-- and then jump to the Dispatch()er.
d541 9
a549 2
	--	ar1 = current pri
	--	ar2 = &ExecRoot->Queue[pri].tail
d551 1
a551 1
	push	ar3	-- use a few more scratch regs
a552 2
	push	ar5
	push	ar6
d554 1
a554 2
	-- place CPU context of thread into ExecRoot->CurrentSaveArea
	-- ar1 = current threads SaveState (ss)
a557 11
						-- ar4=ss->CPUcontext.PC
	addi	SaveState.CPUcontext + CPURegs.PC, ar1, ar4
	subi	num_stacked_regs + 4, R_SSP, ar3 -- ar3 = interrupted PC
						-- + 4 for stacked ar3-6
	-- Move stacked state to SaveState
	-- Assumes PC, ST, AR0..Ar6 are held contigously in SaveState
	-- @@@@@@ This should be optimised with a // ld + st and a rpts.

_test _false [
	push	r0			-- need fp register for // instr
	pushf	r0
d559 2
a560 2
	ldi	*ar3++, r0
	sti	r0, *ar4++		-- interrupt return address
d562 4
a565 2
	ldi	*ar3++, r0
	sti	r0, *ar4++		-- status reg
d567 4
a570 1
	ldi	*ar3++, ar6		-- hold user R_BASE value
d572 2
a573 5
	ldi	*ar3++, r0		-- init first r0 value (ar0) 
					-- for // instr.
	rpts	6
		ldi	*ar3++, r0 ||
		sti	r0, *ar4++	-- ar0 - ar6
d575 2
a576 1
	sti	r0, *ar4++		-- store final r0 value (ar6)
d578 4
a581 5
	popf	r0			-- restore tmp fp reg.
	pop	r0
][
	ldi	*ar3++, ar5		-- init first ar5 value
	sti	ar5, *ar4++		-- interrupt return address
d583 2
a584 2
	ldi	*ar3++, ar5
	sti	ar5, *ar4++		-- status reg
d586 5
a590 1
	ldi	*ar3++, ar6		-- hold user R_BASE value
d592 2
a593 5
	ldi	*ar3++, ar5
	sti	ar5, *ar4++		-- ar0

	ldi	*ar3++, ar5
	sti	ar5, *ar4++		-- ar1
d595 3
a597 2
	ldi	*ar3++, ar5
	sti	ar5, *ar4++		-- ar2
d599 3
a601 2
	ldi	*ar3++, ar5
	sti	ar5, *ar4++		-- ar3
d603 4
a606 2
	ldi	*ar3++, ar5
	sti	ar5, *ar4++		-- ar4
d608 2
a609 2
	ldi	*ar3++, ar5
	sti	ar5, *ar4++		-- ar5
d611 1
a611 5
	ldi	*ar3, ar5		-- ar6 (note no inc on last load)
	sti	ar5, *ar4++		-- ar3 now points to last stacked reg
]
	-- stack unmolested address registers
	sti	ar7, *ar4 		-- ar7
d613 1
a613 1
	-- point stack at remainder of SaveState area
d615 1
a615 1
	addi	SaveState.CPUcontext + CPURegs.A1 - 1, ar1, sp
d636 1
a636 1
	push	ar6		-- ar6 holds stacked user R_BASE
a642 5
	-- Note we never save sp, iie, and iif registers.

	-- As we have just saved the machine state, we can now corrupt
	-- any register.

d644 7
a650 3
	-- ar3 = last stacked reg, + 1 = past stacked PC, + 4 past extra 
	-- stacked regs + std stacked regs.
	subi	num_stacked_regs + 1 + 4, ar3, sp
d652 2
a653 4
	-- Add thread to tail of this priorities run Q.
	-- do: q.tail = q.tail->next = ss
	-- ar1 = SaveState (WPTR)
	-- ar2 = &xroot->Queues[pri].tail
d655 3
a657 4
	-- ar4 = (BPTR) SaveState
	-- C40CAddress ar1, ar4
	subi	R_BASE, ar1, ar4
	lsh	2, ar4
d659 1
a659 4
	-- ar3 = q.tail (WPTR)
	-- C40WordAddress *+ar2(0), ar3
	lsh	-2, *+ar2(0), ar3
	addi	R_BASE, ar3
d661 4
a664 2
	sti	ar4, *+ar3(SaveState.next)	-- q.tail->next = ss
	sti	ar4, *ar2			-- q.tail = ss
d666 2
a667 44
_if _false [	-- check status of thread and save trace record in global ram
	ldi	*+ar1(SaveState.status),r0
	cmpi	THREAD_RUNNING, r0
	beq	statok
	swi
statok:
	ldhi	0x30, ar4
	or	0x19, ar4
	cmpi	ar2, ar4
	bge	tailok
	swi
tailok:
	ldhi	0x30, ar4
	or	0xa, ar4
	cmpi	ar2, ar4
	blt	headok
	swi
headok:
	tstb	1, ar2
	bnz	oddok
	swi
oddok:

	push	ar0		-- note which thread is sliced
	ldhi	0xdeed, ar0	
	patchinstr(PATCHC40MASK24ADD, shift(-2, labelref(._GTrace)), Call 0)
	ldi	THREAD_SLICED, ar0
	patchinstr(PATCHC40MASK24ADD, shift(-2, labelref(._GTrace)), Call 0)
	ldi	ar1, ar0
	patchinstr(PATCHC40MASK24ADD, shift(-2, labelref(._GTrace)), Call 0)
	pop	ar0
]

	-- Terminate Q at this SaveState.
	stik	NULL, *+ar1(SaveState.next)	-- ss->next = NULL

	-- oldss->CPUTimeTotal += difftimes(Timer(), oldss->LastTimeStamp);
	subi	*+ar1(SaveState.LastTimeStamp), *+ar0(ExecRoot.Timer), R_A1
	addi	*+ar1(SaveState.CPUTimeTotal), R_A1
	sti	R_A1, *+ar1(SaveState.CPUTimeTotal)

	-- note we should be restored via a RETI
	stik	THREAD_SLICED, *+ar1(SaveState.status)

d732 2
a733 2
	-- 4 = stub handler is 4 instructions long.
	addi	4, R_A1				-- inc to next handler
d737 1
a737 1
	addi	4, R_A1				-- inc to next handler
d741 1
a741 1
	addi	4, R_A1				-- inc to next handler
d745 1
a745 1
	addi	4, R_A1				-- inc to next handler
d749 1
a749 1
	addi	4, R_A1				-- inc to next handler
d767 1
d769 3
a771 3
	        push    R_ST                     -- MUST save ST here
                push    R_A1                     -- save reg we're about to trash
		ldi	INTR_NMI, R_A1
d776 1
d778 3
a780 3
	        push    R_ST                     -- MUST save ST here
                push    R_A1                     -- save reg we're about to trash
		ldi	INTR_IIOF0, R_A1
d784 1
d786 3
a788 3
	        push    R_ST                     -- MUST save ST here
                push    R_A1                     -- save reg we're about to trash
		ldi	INTR_IIOF1, R_A1
d792 1
d794 3
a796 3
	        push    R_ST                     -- MUST save ST here
                push    R_A1                     -- save reg we're about to trash
		ldi	INTR_IIOF2, R_A1
d800 1
d802 3
a804 3
	        push    R_ST                     -- MUST save ST here
                push    R_A1                     -- save reg we're about to trash
		ldi	INTR_IIOF3, R_A1
d808 1
d810 3
a812 3
	        push    R_ST                     -- MUST save ST here
                push    R_A1                     -- save reg we're about to trash
		ldi	INTR_TINT1, R_A1
d820 19
a838 3
	-- R_ST and R_A1 have already been stacked
	push	R_A2		push	R_A3		push	R_A4
	push	R_FT1		push	R_FT2
d841 3
a843 3
	push	R_TMP1		push	R_TMP2		push	R_TMP3
	push	R_ADDR1		push	R_ADDR2		push	R_ADDR3
	push	R_ADDR4
a845 1
	push	R_BASE
d862 2
a885 1
	pop	R_BASE
a887 4
	pop	R_ADDR4
	pop	R_ADDR3
	pop	R_ADDR2	
	pop	R_ADDR1
d898 14
d913 5
a917 1
        pop     R_A1
@


1.16
log
@address base reg IR0 is now defined to be a constant, user code must
not change its value.
interrupt routines now assume that IR0 is correct
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.15 1992/11/18 14:37:00 paul Exp paul $
d15 5
a210 11
--
-- Note that the interrupt handler assumes that the true C Address base is
-- equivalent to the ExecRoot address. This is used in preference to the
-- possibly corrupt contents of IR0. Do not therefore use the C40Word/CAddress
-- macros.

_if _false  [ -- used for SP bug test
stopme:
	int	0x66ffffff	-- JTAGHalt
	b	stopme
]
d215 1
d221 1
a221 1
	_def	'num_stacked_regs	4
d288 3
a302 2
	--	addi	ar0, ar1	-- dont assume TVTP == IR0

d341 1
d350 1
d353 2
a356 1
while_loop:
d366 1
d371 1
a374 2
	ldi	*+ar1(SaveState.priority), ar3	-- ar3 = priority

d383 1
a383 1
		-- get addr. of start of run Q's
d385 2
a387 1
		addi	ar3, ar5	-- ar5 = index into run Q table
d389 1
a389 1
	-- keep a note of the highest priority thread available to schedule
d394 1
a394 1
	-- Add SaveState to tail of run Q
d396 1
a402 1
	--	subi	ar0, ar1, ar4		-- dont assume TVTP == IR0
a408 1
	--	addi	ar0, ar3		-- dont assume TVTP == IR0
a437 1
	--	addi	ar0, ar1	-- dont assume TVTP == IR0
d498 5
a502 2
	-- entered with ar0 = ExecRoot, ar1 = current pri
	-- ar2 = &ExecRoot->Queue[pri].tail
d507 1
a513 1
	--	addi	ar0, ar1		-- dont assume TVTP == IR0
d516 2
a517 2
	subi	num_stacked_regs + 3, sp, ar3	-- ar3 = interrupted PC
						-- + 3 for stacked ar3-5
d520 25
d551 2
d568 4
a571 1
	ldi	*ar3, ar5		-- ar5 (note no inc on last load)
d573 1
a573 1

d575 1
a575 2
	sti	ar6, *ar4++ 		-- ar6
	sti	ar7, *ar4++ 		-- ar7
d600 1
a600 1
	push	ir0
d613 1
a613 1
	-- ar3 = last stacked reg, + 1 = past stacked PC, + 3 past extra 
d615 1
a615 1
	subi	num_stacked_regs + 1 + 3, ar3, sp
a624 1
	--	subi	ar0, ar1, ar4		-- dont assume TVTP == IR0
a630 1
	--	addi	ar0, ar3		-- dont assume TVTP == IR0
d681 1
a681 1
	-- R_BASE = use standard system base
a698 3
-- Assume R_BASE is never corrupted by users!
--		ldi	NULL, R_BASE
--		ldi	ar0, R_BASE	-- set default address base
d841 3
a843 1
	-- R_USP = use R_SSP as interrupts should not be re-enabled
d850 1
d852 10
d865 1
a865 1
		ldi	R_SSP, R_USP	-- use system stack as user stack
a867 4

-- Assume R_BASE is never corrupted by users!
--		ldi	NULL, R_BASE
--		GetExecRoot R_BASE
@


1.15
log
@fixed up interrupt handlers to stop assuming IR0 is 0, instead they assume
GetExecRoot (tvtp) is synonymous with the std C address base
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.14 1992/11/12 20:54:42 paul Exp $
d15 4
d304 2
a305 2
--	addi	R_BASE, ar1
	addi	ar0, ar1
d402 1
d408 2
a409 2
--	addi	R_BASE, ar3
	addi	ar0, ar3
d438 2
a439 2
--	addi	R_BASE, ar1
	addi	ar0, ar1
d511 2
a512 2
--	addi	R_BASE, ar1
	addi	ar0, ar1
d594 2
a595 2
--	subi	R_BASE, ar1, ar4
	subi	ar0, ar1, ar4
d601 2
a602 2
--	addi	R_BASE, ar3
	addi	ar0, ar3
d653 1
a653 2
	-- R_BASE = - should not be needed as Dispatch has no static data
	--	however access to the execroot goes through this so set to 0
a659 5
	-- Get address of stack for Dispatch(). This is a small stack
	-- that allows interrupts to occur safely while the dispatcher
	-- stays in its idle loop.
	ldi	ExecRoot.DispatchStack + DISPATCHSTACKSIZE - 1, R_USP

d664 4
d670 2
d673 1
a673 1
		ldi	ar0, R_BASE	-- set default address base
d817 1
a817 1
	-- R_BASE = ExecRoot - base of C Addressable memory.
a823 2
	ldi	R_SSP, R_USP	-- use system stack as user stack

d827 1
a827 2
--		ldi	NULL, R_BASE
		GetExecRoot R_BASE
d830 4
@


1.14
log
@made C40Word/CAddress compatible with IR0 != 0
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.13 1992/11/12 17:17:25 paul Exp $
d15 3
d202 5
d298 6
a303 1
        C40WordAddress ar1              -- convert ar1 BPTR to WPTR
d403 2
a404 1
	addi	R_BASE, ar3
d431 4
a434 1
        C40WordAddress ar1		-- convert ar1 BPTR to WPTR
d506 2
a507 1
	addi	R_BASE, ar1
d589 2
a590 1
	subi	R_BASE, ar1, ar4
d596 2
a597 1
	addi	R_BASE, ar3
d667 2
a668 1
		ldi	NULL, R_BASE
d812 1
a812 2
	-- R_BASE = 0 @@@@@@ Currently not required, should be inserted when we
	--	move to a global memory system - probably by root handler
d824 2
a825 1
		ldi	NULL, R_BASE
@


1.13
log
@now used generic cpustate.m
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.12 1992/11/09 15:43:21 nickc Exp paul $
d15 3
d381 11
a391 2
	C40CAddress ar1, ar4			-- ar4 = (BPTR) SaveState
	C40WordAddress *+ar5(0), ar3		-- ar3 = q.tail (WPTR)
d416 2
a417 1
        C40WordAddress ar6, ar1              -- convert ar1 BPTR to WPTR
d487 3
a489 1
	C40WordAddress	*+ar0(ExecRoot.CurrentSaveArea), ar1
d568 11
a578 2
	C40CAddress ar1, ar4			-- ar4 = (BPTR) SaveState
	C40WordAddress *+ar2(0), ar3		-- ar3 = q.tail (WPTR)
@


1.12
log
@temporary fix until Paul produces new version of cpustate.h
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.11 1992/11/09 15:32:43 nickc Exp nickc $
d15 3
d55 1
a55 2
--include cpustate.m
include c40cpustate.m
a382 1
_test _true [
a399 16
][
	-- If a TimedWait()/TimedSuspend() thread times out then it must return
	-- a FALSE value to signify this. The status value must be
	-- left unmolested so that concurrent Resume()'s can detect
	-- that the thread is special - see Resume().

	-- if (ss->status == THREAD_TIMEDWAIT)
	--	ss->CPUcontext.A1 = FALSE;
	-- else
	--	ss->status = THREAD_RUNNABLE;
	cmpi	THREAD_TIMEDWAIT, *+ar1(SaveState.status)
	bNEd	run_status
		sti	ar4, *+ar3(SaveState.next)	-- q.tail->next = ss
		sti	ar4, *ar5			-- q.tail = ss
		-- terminate Q at this SaveState
		stik	NULL, *+ar1(SaveState.next)	-- ss->next = NULL
a400 10
	bud	skip_run_status
		stik	FALSE, *+ar1(SaveState.CPUcontext + CPURegs.A1)
		nop
		nop

run_status:
	stik	THREAD_RUNNABLE, *+ar1(SaveState.status)

skip_run_status:
]
@


1.11
log
@applied patch as per PB instructions
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.10 1992/09/25 09:37:18 paul Exp $
d15 3
d52 2
a53 1
include cpustate.m
@


1.10
log
@changed to use gexec.m
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.9 1992/09/23 17:21:54 paul Exp paul $
d15 3
d49 1
a49 1
include c40cpustate.m
d377 19
d421 1
@


1.9
log
@added NMI interrupt handler support
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.8 1992/08/18 09:54:42 paul Exp $
d15 3
d43 1
a43 1
include c40exec.m
@


1.8
log
@added generic interrupt handler initialisation and stub code
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.7 1992/07/30 18:30:29 paul Exp $
d15 3
d44 1
d53 2
a54 1
.IntsAreEnabled:
d68 2
a69 1
.IntsOn:
d82 2
a83 1
.IntsOff:
d95 2
a96 1
.ClockIntsOn:
d107 2
a108 1
.ClockIntsOff:
d111 1
d127 2
a133 1
.StartTimeSlicer:
d628 2
a629 1
.IdleUntilInterrupt:
d639 1
a639 1
-- The call must be done in a PCS confromant fashion.
d643 3
d648 1
a648 1
.InitEventHandler:
d658 1
d660 5
a667 1
	-- 4 = stub handler is 4 instructions long.
d695 1
a695 1
-- Interrupt handler for INTR_IIOF0
d701 8
d712 1
a712 1
IntrHandler1:
d719 1
a719 1
IntrHandler2:
d726 1
a726 1
IntrHandler3:
d733 1
a733 1
IntrHandler4:
d817 2
a818 1
.DefineExecErrorHandler:
@


1.7
log
@added thread timing support
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.6 1992/06/30 19:23:59 paul Exp $
d15 3
d626 4
a629 4
-- Initialise the root event handler
-- Uses a simple approach to unify interrupt handlers across
-- different processor versions of Helios (@@@@@@ trouble is its too simple at the
-- moment - see notes in c40exec.doc).
d634 39
a672 1
	b	R_LR		-- @@@@@@ currently a dummy
d675 56
d732 49
a790 2
	-- @@@@@@ check out norcroft support functions - divby0()
	-- this may need to call the handler!
a791 1

@


1.6
log
@removed debug
,
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.5 1992/06/26 17:59:02 paul Exp $
d15 4
d574 5
@


1.5
log
@changed from a fixed timeslice quantum to a variable one
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.4 1992/06/19 18:24:53 paul Exp $
d15 3
d167 1
a167 1
_if _defp 'SYSDEB [
d183 1
a183 1
_test _defp 'SYSDEB [	-- Max latency test
d233 1
a233 1
_if _defp 'SYSDEB [
d535 1
a535 1
_if _false [
@


1.4
log
@removed some debugging, optimised and fixed timeslice interrupt handler
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.3 1992/06/16 08:47:28 paul Exp $
d15 3
d132 3
a134 2
	ldi	*+R_ATMP(ExecRoot.ClockTick), R_TMP1	-- number of clock ticks
	ldaperi	timer0_control R_ATMP			-- in 1 millisecond
d423 1
a423 1
		ldi	TICKSPERSLICE, ar1
@


1.3
log
@cleaned up code and optimised slightly
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.2 1992/04/21 09:54:56 paul Exp $
d15 3
a191 3
_if _false [
	sti	ar1, *+ar0(ExecRoot.Latency)	-- save last latency seen
]
d211 1
a211 5
_if _true [ -- tmp dbg - check if clock handler took loger than timelslice!
	cmpi	0x6666, ar1
	bne	smaller_latency
	int	0x66ffffff
]
a254 1
_if _true [
a260 4
	-- check if timeslicing is enabled
	ldi	*+ar0(ExecRoot.SliceEnabled), ar1
	bZ	IntrRet

d267 5
a271 1
	bLT	slice_now
d283 1
a283 1
]
a440 1
	push	ar6
a442 1
	ldi	sp, ar6				-- ar6 = old sp
d447 2
a448 2
	subi	num_stacked_regs + 4, ar6, ar3	-- ar3 = interrupted PC
						-- + 4 for stacked ar3-6
d452 1
a453 1
	sti	ar5, *ar4++		-- interrupt return address
d455 1
a456 1
	sti	ar5, *ar4++		-- status reg
d458 1
a459 1
	sti	ar5, *ar4++		-- ar0
d461 1
a462 1
	sti	ar5, *ar4++		-- ar1
d464 1
a465 1
	sti	ar5, *ar4++		-- ar2
d467 1
a468 1
	sti	ar5, *ar4++		-- ar3
a469 1

a470 4
	ldi	*ar3++, ar5

	sti	ar5, *ar4++		-- ar5
	ldi	*ar3++, ar5
d472 2
a473 1
	sti	ar5, *ar4++		-- store last ar5 value : ar6
d476 1
d511 3
d515 4
a518 3
	-- ar6 = old sp value
	subi	num_stacked_regs + 1 + 4, ar6, sp	-- + 1 = past stacked PC
							-- + 4 for stacked ar3-6
d528 33
a581 3
_if _true [ -- tmp dbg
	ldi	0x6666, R_LR		-- note we come from outer space
]
@


1.2
log
@alpha version
@
text
@d10 1
a10 1
 * RcsId: $Id: c40intr.a,v 1.1 1991/12/03 11:53:02 paul Exp $
d14 4
a17 1
 * RcsLog: $Log$
d34 4
a37 3
	ldi	ST, R_A1result
	and	ST_GIE, R_A1result
	b	R_LR
d40 1
d48 4
a51 3
	or	ST_GIE, st	-- global interrupt enable bit set
	b	R_LR

d61 4
a64 2
	andn	ST_GIE, st	-- global interrupt enable bit zeroed
	b	R_LR
a65 1

d86 1
a172 16
_if _defp 'SYSDEB [
	ldi	sp, ar0
	ldi	*-ar0(4), ar1

	ldhi	0x40, ar0
	cmpi	ar0, ar1
	bge	stopme

	GetExecRoot ar0
	cmpi	ar0, ar1
	ble	stopme

	-- may store value in ar1 in root struct if we are having problems
	-- determining what gets corrupted by an interrupt at the wrong time
]

d187 5
d208 8
d230 16
d265 5
d274 1
d276 1
a276 1
	bGT	slice_now
d330 1
a330 1
        	-- ar2 = &ExecRoot->Queues[prioriy].tail
d550 8
a558 1

d562 1
a562 5
		-- Get address of stack for Dispatch(). This is a small stack
		-- that allows interrupts to occur safely while the dispatcher
		-- stays in its idle loop.
		addi	ExecRoot.DispatchStack + DISPATCHSTACKSIZE - 1, ar0, R_USP

a563 1

d576 1
a576 1
	andn	ST_GIE, st	-- disable interrupts globally again
@


1.1
log
@Initial revision
@
text
@d10 1
a10 1
 * RcsId: $Id$
d19 22
d42 3
a44 5

// Enable all interrupts
//
// Called from C so must conform to PCS
// void IntsOn(void);
a45 3
.IntsOn:
	or	ST_GIE, st	// global interrupt enable bit set
	br	R_LN
d47 5
a52 4
// Disable all interrupts
//
// Called from C so must conform to PCS
// void IntsOff(void);
d55 3
a57 2
	andn	ST_GIE, st	// global interrupt enable bit zeroed
	br	R_LN
d59 5
d65 3
a67 4
// Enable time slicer clock interrupts
//
// Called from C so must conform to PCS
// void SliceIntsOn(void);
a68 3
.SliceIntsOn:
	or	IIE_ETINT0, iie		// timer 0 enabled
	br	R_LN
d70 5
d76 3
a78 4
// Disable time slicer clock interrupts
//
// Called from C so must conform to PCS
// void SliceIntsOff(void);
a79 3
.SliceIntsOff:
	andn	IIE_ETINT0, iie		// timer 0 disabled
	br	R_LN
d81 10
a91 9
// Start time slicer
// 
// Initialise time slicer clock to call `SliceIntrHandler' every
// R_A1 microseconds. Once set up, the clock is reset and slicer
// interrupts are enabled.
// Assumes system stack pointer and interrupt vector table already initialised
//
// Called from C so must conform to PCS
// void StartTimeSlicer(void)
d93 3
d97 1
a97 1
	// Initialise clock interrupt and handler
d99 9
a107 2
	// Get interrupt vector table
	ldep	ivtp, ar5	// ar5 = pcs temp
d109 45
a153 46
	// Set interrupt vector for clock 0 to SliceIntrHandler
	push r11		// save return address
	laj 4			// get address of SliceIntrHandler
		ldi	SliceIntrHandler - 3, r8
		addi	r11, r8
		pop	r11
	sti	r8, *+ar5(2)	// store in clk0 interrupt vect.

	// Set up timer 0 period register
	// 33Mhz = 60.60606060 nanosecond H1 cycle time
	// timer resolution = H1 * 2 = 121.21212121 nanosecond units
	// period for 1 millisecond interrupt = 1000000 / resolution
	// In TIM-40 systems this value is calulated from ID ROM info

	// Load clock tick value for 1 millisecond
	ExecRoot ar5		// address of ExecRoot
	ldi	*ar5(XRoot_ClockTick), r8	// clock tick value
	ldhi	0x0010, ar5	// tclk0 ctrl reg address
	or 	0x0020, ar5
	sti	r8, *+ar5(8)	// store in clk0 period reg

	bud	r11		// delayed branch
		// setup clk0 control reg
		// use internal clock, reset it and let it go
		// set TCLK0 pin to general I/O output
		// set output low = access local RAM rather than TIM-40 ID ROM
		ldi	0b01011000010, r8
		sti	r8, *ar5	// store in clk0 period reg

		// enable clock 0 interrupts
		or	1, iie


// Time slicer clock interrupt handler
// 
// This is entered directly from the timer 0 interrupt vector.
// Interrupts are disabled and the return address is pointed to by
// the system stack pointer.
//
// Assumes clock 0 interrupt every millisecond.
//
// The code is organised so that the most likely set of circumstances causes
// no branches until the RETI is hit. i.e. There will usually be items on
// the timer Q, but they will not usually need waking up and the interrupt
// will not usually require the current thread to be timesliced. Also
// the minimum number of registers are stacked.
d156 1
a156 1
	// save minimal state
d158 1
a158 1
	push	ar0	// used exclusively as ExecRoot pointer
d162 2
a163 2
	// if any regs are added to the stack update this manifest
	_defp	num_regs_stacked 4
d165 56
a220 8
	// ar0 = address of ExecRoot
	ExecRoot ar0

	or	ST_SET_COND, st		// Set cond codes for all registers

        // increment ExecRoot usec timer by 1 millisecond
        // ar2 = incremented ExecRoot timer value
        ldi     *+ar0(XRoot_Timer), ar2
d222 2
a223 1
        sti     ar2, *+ar0(XRoot_Timer)
d225 10
a234 10
        // check timer Q for threads to reshedule
        // ar1 = TimerQ SaveState pointer
        ldi     *+ar0(Xroot_TimerQ), ar1
        bZ      no_wakeups 	        // empty TimerQ

        // Check if top SaveState should be woken up know
	// TimerQ SaveStates are in shortest time to wakeup order
	// if (After(xroot->Timer, ss->wakeup) goto do_wakeups
        C40WordAddress ar1              // convert ar1 BPTR to WPTR
        cmpi    *+ar1(SS_wakeup), ar2
d238 8
a245 6
	// dec ticks until slice counter
	subi	1, *+ar0(XRoot_SliceTime), ar2	// ar2 = number of ticks left
	sti	ar2, *+ar0(XRoot_SliceTime)

	// check if current thread is HIGHPRI (0). If so simply return.
	ldi	*+ar0(Xroot_CurrentPri), ar1
d248 2
a249 25
	_if _defp 'HIGHESTAVAILPRI [
		// If higher priority threads have been resumed, then we must
		// slice immediately.
		// ar1 = current pri
		cmpi	ar1, *+ar0(XRoot_HighestAvailPri)
		bLT	slice_now

		// When higher priority threads than the current one
		// are scheduled, we preemptively slice the current thread
		// before its full timeslice is completed and execute the
		// higher priority thread(s).
	]

	// If Timeslice has not yet expired then return and continue thread.
	// if (xroot->SliceTime <= 0)
	//	SliceMe();

	// ar2 = number of ticks left
	cmpi	0, ar2
	_test _defp 'HIGHESTAVAILPRI [
		bLE	check_slice	// We know we are the highest avail pri
					// if only thread on queue just continue
	][
		bLE	slice_now	// just slice
	]
d251 11
d267 1
a267 1
	retiU		// enable interrupts and return from interrupt 
a269 1

d271 1
a271 1
	push	ar3	// need a few more regs
d274 3
a276 1
	push	ar6
d279 74
a352 68
        // If we get here the ar1 == (WPTR) SaveState is due for wakeup
	// ar0 = ExecRoot
        // ar1 = TimerQ SaveState to wakeup
        // ar2 = current ExecRoot timer value

	// Remove SaveState from timer Q
        // ExecRoot->TimerQ = ss->next
        ldi     *+ar1(SS_next), ar6		// ar6 = ss->next (BPTR)
	sti     ar6, *+ar0(XRoot_TimerQ)	// xroot->TimerQ = ss->next

        // Add SaveState to the tail of its priority's run Q
        // ar2 = &ExecRoot->Queues[prioriy].tail
        addi    XRoot_Queue0.tail, ar0, ar5	// get addr. of start of run Q's
	ldi	*+ar1(SS_priority), ar3		// ar3 = priority
	// &ExecRoot->Queue[0] + priority * 2 
	addi	ar3, ar3, ar5			// ar5 = index into run Q table

	_if _defp 'HIGHESTAVAILPRI [
		// Check if new thread is higher than the HighestAvailPri
		//
		// if (xroot->HighestAvailPri < ss->priority)
		cmpi	*+ar0(XRoot_HighestAvailPri), ar3
		bGE	not_higherpri

		//	xroot->HighestAvailPri = ss->priority;
		sti	ar3, *+ar0(XRoot_HighestAvailPri)
	not_higherpri:
	]

	// Add SaveState to tail of run Q
	// do: q.tail = q.tail->next = ss
	// ar1 = SaveState (WPTR)
	// ar5 = q.tail
	C40CAddress ar1, ar4		// ar4 = (BPTR) SaveState
	C40WordAddress *ar5, ar3	// ar3 = q.tail (WPTR)
	sti	ar4, *+ar3(SS_Next)	// q.tail->next = ss
	sti	ar4, *ar5		// q.tail = ss

	// terminate Q at this SaveState
	stik	NULL, *ar1(SS_next)	// ss->next = NULL

	_test _defp 'TIMEDSUSPEND [
		// If a TimedSuspend() thread times out then it must return
		// a FALSE value to signify this. The status value must be
		// left unmolested so that concurrent Resume()'s can detect
		// that the thread is special - see Resume().

		// if (ss->status == THREAD_TIMEDWAIT)
		//	ss->CPUContext.R_A1 = FALSE;
		// else
		//	ss->status = THREAD_RUNNABLE;
		cmpi	THREAD_TIMEDWAIT, *+ar1(SS_status)
		bNE	run_status
		stik	FALSE, *+ar1(SS_CPUContext + SSCTX_R_A1)
		b	skip_run_status
	run_status:
		stik	THREAD_RUNNABLE, *+ar1(SS_status)
	skip_run_status:
	][
		// Note new thread status

		// ss->status = THREAD_RUNNABLE;
		stik	THREAD_RUNNABLE, *+ar1(SS_status)
	]

	// ar6 = ss->next at this point
	// ss = xroot->TimerQ;
        C40WordAddress ar6, ar1              // convert ar1 BPTR to WPTR
d354 1
a354 1
	// if (ss == NULL) break
d357 3
a359 3
        // Check if the new top SaveState should be woken up now
        // if (After(xroot->Timer, ss->wakeup) goto while_loop
        cmpi    *+ar1(SS_wakeup), ar2
d361 5
d368 32
a399 30
	pop	ar6
	pop	ar5
	pop	ar4
	pop	ar3

	b	no_wakeups


	_test _defp 'HIGHESTAVAILPRI [
	// We reach this point if we know that no higher priorities are
	// currently available to run. Therefore we are simply running
	// round robin in this priorities Q. Therefore if we are the only
	// thread on the Q, we can simply continue instead of slicing.
	check_slice:
		// get address of run Q for this priority into ar2
		// ar1 = current pri
		// ar2 = &ExecRoot->Queue[pri].head
	        addi    XRoot_Queue0.head, ar0, ar2	// &xroot->Queue[0].head
		addi	ar1, ar1, ar2			// ar2 =index into run Q

		// check if any other threads are at the same priority, if not
		// just continue current thread
		cmpi	NULL, *ar2++			// check if Q is empty
							// ++ points ar2 at tail
		bNE	do_slice

		// Only thread on Q so reset timeslice time and continue thread
		ldi	TICKSPERSLICE, *+aro(XRoot_SliceTime) 	
		b	IntrRet
	]
d402 6
a407 5
	// Get address of run Q for this priority into ar2
	// ar1 = current pri
	// ar2 = &ExecRoot->Queue[pri].tail
        addi    XRoot_Queue0.head, ar0, ar2		// &xroot->Queue[0].head
	addi	ar1, ar1, ar2				// ar2 =index into run Q
d410 5
a414 5
	// If we get to this point then we are going to slice the current
	// thread, add its SaveState to the appropriate run Q, save its state
	// and then jump to the Dispatch()er.
	// entered with ar0 = ExecRoot, ar1 = current pri
	// ar2 = &ExecRoot->Queue[pri].tail
d416 1
a416 1
	push	ar3	// use a few more scratch regs
d421 11
a431 10
	// place CPU context of thread into ExecRoot->CurrentSaveArea
	ldi	sp, ar6					// ar6 = old sp
	// ar1 = current threads SaveState (ss)
	C40WordAddress	*+ar0(XRoot_CurrentSaveArea), ar1
	addi	SS_CPUContext + SSCTX_PC, ar1, ar4	// ar4=ss->CPUContext.PC
	sub	num_regs_stacked + 3, ar6, ar3		// ar3 = interrupted PC
							// + 4 for stacked ar3-6
	// Move stacked state to SaveState
	// Assumes PC, ST, AR0..Ar6 are held contigously in SaveState
	ldi	*ar3++, ar5		// init first ar5 value
d433 1
a433 1
||	sti	ar5, *ar4++		// interrupt return address
d436 1
a436 1
||	sti	ar5, *ar4++		// status reg
d439 1
a439 1
||	sti	ar5, *ar4++		// ar0
d442 1
a442 1
||	sti	ar5, *ar4++		// ar1
d445 1
a445 1
||	sti	ar5, *ar4++		// ar2
d447 2
a448 2
||
	sti	ar5, *ar4++		// ar3
d451 1
a451 1
||	sti	ar5, *ar4++		// ar4
d454 1
a454 1
||	sti	ar5, *ar4++		// ar5
d457 1
a457 1
	sti	ar5, *ar4++		// store last ar5 value : ar6
d459 2
a460 2
	// stack unmolested address registers
	sti	ar7, *ar4++ 		// ar7
d462 82
a543 79
	// point stack at remainder of SaveState area
	// or: LDI AR4, SP
	addi	SS_CPUContext + SSCTX_R_A1 - 1, ar1, sp

	// PUSH unmolested registers into the SaveState.
	// Assumes these registers are held in contigous locations in the
	// SaveState. PUSH both the integer and float portions of the
	// extended-precision registers.
	push	R_A1	pushf	R_A1
	push	R_A2	pushf	R_A2
	push	R_A3	pushf	R_A3
	push	R_A4	pushf	R_A4
	push	R_V1	pushf	R_V1
	push	R_V2	pushf	R_V2
	push	R_V3	pushf	R_V3
	push	R_V4	pushf	R_V4
	push	R_T1	pushf	R_T1
	push	R_T2	pushf	R_T2
	push	R_T3	pushf	R_T3
	push	R_LR	pushf	R_LR

	// PUSH remaining registers.
	push	R_DP
	push	R_BASE
	push	R_USE
	push	R_IP
	push	R_TMP1
	push	R_TMP2
	push	R_TMP3

	// Note we never save sp, iie, and iif registers.

	// Adjust system stack pointer back to pre-interrupt position.
	// ar6 = old sp value
	subi	num_stacked_regs + 1 + 4, ar6, sp	// + 1 = past stacked PC
							// + 4 for stacked ar3-6
	// Add thread to tail of this priorities run Q.
	// do: q.tail = q.tail->next = ss
	// ar1 = SaveState (WPTR)
	// ar2 = &xroot->Queues[pri].tail
	C40CAddress ar1, ar4			// ar4 = (BPTR) SaveState
	C40WordAddress *ar2, ar3		// ar3 = q.tail (WPTR)
	sti	ar4, *+ar3(SS_Next)		// q.tail->next = ss
	sti	ar4, *ar2			// q.tail = ss

	// Terminate Q at this SaveState.
	stik	NULL, *ar1(SS_next)		// ss->next = NULL


	// Create skeleton C environment.
	// R_SP = dispatch stack for safe timer interrupt during scheduler idle
	// R_BASE = 0
	// R_A1 = NULL
	// R_USE - not needed, but set to 0 + STACKGUARD in case 
	//	stack checking enabled.
	// R_FP - not needed
	// R_MT - not needed (kernel has no module table)
	// R_LR - not needed (we will never return)

	// Get address of stack for Dispatch(). This is a small stack that
	// allows interrupts to occur safely while the dispatcher stays in its
	// idle loop.
	addi	XRoot_DispatchStack + DISPATCHSTACKSIZE - 1, ar0, R_USP

	ldi	NULL, R_A1	// NULL *SaveState argument to Dispatch()
	ldi	0, R_BASE
	ldi	PCS_STACKGUARD, R_USE

	// jump to C implementation of Dispatch()er

	b	.Dispatch



// Enable interrupts and idle until an interrupt occurs, then disable
// interrupts again and return.
//
// Called from C so must conform to PCS
// void IdleUntilInterrupt(void);
d546 3
a548 3
	idle			// enable interrupts and wait for an interrupt
	andn	ST_GIE, st	// disable interrupts globally again
	br	R_LR
d552 8
a559 7
// Initialise the root event handler
// Uses a simple approach to unify interrupt handlers across
// different processor versions of Helios (@@@@@@ trouble is its too simple at the
// moment - see notes in c40exec.doc).
//
// Called from C so must conform to PCS
// void InitEventHandler(VoidFnPtr handler);
d562 1
a562 1
	br	R_LN		// @@@@@@ currently a dummy
d566 7
a572 6
// Attach the handler function to the processors exception vector. The function
// called should form the root of the syncronous run-time signal handler.
// i.e. any address/bus errors, div by 0, etc exceptions.
//
// Called from C so must conform to PCS
// int DefineExecErrorHandler(VoidFnPtr handler);
d575 4
a578 4
	// C40 cannot do any of this so simply return!
	// @@@@@@ check out norcroft support functions - divby0()
	// this may need to call the handler!
	br	R_LN
d583 1
a583 1
// end of c40intr.a
@
