head	1.27;
access;
symbols
	Helios_C40_1_3_Official_Release:1.20
	Alenia_release:1.17
	Helios1_3:1.17
	C40_Field_Test_2:1.17
	C40_Field_Test_R1:1.14
	Helios13_beta:1.14
	Helios1_2_2_Fault:1.11
	Helios1_2_2_Native:1.10
	Helios1_2_2_native_beta:1.10
	Helios1_2_2:1.9
	Helios1_2_2Beta:1.9
	Helios1_2_1:1.7
	Helios1_2:1.7;
locks; strict;
comment	@ * @;


1.27
date	94.03.10.17.13.40;	author nickc;	state Exp;
branches;
next	1.26;

1.26
date	93.12.08.17.54.39;	author nickc;	state Exp;
branches;
next	1.25;

1.25
date	93.08.12.11.25.36;	author nickc;	state Exp;
branches;
next	1.24;

1.24
date	93.08.11.11.14.35;	author bart;	state Exp;
branches;
next	1.23;

1.23
date	93.08.06.10.19.29;	author nickc;	state Exp;
branches;
next	1.22;

1.22
date	93.08.05.18.34.59;	author bart;	state Exp;
branches;
next	1.21;

1.21
date	93.08.05.15.14.29;	author bart;	state Exp;
branches;
next	1.20;

1.20
date	93.04.14.16.13.05;	author nickc;	state Exp;
branches;
next	1.19;

1.19
date	93.01.13.11.07.56;	author bart;	state Exp;
branches;
next	1.18;

1.18
date	93.01.08.12.33.49;	author bart;	state Exp;
branches;
next	1.17;

1.17
date	92.09.09.11.44.02;	author bart;	state Exp;
branches;
next	1.16;

1.16
date	92.08.14.17.21.19;	author bart;	state Exp;
branches;
next	1.15;

1.15
date	92.07.21.11.02.39;	author bart;	state Exp;
branches;
next	1.14;

1.14
date	92.06.08.15.27.20;	author bart;	state Exp;
branches;
next	1.13;

1.13
date	92.04.24.15.43.21;	author bart;	state Exp;
branches;
next	1.12;

1.12
date	92.03.25.18.03.41;	author bart;	state Exp;
branches;
next	1.11;

1.11
date	92.01.15.11.04.39;	author bart;	state Exp;
branches;
next	1.10;

1.10
date	92.01.14.14.20.34;	author bart;	state Exp;
branches;
next	1.9;

1.9
date	91.06.03.13.24.46;	author bart;	state Exp;
branches;
next	1.8;

1.8
date	91.05.18.12.08.02;	author bart;	state Exp;
branches;
next	1.7;

1.7
date	90.12.01.15.37.21;	author bart;	state Exp;
branches;
next	1.6;

1.6
date	90.11.25.20.06.27;	author bart;	state Exp;
branches;
next	1.5;

1.5
date	90.11.01.14.57.48;	author bart;	state Exp;
branches;
next	1.4;

1.4
date	90.10.18.13.23.25;	author bart;	state Exp;
branches;
next	1.3;

1.3
date	90.09.24.18.46.07;	author bart;	state Exp;
branches;
next	1.2;

1.2
date	90.09.20.17.43.02;	author bart;	state Exp;
branches;
next	1.1;

1.1
date	90.09.12.14.54.08;	author jon;	state Exp;
branches;
next	;


desc
@@


1.27
log
@added initialisation of Nodes in SYSDEB world
@
text
@/*------------------------------------------------------------------------
--                                                                      --
--           H E L I O S   N E T W O R K I N G   S O F T W A R E	--
--           ---------------------------------------------------	--
--                                                                      --
--             Copyright (C) 1990 - 1993, Perihelion Software Ltd.      --
--                        All Rights Reserved.                          --
--                                                                      --
-- rmlib2.c								--
--                                                                      --
--	The interaction module of the Resource Management library.	--
--	This module is responsible for communication between the 	--
--	application and the various servers.				--
--                                                                      --
--	Author:  BLV 1/5/90						--
--                                                                      --
------------------------------------------------------------------------*/
/* RcsId: $Header: /hsrc/network/RCS/rmlib2.c,v 1.26 1993/12/08 17:54:39 nickc Exp nickc $*/

#define in_rmlib	1

/*{{{  Headers */
#if defined __SUN4 || defined RS6000
#include </hsrc/include/memory.h>
#include </hsrc/include/link.h>
#define _link_h
#endif
#include <stddef.h>
#include <syslib.h>
#include <stdarg.h>
#include <string.h>
#include <root.h>
#include <posix.h>
#include <gsp.h>
#include <nonansi.h>
#include <process.h>
#include <sys/socket.h>
#include <sys/un.h>
#include <pwd.h>
#include "exports.h"
#include "private.h"
#include "rmlib.h"

#ifdef Malloc		/* courtesy of servlib.h */
#undef Malloc
#endif

#ifdef RS6000
extern Environ * getenviron( void );
#endif
/*}}}*/
/*{{{  Compile time options */

#ifdef __TRAN
#pragma -f0		/* 0 == disable vector stack			*/
#pragma -g0		/* remove names from code			*/
#endif

#ifdef STACKCHECK
#pragma	-s0
#else
#pragma -s1
#endif

#ifdef STACKEXTENSION
#define RmPipeGuardian_Stack	1500
#define RmDoSynch_Stack		750
#else
#define RmPipeGuardian_Stack	3000
#define RmDoSynch_Stack		1000
#endif

/*}}}*/
/*{{{  Miscellaneous utilities */

/*{{{  FullRead */

/**
*** A little utility routine to cope with the fact that pipe reads do
*** not necessarily return the amount of data requested.
**/
int FullRead(Stream *pipe, BYTE *buffer, int amount, word timeout)
{ int	read = 0;
  int	temp;

  forever  
  { temp = (int) Read(pipe, &(buffer[read]), ((word)amount - (word)read), timeout);
    if ((temp < 0) || ((temp eq 0) && (timeout eq -1)))
     return((read eq 0) ? temp : read);
    read += temp;
    if (read >= (word)amount) return(read);
    if (timeout ne -1) return(read);
  }
}

/*}}}*/
/*{{{  RmLookupProcessor() */
/**
*** Given a network, look up the processor. 
*** Arguments : Network, the root structure or a subnet
***             name, something like Cluster/00
*** 
*** The routine determines the last bit of the name, e.g. 00, and
*** searches the network. When a processor is reached whose ID matches
*** this last bit of the name, the search goes back up the tree trying
*** to match all the parents.
**/
static int	LookupAux1(RmProcessor, ...);

RmProcessor	RmLookupProcessor(RmNetwork Network, char *name)
{ char		*temp = name + strlen(name);

  if (*name eq '/') name++;  
  for ( ; (temp >= name) && (*temp ne '/'); temp--);

  return((RmProcessor) RmSearchProcessors(Network, &LookupAux1, name, ++temp));
}

static int LookupAux1(RmProcessor Processor, ...)
{ va_list	args;
  char		*name;
  char		*last_name;
  RmNetwork	current;
  RmNetwork	root_net;
  int		amount;
      
  va_start(args, Processor);
  name		= va_arg(args, char *);
  last_name	= va_arg(args, char *);
  va_end(args);

	/* Unless the last bit matches, do not bother to check */  
  if (strcmp(RmGetProcessorId(Processor), last_name)) return(0);

  current	= (RmNetwork) Processor;
  root_net	= RmRootNetwork(Processor);
  
  while (last_name > name)	/* If name is 00, match is immediate	*/
   { last_name--; last_name--;  /* Skip the / and get to last char	*/
     for ( amount = 0; (last_name >= name) && (*last_name ne '/'); 
           last_name--, amount++);
     last_name++;		/* should now be Cluster */
     current = RmParentNetwork((RmProcessor) current);
     if (current eq (RmNetwork) NULL) return(0);

     if ((current eq root_net) && (RmRootName ne NULL))
      { if (strncmp(RmRootName, last_name, amount)) return(0);
      }
     else
      { if (strncmp(current->DirNode.Name, last_name, amount)) return(0); 
      }
   }
  return((int) Processor);
}
/*}}}*/
#ifdef __HELIOS
/*{{{  RmBuildProcessorName() and RmMapProcessorToObject() */

/**
*** 1) RmBuildProcessorName(): given a suitable buffer of IOCDataMax bytes, 
***    and a processor that is part of a network, construct the full pathname
***    of the processor
**/
char *RmBuildProcessorName(char *buffer, RmProcessor processor)
{ const char *name;

  if ((processor eq NULL) ||
      ((processor->ObjNode.Type ne Type_Processor) && (processor->ObjNode.Type ne Type_Network)))
   { RmErrno = RmE_NotProcessor; return(NULL); }

  if (processor eq (RmProcessor) RmRootNetwork(processor))
   { *buffer++ = '/';
     if (RmRootName ne NULL)
      strcpy(buffer, RmRootName);
     else
      strcpy(buffer, processor->ObjNode.Name);
     return(&(buffer[strlen(buffer)]));
   }
  else
   { buffer = RmBuildProcessorName(buffer, (RmProcessor) RmParentNetwork(processor));
     *buffer++ = '/';
     for (name = processor->ObjNode.Name; *name ne '\0'; ) *buffer++ = *name++;
     *buffer = '\0';
     return(buffer);
   }
}

/**
*** 2) RmMapProcessorToObject(): given a processor that is part of a real
***    network, return a Helios Object structure corresponding to this
***    processor and containing the appropriate capability.
**/
Object	*RmMapProcessorToObject(RmProcessor processor)
{ char		*buf; 
  Object	*result;
  Capability	*cap;
  bool		newbuf = FALSE;

  CheckProcessorFail(processor, Null(Object));  

  if ((processor->StructType ne RmL_Obtained) &&
      (processor->StructType ne RmL_Existing))
   return(RmErrno = processor->Errno = RmE_NoAccess, Null(Object));
  cap = &(processor->RealCap);

  if (processor->ObjNode.Parent ne Null(DirNode))
   {   /* This processor is in an RmNetwork, build the name using the network */
     buf = (char *) Malloc(IOCDataMax);
     if (buf eq Null(char))
      return(RmErrno = processor->Errno = RmE_NoMemory, Null(Object));
     newbuf = TRUE;
     (void) RmBuildProcessorName(buf, processor);
   }
  else
   { 
     buf = RmGetObjectAttribute((RmObject) processor, "PUID", TRUE);
     if (buf eq Null(char))
      return(RmErrno = processor->Errno = RmE_NotNetwork, Null(Object));
   }
  if (*((int *) cap) eq 0)
   result = Locate(Null(Object), buf);
  else
   result = NewObject(buf, cap);

  if (newbuf) Free(buf);
  if (result eq Null(Object))
   RmErrno = processor->Errno = RmE_NotFound;
  return(result);
}

/*}}}*/
/*{{{  my_objname */
	/* Why is this in the Server Library !"@@$%^&*	*/
char	*my_objname(char *name)
{ char	*tmp = name + strlen(name);
  until( (*tmp eq c_dirchar) || (tmp < name)) tmp--;
  return(tmp + 1);
}
/*}}}*/
/*{{{  Name and user id handling */
/**
*** RmWhoAmI() and RmWhoIs(). These are used to examine the user id's
*** returned by the previous routine, and map onto posix calls -
*** eventually.
**/
int RmWhoAmI(void)
{ Environ	*env		= getenviron();
  Object	*session;
  int		i;
  char		username[NameMax];
  char		*temp;
  struct passwd	*passwd;
  
	/* First, get hold of the environment and the Session object */    
  if (env eq Null(Environ)) return(-1);
  if (env->Objv eq Null(Object *)) return(-1);
  for (i = 0; i <= OV_Session; i++)
   if (env->Objv[i] eq Null(Object))
    return(0);
 
  session = env->Objv[OV_Session];
  if (session eq (Object *) MinInt) return(-1);

	/* Get the last bit of the session name, which should be the username */
  temp = session->Name + strlen(session->Name);
  for ( ; *temp ne '/'; temp--);
  strcpy(username, ++temp);

	/* Strip out .12 at the end, if present */
  for (temp = username + strlen(username); temp > username; temp--)
   if (*temp eq '.')
    { *temp = '\0'; break; }

  passwd =  getpwnam(username);
  if (passwd eq Null(struct passwd))
   return(0);

  return(passwd->pw_uid);
}

const char *RmWhoIs(int uid)
{ struct passwd	*passwd;

  if (uid eq RmO_SystemPool)	return("free pool");
  if (uid eq RmO_System)	return("system");
  if (uid eq RmO_Cleaners)	return("cleaners");
  if (uid eq RmO_Graveyard)	return("graveyard");

  passwd = getpwuid(uid);
  if (passwd eq Null(struct passwd))
   return("<unknown>");
  else
   return(passwd->pw_name);
}
/*}}}*/
/*{{{  Error handling */
/**-----------------------------------------------------------------------------
*** Error manipulation, this is about as bad a place as any to have this routine
**/
const	char	*RmMapErrorToString(int err)
{ switch(err)
   { case RmE_Success		: return("success");
     case RmE_NotProcessor	: return("NotProcessor, argument is not a valid processor");
     case RmE_NotTask		: return("NotTask, argument is not a valid task");
     case RmE_NotNetwork	: return("NotNetwork, argument is not a network");
     case RmE_NotTaskforce	: return("NotTaskforce, argument is not a taskforce");
     case RmE_WrongNetwork	: return("WrongNetwork, this network is inappropriate");
     case RmE_WrongTaskforce	: return("WrongTaskforce, this taskforce is inappropriate");
     case RmE_InUse		: return("InUse, some object is currently in use");
     case RmE_Corruption	: return("Corruption, there appears to be memory corruption");
     case RmE_ReadOnly		: return("ReadOnly, the object cannot be modified");
     case RmE_BadArgument	: return("BadArgument, one of the arguments was invalid");
     case RmE_NoMemory		: return("NoMemory, there is not enough memory on the local processor");
     case RmE_NotFound		: return("NotFound, a search failed");
     case RmE_TooLong		: return("TooLong, a string argument was too large");
     case RmE_NotRootNetwork	: return("NotRootNetwork, the operation cannot be performed on a subnet");
     case RmE_NoAccess		: return("NoAccess, the application has not obtained access");
     case RmE_OldStyle		: return("OldStyle, please recompile your resource map");
     case RmE_BadFile		: return("BadFile, the file contains invalid data");
     case RmE_CommsBreakdown	: return("CommsBreakdown, the application failed to communicate properly with a server");
     case RmE_Skip		: return("Skip, a large container for refuse etc.");
     case RmE_NotRootTaskforce	: return("NotRootTaskforce, the operation cannot be performed on a sub-taskforce");
     case RmE_MissingServer	: return("MissingServer, an essential server could not be found");
     case RmE_PartialSuccess	: return("PartialSuccess, the operation did not succeed completely");
     case RmE_BadLink		: return("BadLink, the specified link does not exist");
     case RmE_BadProcessor	: return("BadProcessor, this processor is currently unusable");
     case RmE_BadChannel	: return("BadChannel, the specified channel does not exist");
     case RmE_YouMustBeJoking	: return("YouMustBeJoking, not currently implemented");
     case RmE_ServerMemory	: return("ServerMemory, a server ran out of memory");
     case RmE_NotPossible	: return("NotPossible, hardware limitation");
     case RmE_NoResource	: return("NoResource, not enough free resources");
     default			: return("<unknown error>");
   }
}
/*}}}*/
#endif

/*}}}*/
#ifdef __HELIOS
/*{{{  Client-server communication */

     static bool RmOpenDefaultServer(RmServer *);
     static void RmPipeGuardian(RmServer);

/*{{{  General description */
/**
*** Communication requirements for the networking software. Bi-directional
*** communication is required for the following:
***
*** Taskforce Manager	<-> Network Server
*** Session Manager	<-> Network Server
*** Application		<-> Network Server (read-only, all clever jobs have)
***			   		   (to be validated by the TFM     )
*** Application		<-> Taskforce Manager
*** Application		<-> Session Manager
*** Special		<-> e.g. one Network Server to another for joinnet
***
*** The data to be transmitted is very variable. The most common data is
*** networks, processors, taskforces, and tasks, which are best transmitted
*** using fifo's or pipes. Other data includes timestamps, task termination
*** details, exception handling for crashed processors and aborted tasks,
*** and so on.
***
*** For future portability and for reliability Unix domain sockets are used
*** for all communication. This is not particularly efficient, for example
*** it involves an extra thread running in both the server and the client,
*** but that is a penalty I am willing to pay for now. For Helios 2.x it
*** may be desirable to switch to virtual channels, as the software is
*** careful not to rely on select() or similar features. The actual
*** communication is via Syslib Reads and Writes, to get timeouts.
***
*** For now, any application including the networking servers typically
*** has upto two streams open : one to the Network Server, read-only,
*** to implement routines such as RmGetNetwork(); and one to the ``parent''. 
*** For the Taskforce Manager and the Session Manager this parent is the
*** Network Server. For everything else this parent is the session's 
*** Taskforce Manager. The library multiplexes all interactions down 
*** these stream. In future it may be necessary/desirable to include the
*** Session Manager and Batch Server as programs using this facility.
***
*** The following routines are used for the communication :
***  1) RmJob	RmNewJob(server);
*** 	 If the connection has not yet been opened, this routine does so. It
***      returns a pointer to a suitable structure, useful for other routines.
***  2) Stream	*RmLockWrite(RmJob);
***	 This routine gets exclusive access to the stream, and returns it
***	 for whatever the caller wants to do, e.g. write a network structure.
***  3) void	RmUnlockWrite(RmJob);
***      This routine releases the exclusive access
***  4) Stream	*RmLockRead(RmConn);
***	 This routine is used only inside the servers, to wait for data
***	 arriving on the stream.
***  5) Stream	*RmSwitchLockRead(RmJob);
***	 This routine releases the exclusive write access as before and
***	 waits on a semaphore for the reply to arrive. It returns the
***	 Stream pointer so that the caller can read all the reply data.
***  6) void	RmUnlockRead(RmJob);
***	 This implies that the read is finished.
***  7) void	RmFinishJob(RmJob);
***	 This routine is called once the operation has finished. It does
***	 not close the Stream to the server, because that stream may be
***	 shared with other jobs.
***  8) int	RmTx(RmJob, RmRequest);
***	 Send a fairly arbitrary request
***  9) int	RmRx(RmJob, RmReply);
***	 Receive a fairly arbitrary reply
*** 10) int RmXch(server, RmRequest *, RmReply)
***	 Create a new job, send a request, receive a reply, finish the job
***
*** The implementation involves link guardian-style processes waiting at
*** both ends of the connection for incoming packets. Every packet starts
*** with a unique identifier, indicating the particular job.
*** There are special synchronisation packets to ensure
*** that both sides are still alive.
***
*** The servers can associate resources with stream connections. For example,
*** if an application has obtained a network of processors and exits without
*** releasing them, the resulting close request generated by the system
*** library will cause the server to reclaim the resources.
***
*** In addition to RmNewJob(), there is a routine RmOpenServer().
*** This opens the stream to the specified server. It is used by special
*** programs such as mergenet, that need to interact with a specific Network
*** Server. The corresponding routine, RmCloseServer(), is used to terminate.
***
*** Consider a vaguely typical piece of code: RmGetNetwork(). This would
*** perform the following steps.
***	1) RmNewJob(&RmNetworkServer);
***	2) RmLockWrite(Job);
***	3) send the request code for RmGetNetwork()
***	4) RmSwitchLockRead(Job)
***		(this suspends the routine until the reply arrives)
***	5) read the reply, success or failure
***	6) RmUnlockRead(Job)
***	7) RmFinishedJob(Job)
**/
/*}}}*/
/*{{{  Basic job handling */

/**
*** RmNewJob(). Given an open RmServer to the Network Server, Session
*** Manager, or Parent, or to some application-defined Server, this routine
*** allocates a new RmConn structure and adds it to the list of known
*** connections using this server. For the three default servers the
*** stream may not have been opened yet. Hence I have to pass the address
*** of the RmServer pointer, not the pointer itself, so that I can compare
*** this with the three basic addresses. This allows me to OpenServer()
*** the right thingy.
**/

int	RmNewJob(RmServer *server, RmJob *job_ptr)
{ RmJob	new_job	= (RmJob)Malloc(sizeof(RmJobStruct));

  if (new_job eq (RmJob)NULL)
   return(RmErrno = RmE_NoMemory);
  
  if (*server eq (RmServer)NULL)
   unless(RmOpenDefaultServer(server))
    { Free(new_job); return(RmErrno = RmE_MissingServer); }
 
  Wait(&((*server)->StructLock));
  new_job->Id		= (*server)->MaxId++;
  new_job->Server	= *server;
  new_job->WriteLocked	= FALSE;
  new_job->ReadLocked	= FALSE;
  new_job->KeepLocked	= FALSE;  
  InitSemaphore(&(new_job->Wait), 0);
#ifdef SYSDEB
  new_job->Node.Next = new_job->Node.Prev = &new_job->Node;
#endif
  AddTail(&((*server)->Jobs), &(new_job->Node));
  Signal(&((*server)->StructLock));
  *job_ptr = new_job;
  return(RmE_Success);
}

/**
*** Undo the effects of a NewJob. Very easy, just remove the
*** thingy from its linked list after suitable locking and free it.
**/
void	RmFinishedJob(RmJob job)
{ RmServer	server = job->Server;

  if (job->WriteLocked)
   { IOdebug("RmLib Job Error : id %d, write still locked", job->Id);
     Signal(&(server->WriteLock));
   }
  if (job->ReadLocked)
   { IOdebug("RmLib Job Error : id %d, read still locked", job->Id);
     Signal(&(server->PipeGuardian));
   }
  Wait(&(server->StructLock));
  Remove(&(job->Node));
  Signal(&(server->StructLock));
  Free(job);  
}

/**
*** The various locking operations. These are all very basic.
**/
Stream	*RmLockWrite(RmJob job)
{ RmServer	server = job->Server;
  Stream	*pipe;

  Wait(&(server->WriteLock));
  job->WriteLocked	= TRUE;
  pipe			= server->Pipe_ctos;
  		
	/* The connection ID is sent automatically, the application does */
	/* not have to worry about it.	*/
  if (Write(pipe, (BYTE *) &(job->Id), sizeof(int), -1) ne sizeof(int))
   return(Null(Stream));

  return(pipe);
}

void	RmUnlockWrite(RmJob job)
{ RmServer	server = job->Server;
  Signal(&(server->WriteLock));
  job->WriteLocked = FALSE;
}

Stream	*RmLockRead(RmJob job)
{ RmServer	server = job->Server;

  Wait(&(job->Wait));		/* Triggered by RmPipeGuardian */
  job->ReadLocked = FALSE;
  return(server->Pipe_stoc);
}

Stream	*RmSwitchLockRead(RmJob job)
{ RmServer	server = job->Server;

  if (!job->WriteLocked)
   IOdebug("RmLib job error : switching lock while write unlocked");
  else   
   { Signal(&(server->WriteLock));
     job->WriteLocked = FALSE;
   }
   
  Wait(&(job->Wait));
  job->ReadLocked = TRUE;
  return(server->Pipe_stoc);
}

void	RmUnlockRead(RmJob job)
{ RmServer	server = job->Server;
  if (!job->ReadLocked)
   IOdebug("RmLib job error, unlocking read lock that has not been set");
  Signal(&(server->PipeGuardian));
  job->ReadLocked = FALSE;
}

/*}}}*/
/*{{{  Connecting to servers */

/**
*** RmOpenServer(). This attempts to set up the basic connection
*** between a client and a networking server. All communication between that
*** client and that server will share this connection.
***
*** An RmServerStruct structure is allocated and initialised. Then an attempt
*** is made to connect to the named socket, which should be something like
*** /.NS_ctos. If successful the name is manipulated to the
*** complement stream, e.g. /.NS_stoc, to get a stream for the
*** other direction. To support fault tolerance timed-out communication is
*** required, hence the Helios Streams are extracted and stored as well.
***
*** Following the connections there is some initial communication to ensure
*** that the sockets really have been set up. If this works a PipeGuardian
*** thread is spawned off to handle messages sent by the server.
**/

int	RmOpenServer(char *sockserv, char *name, Capability *cap, RmServer *server_ptr)
{ RmServer 		server	= (RmServer)NULL;
  struct sockaddr_un	address;
  Stream		*sock;
  int			len;
  Capability		local_cap;
  int			rc = RmE_Success;

  if ((name eq Null(char)) || (server_ptr eq Null(RmServer)))
   return(RmErrno = RmE_MissingServer);

  if (sockserv eq Null(char)) sockserv = "/.socket";

	/* The RmServer structure, allocate and initialise */
  server		= (RmServer)Malloc(sizeof(RmServerStruct));
  if (server eq (RmServer) NULL) return(RmErrno = RmE_NoMemory);

  InitSemaphore(&(server->WriteLock), 1);
  server->MaxId		= 1;
  InitSemaphore(&(server->StructLock), 1);
  InitSemaphore(&(server->PipeGuardian), 0);
  InitList(&(server->Jobs));
  server->Socket_ctos	= Null(Stream);
  server->Socket_stoc	= Null(Stream);
  server->Pipe_ctos	= Null(Stream);
  server->Pipe_stoc	= Null(Stream);

  sock = Socket(sockserv, SOCK_STREAM, 0);
  if (sock eq Null(Stream))
   { rc = RmE_NoMemory; goto fail; }

  address.sun_family	= AF_UNIX;
  strcpy(address.sun_path, name);
  len = sizeof(address.sun_family) + strlen(address.sun_path) + 1;

  if (Connect(sock, (BYTE *) &address, len) < Err_Null)
   { rc = RmE_MissingServer; goto fail; }

  server->Socket_ctos	= sock;
  server->Pipe_ctos	= sock;

	/* hack the _ctos to _stoc	*/
  strcpy(address.sun_path, name);  
  len = strlen(address.sun_path);
  address.sun_path[len - 1]	= 'c';
  address.sun_path[len - 4]	= 's';
  address.sun_family	= AF_UNIX;
  len = sizeof(address.sun_family) + strlen(address.sun_path) + 1;

	/* create another socket for the reverse direction	*/
  sock = Socket(sockserv, SOCK_STREAM, 0);
  if (sock eq Null(Stream))
   { rc = RmE_NoMemory; goto fail; }

  if (Connect(sock, (BYTE *) &address, len) < Err_Null)
   { rc = RmE_NoMemory; goto fail; }

  server->Socket_stoc	= sock;
  server->Pipe_stoc	= sock;

  if (cap eq Null(Capability))
   { memset(&local_cap, 0, sizeof(Capability)); cap = &local_cap; }

  if (Write(server->Pipe_ctos, (BYTE *) cap, sizeof(Capability), 10 * OneSec)
	ne sizeof(Capability))
   { rc = RmE_CommsBreakdown; goto fail; }

  if (Write(server->Pipe_ctos, (BYTE *) &RmProgram, sizeof(int), 10 * OneSec)
	ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto fail; }

  if (Read(server->Pipe_stoc, (BYTE *) &len, sizeof(int), 10 * OneSec)
	ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto fail; }

	/* Fork() off the pipe guardian process, to wait for data */
  unless(Fork(RmPipeGuardian_Stack, RmPipeGuardian, 4, server))
   { rc = RmE_NoMemory; goto fail; }

  *server_ptr = server;
  return(RmE_Success);

fail:
  if (server ne (RmServer) NULL)
   { if (server->Socket_ctos ne Null(Stream))
      Close(server->Socket_ctos);
     if (server->Socket_stoc ne Null(Stream))
      Close(server->Socket_stoc);
     Free(server);
   }

  return(rc);
}

/**
*** RmCloseServer(). This does the inverse operation to RmOpenServer()
*** above. It is legal only iff there are no outstanding connections
*** using this RmServer. Closing the RmServer requires terminating
*** the PipeGuardian process, which is non-trivial. It can be handled
*** by close'ing the Stream originally Open'ed to the server, which causes
*** the server to send a terminate message down the pipe and the terminate
*** message is interpreted by the PipeGuardian. This assumes that the
*** Close always gets through...
**/

int	RmCloseServer(RmServer server)
{ 
  if (server eq (RmServer) NULL) return(RmE_Success);
  Wait(&(server->StructLock));
  unless(EmptyList_(server->Jobs))
   { Signal(&(server->StructLock)); return(RmErrno = RmE_InUse); }

  server->Pipe_stoc	= Null(Stream);
  server->Pipe_ctos	= Null(Stream);
  if (server->Socket_stoc ne Null(Stream))
   { Close(server->Socket_stoc);
     server->Socket_stoc	= Null(Stream);
   }
  if (server->Socket_ctos ne Null(Stream))
   { Close(server->Socket_ctos);
     server->Socket_ctos	= Null(Stream);
   }
  Signal(&(server->StructLock));
  Delay(2 * OneSec);
  return(RmE_Success);
}

/**
*** This routine is invoked automatically when the application attempts
*** to connect to one of the default servers for the first time. These
*** default servers can be the Network Server, the Session Manager, and
*** the ``parent''. For the first two no special authority is required.
*** The parent is trickier. The Network Server does not have a parent.
*** The parent for the Session Manager and for a Taskforce Manager is the
*** Network Server, and a suitable capability should have been installed.
*** The parent for user applications is the Taskforce
*** Manager, and there should be an Object entry in the environment.
**/
static bool	RmOpenDefaultServer(RmServer *server_ptr)
{ char		*name;
  char		*path	= Null(char);
  Capability	*cap;
  char		path_buf[109];	/* size <- <sys/un.h> */
  char		name_buf[NameMax + 8];

  if (server_ptr eq &RmNetworkServer)
   { name = ".NS_ctos";
     if ((RmProgram eq Rm_Session) || (RmProgram eq Rm_TFM))
      cap = &RmLib_Cap;
     else
      cap = Null(Capability);
   }
  elif (server_ptr eq &RmSessionManager)
   { name = ".SM_ctos"; cap = Null(Capability); }
  elif (server_ptr eq &RmParent)
   switch (RmProgram)
    { case Rm_Netserv	: return(FALSE);

      case Rm_Session	:
      case Rm_TFM	: if (RmNetworkServer ne (RmServer) NULL)
			   { RmParent = RmNetworkServer; return(TRUE); }
			  name = ".NS_ctos";
			  cap  = &RmLib_Cap;
			  break;
			  
      case Rm_User	:
      default		:
      			  { Environ	*env = getenviron();
			    char	*temp;
			    int		i;

			    if (env eq Null(Environ))		return(FALSE);
			    if (env->Objv eq Null(Object *))	return(FALSE);
			    for (i = 0; i <= OV_TFM; i++)
			     if (env->Objv[i] eq Null(Object))
			      return(FALSE);
			    if (env->Objv[OV_TFM] ne (Object *) MinInt)
			     cap = &(env->Objv[OV_TFM]->Access);
			    else
			     cap = NULL;
			    path = path_buf; name = name_buf;

				/* /Cluster/01/bart.1/tfm		 */
				/* -> /Cluster/01/.socket, .bart.1._ctos */
			    strcpy(path, env->Objv[OV_TFM]->Name);
			    name[0] = '.';
			    temp = objname(path);
			    *--temp = '\0';
			    temp = objname(path);
			    strcpy(&(name[1]), temp);
			    strcpy(temp, ".socket");
			    strcat(name, "_ctos");
				/* -> /Cluster/01/.socket, .bart.1_ctos	*/
			  }
			  break;
    }
  else
   return(FALSE);

  if (RmOpenServer(path, name, cap, server_ptr) eq RmE_Success)
    return(TRUE);
  else
   return(FALSE);
}

/*}}}*/
/*{{{  The Pipe Guardian */

/**
*** The PipeGuardian(). This is a little process Fork()'ed off when Opening
*** a Stream to a Server. It waits on the pipe for incoming packets. These
*** may be messages aimed at the PipeGuardian itself, such as synchronisation,
*** termination, or exceptions. Alternatively they may be aimed at some
*** other process that has an open connection using this stream. A search
*** is made to find the connection, and that connection is Signalled to
*** wake up the process. The pipe guardian now releases the pipe stream to
*** that process, and waits for that process to read all the data it is
*** expecting.
**/
static	int	RmMatchJob(RmJob job, int id);
static  int	RmAbortJob(RmJob job);
static	void	RmDoSynch(RmServer);
static	void	RmDoDup2(RmServer);

static	void RmPipeGuardian(RmServer server)
{ Stream *pipe	= server->Pipe_stoc;
  int	 id;

#ifndef __TRAN
  SetPriority(HighServerPri);
#endif

  forever
   { word result;

     result = FullRead(pipe, (BYTE *) &id, sizeof(int), 30 * OneSec);

     if (result eq 4)   /* Success */
      { 
        if (id & RmR_Private)
         { 
	   if ((id & ~RmR_Private) eq RmR_Terminate)
            break;
           elif ((id & ~RmR_Private) eq RmR_Synch)
            continue;
	   elif ((id & ~RmR_Private) eq RmR_Dup2)
	    RmDoDup2(server);
           else
            { int	size;
	      BYTE	*data;
	      result = FullRead(pipe, (BYTE *) &size, sizeof(int), 30 * OneSec);
	      if (result ne 4) break;
	      data = (BYTE *)Malloc(size);
	      if (data eq NULL) break;
	      result = FullRead(pipe, data, size, 30 * OneSec);
	      if (result != size) break;
	      if (RmExceptionHandler ne (VoidFnPtr) NULL)
	       { unless(Fork(RmExceptionStack, RmExceptionHandler,
			12, id, size, data))
		  Free(data);
	       }
	      else
	       Free(data);
	    }
         }
        else
         { RmJob	job;
           Wait(&(server->StructLock));
	   job = (RmJob)
	      SearchList(&(server->Jobs), (WordFnPtr) &RmMatchJob, id);
	   Signal(&(server->StructLock));
	   if (job eq (RmJob) NULL)
	    break;
	   Signal(&(job->Wait));
	   Wait(&(server->PipeGuardian));
	 } 
      }
     elif (result eq 0)		/* timeout */
      { if (server->Pipe_ctos eq Null(Stream)) break;
      	(void) Fork(RmDoSynch_Stack, &RmDoSynch, 4, server);
      }
     else
      { word rc2 = Result2(pipe);
	if ((rc2 eq ReadRc_EOF) || ((rc2 & EC_Mask) > EC_Warn))
	 break;
      }
   }

 (void) WalkList(&(server->Jobs), (WordFnPtr) &RmAbortJob);
  RmCloseServer(server);
  Free(server);
}

static	int	RmMatchJob(RmJob job, int id)
{ if (job->Id eq id)
   return(1);
  else
   return(0);
}

static int	RmAbortJob(RmJob job)
{ Signal(&(job->Wait));
  return(0);
}

static void RmDoSynch(RmServer server)
{ int	rc = RmR_Private + RmR_Synch;

  Wait(&(server->WriteLock));
  (void) Write(server->Pipe_ctos, (BYTE *) &rc, sizeof(int), 10 * OneSec);
  Signal(&(server->WriteLock));
}

/**
*** This code is intended to support parallel libraries such as the
*** farm library. The TFM has received a request to update a taskforce
*** or convert a task to a taskforce. As part of handling this request
*** it has to make this task open additional channels. Any requests that
*** may require this should set the RmC_KeepLocked flag to ensure that
*** no other requests are sent to the TFM at the same time.
**/
static void RmDoDup2(RmServer server)
{ Dup2Details	 details;
  Stream	*stream;
  bool		 success	= FALSE;
  int		 fd;

	/* Receive the file descriptor that this task should		*/
	/* open, followed by the name of the stream. The latter		*/
	/* incorporates a capability.					*/
  Read(server->Pipe_stoc, (BYTE *) &details, sizeof(Dup2Details), -1);
  stream = Open(cdobj(), details.Name, O_ReadWrite);
  if (stream eq NULL) goto done;

	/* Now turn the Stream into a file descriptor. If necessary use	*/
	/* dup2() to ensure that the right file descriptor is used.	*/
  fd = sopen(stream);
  if (fd < 0)
   { Close(stream); goto done; }
  if (fd ne details.FileDescriptor)
   { int res = dup2(fd, details.FileDescriptor);
     close(fd);
     if (res eq details.FileDescriptor)
      success = TRUE;
    }
   else
    success = TRUE;

done:
  Write(server->Pipe_ctos, (BYTE *) &success, sizeof(bool), -1);
}

/*}}}*/
/*{{{  RmTx, RmRx, RmXch */

/**
*** General Rmlib->Server Communication routines
**/
int RmTx(RmJob job, RmRequest *request)
{ Stream	*pipe = RmLockWrite(job);
  int		rc;

#if 0
IOdebug("RmTx: FnRc %x, Network %x, Taskforce %x, Processor %x, Task %x, size %d",
		request->FnRc, request->Network, request->Taskforce,
		request->Processor, request->Task,
		request->VariableSize);
#endif

  if (request->FnRc & RmC_KeepLocked)
   { job->KeepLocked = TRUE; request->FnRc &= ~RmC_KeepLocked; }

  if (Write(pipe, (BYTE *) request, sizeof(RmRequest), -1) ne sizeof(RmRequest))
   { rc = RmE_CommsBreakdown; goto fail; }

  if ((request->Network ne (RmNetwork) NULL) ||
      (request->Taskforce ne (RmTaskforce) NULL))
   if ((rc = RmWriteStream(pipe, request->Network, request->Taskforce,
			request->Filter)) ne RmE_Success)
    goto fail;

  if (request->Processor ne (RmProcessor) NULL)
   if ((rc = RmWriteProcessor(pipe, request->Processor, FALSE)) ne RmE_Success)
    goto fail;

  if (request->Task ne (RmTask) NULL)
   if ((rc = RmWriteTask(pipe, request->Task, FALSE)) ne RmE_Success)
    goto fail;

  if (request->VariableSize > 0)
   if (Write(pipe, request->VariableData, request->VariableSize, -1)
	ne request->VariableSize)
    { rc = RmE_CommsBreakdown; goto fail; }

  return(RmE_Success);

fail:
#ifdef SYSDEB
  IOdebug("RmTx: failed to send request down pipe %s", pipe->Name);
#endif
  RmUnlockWrite(job);
  return(rc);
}

int RmRx(RmJob job, RmReply *reply)
{ Stream	*pipe;
  int		rc;
  BYTE		*vardata = reply->VariableData;

  if (job->KeepLocked)
   pipe = RmLockRead(job);
  else
   pipe = RmSwitchLockRead(job);

  if (FullRead(pipe, (BYTE *) reply, sizeof(RmReply), -1) ne sizeof(RmReply))
   { rc = RmE_CommsBreakdown; goto fail; }

#if 0
IOdebug("RmRx: FnRc %x, Network %x, Taskforce %x, Processor %x, Task %x, size %d",
		reply->FnRc, reply->Network, reply->Taskforce,
		reply->Processor, reply->Task, reply->VariableSize);
#endif

  if ((reply->Network ne (RmNetwork) NULL) ||
      (reply->Taskforce ne (RmTaskforce) NULL))
   if ((rc = RmReadStream(pipe, &(reply->Network), &(reply->Taskforce)))
       ne RmE_Success)
    goto fail;

  if (reply->Processor ne (RmProcessor) NULL)
   if ((rc = RmReadProcessor(pipe, &(reply->Processor), FALSE))
       ne RmE_Success)
    goto fail;

  if (reply->Task ne (RmTask) NULL)
   if ((rc = RmReadTask(pipe, &(reply->Task), FALSE))
       ne RmE_Success)
    goto fail;

  if (reply->VariableSize > 0)
   { if (vardata eq NULL)
      { vardata = reply->VariableData = (char *)Malloc(reply->VariableSize);
        if (vardata eq NULL)
         { rc = RmE_NoMemory; goto fail; }
      }
     if (FullRead(pipe, vardata, reply->VariableSize, -1) ne reply->VariableSize)
      { rc = RmE_CommsBreakdown; goto fail; }
   }

  if (job->KeepLocked) RmUnlockWrite(job);
  RmUnlockRead(job);
  return(reply->FnRc);

fail:
#ifdef SYSDEB
  IOdebug("RmRx: failed to receive reply from pipe %s", pipe->Name);
#endif
  if (job->KeepLocked) RmUnlockWrite(job);
  RmUnlockRead(job);
  return(rc);
}

int RmXch(RmServer *Server, RmRequest *request, RmReply *reply)
{ RmJob	job;
  int	rc = RmNewJob(Server, &job);

  if (rc ne RmE_Success) return(rc);
  rc = RmTx(job, request);
  if (rc eq RmE_Success)
   rc = RmRx(job, reply);
  RmFinishedJob(job);
  return(rc);
}

/*}}}*/

/*}}}*/
#endif
/*{{{  Stream I/O */

/**-----------------------------------------------------------------------------
*** Stream I/O. The ``user'' routines are RmRead() and RmWrite(),
*** which take filenames. The routines attempt to open the actual files,
*** and call lower-level routines RmReadStream() and RmWriteStream().
*** These are implemented using yet lower level routines. All of these
*** are accessible but not documented.
**/
/*{{{  byte swapping, if needed */
#ifndef HOSTISBIGENDIAN
#define SWAP(a)
#else
int swap(byte *x)
{ union { int x; byte y[4]; } a;

  a.y[3] = *x++;
  a.y[2] = *x++;
  a.y[1] = *x++;
  a.y[0] = *x;
  return(a.x);
}

#define SWAP(a) (*(int *)(&(a))) = swap((byte *) &(a));
#endif
/*}}}*/
/*{{{  RmRead(), RmWrite() */
int RmRead(char *filename, RmNetwork *Network, RmTaskforce *Taskforce)
{ Stream 	*stream;
  Object 	*file;
  int	 	rc;
  Environ	*env = getenviron();
  
  if (filename eq Null(char))
   return(RmErrno = RmE_BadArgument);
  if ((Network eq Null(RmNetwork)) && (Taskforce eq Null(RmTaskforce)))
   return(RmErrno = RmE_BadArgument);
  file = Locate(env->Objv[0], filename);
  if (file eq Null(Object))
   { word rc = Result2(env->Objv[0]);
     if ((rc & EG_Mask) eq EG_Protected)
      return(RmErrno = RmE_NoAccess);
     elif ((rc & EG_Mask) eq EG_NoMemory)
      return(RmErrno = RmE_NoMemory);
     else
      return(RmErrno = RmE_NotFound);
   }      
  stream = Open(file, Null(char), O_ReadOnly);
  (void) Close(file);
  if (stream eq Null(Stream))
   return(RmErrno = RmE_NoMemory);
  rc = RmReadStream(stream, Network, Taskforce);
  (void) Close(stream);
  return(rc);  
}

int RmWrite(char *filename, RmNetwork Network, RmTaskforce Taskforce)
{ Stream	*stream;
  int		rc;
  RmFilterStruct filter;
  Environ	*env = getenviron();
    
  filter.Network	= NULL;
  filter.Processor	= NULL;  
  filter.Taskforce	= NULL;
  filter.Task		= NULL;
  filter.SendHardware	= TRUE;
  
  if (filename eq Null(char))
   return(RmErrno = RmE_BadArgument);
  if ((Network eq (RmNetwork)NULL) && (Taskforce eq (RmTaskforce)NULL))
   return(RmErrno = RmE_BadArgument);
  if (Network ne (RmNetwork) NULL)
   if (Network->DirNode.Type ne Type_Network)
    return(RmErrno = RmE_NotNetwork);
  if (Taskforce ne (RmTaskforce) NULL)
   if (Taskforce->DirNode.Type ne Type_Taskforce)
    return(RmErrno = RmE_NotTaskforce);    

  stream = Open(env->Objv[0], filename, O_WriteOnly + O_Create + O_Truncate);
  if (stream eq Null(Stream))
   { word res = Result2(env->Objv[0]);
     if ((res & EG_Mask) eq EG_NoMemory)
      return(RmErrno = RmE_NoMemory);
     elif ((res & EG_Mask) eq EG_Protected)
      return(RmErrno = RmE_NoAccess);
     else
      return(RmErrno = RmE_BadFile);
   }
  rc = RmWriteStream(stream, Network, Taskforce, &filter);
  (void) Close(stream);
  return(rc);
}
/*}}}*/
/*{{{  RmReadStream(), RmWriteStream() */
/**
*** The next two routines, RmReadStream() and RmWriteStream(), are called
*** mostly from inside Helios software. Hence there is no checking.
***
*** The first three words of a saved file contain the following:
*** a version number, a bool to indicate whether or not there is a network,
*** and a bool to indicate whether or not there is a taskforce. These
*** 12 bytes are read in one go. If this test is passed calls are made to
*** yet lower level routines to do the real work.
**/
static	int	UpdateMapping(RmTask, ...);

int RmReadStream(Stream *stream, RmNetwork *Network, RmTaskforce *Taskforce)
{ int		junk[3];
  RmNetwork	LocalNetwork;
  RmTaskforce	LocalTaskforce;
  int		rc;

  if (FullRead(stream, (BYTE *) junk, 3 * sizeof(int), -1) ne (3 * sizeof(int)))
   return(RmErrno = RmE_BadFile);
  SWAP(junk[0]) SWAP(junk[1]) SWAP(junk[2])

  if (junk[0] eq 0x06)	/* old-style resource map */
   return(RmErrno = RmE_OldStyle);
	/* 7 was used in Helios 1.2.2 for resource map binaries */
  if ((junk[0] ne 0x07)	&& (junk[0] ne RmLib_Magic))
   return(RmErrno = RmE_BadFile);
   
  if (junk[1])		/* There is a Network in the file */
   { if (Network eq Null(RmNetwork))	/* but it should be discarded */
      { rc = RmReadNetwork(stream, &LocalNetwork, FALSE);
        if (rc eq RmE_Success)
         (void) RmFreeNetwork(LocalNetwork);
        else
         return(rc);
      }
     else
      { rc = RmReadNetwork(stream, Network, FALSE);
        if (rc ne RmE_Success)
         return(rc);
      }
   }
  else	/* No network, but the user expected one */
   { if (Network ne Null(RmNetwork))
      *Network = (RmNetwork)NULL;
   }
      
  if (junk[2])	/* Similarly for the Taskforce */
   { if (Taskforce eq Null(RmTaskforce))
      { rc = RmReadTaskforce(stream, &LocalTaskforce, FALSE);
        if (rc eq RmE_Success)
         (void) RmFreeTaskforce(LocalTaskforce);
        else
         return(rc);
      }
     else
      { rc = RmReadTaskforce(stream, Taskforce, FALSE);
        if (rc ne RmE_Success) return(rc);
        (void) RmApplyTasks(*Taskforce, &UpdateMapping, *Network);
      }
   }
  else
   { if (Taskforce ne Null(RmTaskforce))
      *Taskforce = (RmTaskforce) NULL;
   }
   
  return(RmE_Success);
}

int RmWriteStream(Stream *stream, RmNetwork Network, RmTaskforce Taskforce,
		RmFilter filter)
{ int	junk[3];
  int	rc;
  
  junk[0] = (int) RmLib_Magic;
  junk[1] = (Network ne (RmNetwork) NULL);
  junk[2] = (Taskforce ne (RmTaskforce) NULL);

  SWAP(junk[0]) SWAP(junk[1]) SWAP(junk[2])

  if (Write(stream, (BYTE *) junk, 3 * sizeof(int), -1) ne (3 * sizeof(int)))
   return(RmErrno = RmE_BadFile);
   
  if (Network ne (RmNetwork) NULL)
   if ((rc = RmWriteNetwork(stream, Network, filter)) ne RmE_Success)
    return(rc);

  if (Taskforce ne (RmTaskforce) NULL)
   if ((rc = RmWriteTaskforce(stream, Taskforce, filter)) ne RmE_Success)
    return(rc);
    
  return(RmE_Success);
}

/**
*** Update the task->processor mapping. If a taskforce is part of the
*** file then every component task has to be updated. If there is no
*** network then the task cannot be mapped. Otherwise the task must be
*** mapped onto the right processor.
**/
static	int	UpdateMapping(RmTask task, ...)
{ va_list	args;
  RmNetwork	network;
  RmProcessor	processor;

  va_start(args, task);
  network = va_arg(args, RmNetwork);
  va_end(args);
  
  if (network eq (RmNetwork) NULL) return(0);
   
  if (task->MappedTo ne RmL_NoUid)
   { processor = RmFindProcessor(network, task->MappedTo);
     task->MappedTo = RmL_NoUid;
     if (processor ne (RmProcessor) NULL)
      if (RmMapTask(processor, task) ne RmE_Success)
       { IOdebug("RmLib: internal error, failed to map task onto processor");
       }
   }
  return(0);
}
/*}}}*/
/*{{{  RmReadNetwork() */

/**
*** Every object in the file is preceeded by a type, in this  case
*** Type_Network or Type_File. This allows RmReadProcessor below to
*** read a single word, check the type, and if necessary call 
*** RmReadNetwork() recursively. Unfortunately the type has now been
*** read, and I do not want to Seek() back because that will fail on
*** pipes. Hence I use a third argument to say whether or not this
*** routine has been called recursively.
**/
static	int	RmReadRoot(RmSet);
static	int	RmReadResets(Stream *, RmNetwork, int);
static  void	RmTidyNetworkRead(RmNetwork);

int RmReadNetwork(Stream *stream, RmNetwork *NetworkPtr, bool recursive)
{ RmNetwork	Network;
  RmSet		root;
  int		rc;
  int		i;
  int		resets;

  if (!recursive)
   { int type;
     if (FullRead(stream, (BYTE *) &type, sizeof(int), -1) ne sizeof(int))
      return(RmErrno = RmE_BadFile);
     SWAP(type)
     if (type ne Type_Network)
      return(RmErrno = RmE_NotNetwork);
   }

  Network = *NetworkPtr = (RmNetwork) Malloc(sizeof(RmNetworkStruct));
  if (Network eq (RmNetwork) NULL)
   return(RmErrno = RmE_NoMemory);
  if (FullRead(stream, (BYTE *) Network, sizeof(RmNetworkStruct), -1) ne
  		sizeof(RmNetworkStruct))
   { Free(Network); *NetworkPtr = NULL; return(RmErrno = RmE_BadFile); }

  SWAP(Network->DirNode.Type)
  SWAP(Network->DirNode.Flags)
  SWAP(Network->DirNode.Key)
  SWAP(Network->DirNode.Dates.Creation)
  SWAP(Network->DirNode.Dates.Access)
  SWAP(Network->DirNode.Dates.Modified)
  SWAP(Network->DirNode.Account)
  SWAP(Network->DirNode.Nentries)
  SWAP(Network->Private)
  SWAP(Network->NoTables)
  SWAP(Network->Private2)
  SWAP(Network->Errno)

  resets			= (int) Network->Hardware.Head;
  SWAP(resets)
  InitList(&(Network->Hardware));
  root				= Network->Root;
  Network->Root			= NULL;
  Network->DirNode.Node.Next	= NULL;
  Network->DirNode.Node.Prev	= NULL;
  Network->DirNode.Parent	= NULL;
  InitSemaphore(&(Network->DirNode.Lock), 1);
  InitList(&(Network->DirNode.Entries));

  if (resets > 0)
   if ((rc = RmReadResets(stream, Network, resets)) ne RmE_Success)
    goto error;
    
	/* When writing the root, the pointer is set to NULL */
	/* There is also some special work to be done to sort out the Uid */
	/* tables. */
  if (root eq (RmSet) NULL)
   { Network->Root = (RmSet) Network;
     if ((rc = RmReadRoot((RmSet) Network)) ne RmE_Success)
      { Free(Network); *NetworkPtr = NULL; return(rc); }
   }

  for (i = 0; i < Network->DirNode.Nentries; i++)
   { int type;
     if (FullRead(stream, (BYTE *) &type, sizeof(int), -1) ne sizeof(int))
      { rc = RmE_BadFile; Network->DirNode.Nentries = i; goto error; }
     SWAP(type)
     if (type eq Type_Network)
      { RmNetwork	Subnet;
        if ((rc = RmReadNetwork(stream, &Subnet, TRUE)) ne RmE_Success)
         { rc = RmE_BadFile; Network->DirNode.Nentries = i; goto error; }
        AddTail(&(Network->DirNode.Entries), &(Subnet->DirNode.Node));
        Subnet->DirNode.Parent = &(Network->DirNode);
      }
     elif (type eq Type_Processor)
      { RmProcessor	Processor;
        if ((rc = RmReadProcessor(stream, &Processor, TRUE)) ne RmE_Success)
         { Network->DirNode.Nentries = i; goto error; }
        AddTail(&(Network->DirNode.Entries), &(Processor->ObjNode.Node));
        Processor->ObjNode.Parent = &(Network->DirNode);
      }
     else
      { rc = RmE_BadFile; Network->DirNode.Nentries = i; goto error; }
   }

  if (Network->Root eq (RmSet) Network)
   RmTidyNetworkRead(Network);
   
  return(RmE_Success);
  
error:
  RmFreeNetwork(Network);
  *NetworkPtr = NULL;
  RmErrno = rc;
  return(rc);
}

/**
*** For now I do not bother to ship the UID tables with the root structures,
*** because they do not appear to be needed. Hence all this routine does is
*** allocate space for the tables.
**/
static int RmReadRoot(RmSet Set)
{ int 	NoTables	= Set->NoTables;
  Set->NoTables		= 0;
  Set->Tables		= Null(RmUidTableEntry *);
  
  while(NoTables-- > 0)
   unless(RmExtendFreeQ(Set))
    return(RmErrno = RmE_NoMemory);
  return(RmE_Success);
}

/**
*** The file contains count RmHardwareFacility structures, each followed by
*** a suitable table. The table contains Uid's rather than pointers, a
*** problem that is resolved later. The AddHardwareFacility() routine
***is used, which makes a duplicate of the RmHardwareFacility structure.
**/

static int	RmReadResets(Stream *stream, RmNetwork Network, int count)
{ RmHardwareFacility	Reset;
  int			*table;
  int			rc;
      
  while(count-- > 0)
   { if (FullRead(stream, (BYTE *) &Reset, sizeof(RmHardwareFacility), -1) ne
   	 sizeof(RmHardwareFacility))
      return(RmErrno = RmE_BadFile);
     SWAP(Reset.Type)
     SWAP(Reset.NumberProcessors)
     SWAP(Reset.Essential)
     table = (int *) Malloc(sizeof(int) * (word) Reset.NumberProcessors);
     if (table eq Null(int))
      return(RmErrno = RmE_NoMemory);
     if (FullRead(stream, (BYTE *) table, sizeof(int) * Reset.NumberProcessors, -1)
              ne (sizeof(int) * Reset.NumberProcessors))
      { Free(table); return(RmErrno = RmE_BadFile); }
     Reset.Processors = (RmProcessor *) table;
#ifdef HOSTISBIGENDIAN
     { int i;
       for (i = 0; i < Reset.NumberProcessors; i++)
        SWAP(table[i])
     }
#endif
     rc = RmAddHardwareFacility(Network, &Reset);
     Free(table);
     if (rc ne RmE_Success)
      return(RmErrno = rc);
   }
  return(RmE_Success);
}

/**
*** Once the whole network has been read in, some tidying up is required.
*** In particular, all objects need to have the Root set; all processors
*** should install their pointers in the Uid tables; and all reset and
*** configuration drivers should have their Uid's converted to pointers.
*** These three steps are done by two different RmApplyNetwork()'s
**/

static	int	RmTidyNetworkAux1(RmProcessor Processor, ...);
static	int	RmTidyNetworkAux2(RmProcessor Processor, ...);
static	int	RmTidyHardwareFacility(RmHardwareFacility *Reset, ...);

static	void	RmTidyNetworkRead(RmNetwork Network)
{ (void) RmApplyNetwork(Network, &RmTidyNetworkAux1, Network);
  (void) RmApplyNetwork(Network, &RmTidyNetworkAux2, Network);
  (void) RmApplyHardwareFacilities(Network, &RmTidyHardwareFacility, Network);
}

/**
*** If the object is a network, simply fill in the root and recurse.
***
*** Otherwise fill in the root and obtain the Uid.
**/
static	int	RmTidyNetworkAux1(RmProcessor Processor, ...)
{ va_list	args;
  RmNetwork	Root;

  va_start(args, Processor);
  Root	= va_arg(args, RmNetwork);
  va_end(args);
  if (RmIsNetwork(Processor))
   { RmNetwork	Network = (RmNetwork) Processor;
     Network->Root	= (RmSet) Root;  
     (void) RmApplyNetwork(Network, &RmTidyNetworkAux1, Root);
   }
  else
   { Processor->Root	= Root;
     (void) RmObtainUid((RmSet) Root, (RmObject) Processor);
   }
  return(0);
}

/**
*** This routine takes care of reset facilities and configure drivers held
*** in sub-networks.
**/
static	int	RmTidyNetworkAux2(RmProcessor Processor, ...)
{ va_list	args;
  RmNetwork	Root;
  
  va_start(args, Processor);
  Root	= va_arg(args, RmNetwork);
  va_end(args);
  
  if (RmIsNetwork(Processor))
   { RmNetwork Network	= (RmNetwork) Processor;
     (void) RmApplyHardwareFacilities(Network, &RmTidyHardwareFacility, Root);
     (void) RmApplyNetwork(Network, &RmTidyNetworkAux2, Root);
   }
  return(0);
}

/**
*** This routine take all the reset facilities and configure drivers
*** held in a network, and map the Uid's currently stored in the tables
*** onto the real pointers.
**/
static int	RmTidyHardwareFacility(RmHardwareFacility *Reset, ...)
{ va_list	args;
  RmNetwork	Root;
  RmProcessor	*Table;
  int		i;
  
  va_start(args, Reset);
  Root	= va_arg(args, RmNetwork);
  va_end(args);
  
  Table = Reset->Processors;
  for (i = 0; i < Reset->NumberProcessors; i++)
    Table[i] = RmFindProcessor(Root, (int) Table[i]);
  return(0);
}

/*}}}*/
/*{{{  RmWriteNetwork() */

/**
*** Clearly RmWriteNetwork() has to be kept closely in step with
*** RmReadNetwork(). The possibility exists of having a filter function
*** to do things to the RmNetwork structure. Hence there is an auxiliary
*** routine RmWriteRmNetworkStruct() which copies the structure onto the
*** stack, applies some filtering, and does the actual write.
**/

static	int	RmWriteNetworkStruct(Stream *stream, RmNetwork Network,
			RmFilter filter);
static	int	RmWriteResets(Stream *Stream, RmNetwork Network);
static	int	RmWriteNetworkContents(RmProcessor Processor, ...);

/**
*** Step 1 : write Type_Network
***      2 : write the RmNetwork struct itself, suitably filtered
***      3 : write the reset drivers if any
***      4 : ditto for the contents
***      5 : write the contents
**/
int RmWriteNetwork(Stream *stream, RmNetwork Network, RmFilter filter)
{ int	rc;

  if ((rc = RmWriteNetworkStruct(stream, Network, filter)) eq RmE_Success)
   { 
     if (filter ne (RmFilter) NULL)
      if (filter->SendHardware)   
       if ((rc = RmWriteResets(stream, Network)) ne RmE_Success)
        return(RmErrno = rc);
     return(RmSearchNetwork(Network, &RmWriteNetworkContents, stream, filter));
   }
  elif (rc eq RmE_Skip)
   return(RmE_Success);
  else
   return(RmErrno = rc);
}

/**
*** RmWriteNetworkStruct(). This makes a copy of the RmNetwork structure
*** onto the stack, performs some filtering, and writes it out.
*** Automatic filtering includes zapping the Root pointer if this is
*** the root, for recognition purposes, and figuring out the number of
*** reset facilities and configuration drivers.
**/
static int	RmWriteNetworkStruct(Stream *stream, RmNetwork Network,
					RmFilter filter)
{ RmNetworkStruct	copy;
  int			filter_result = RmE_Success;
  word			type = Type_Network;
      
  memcpy((void *) &copy, (void *) Network, sizeof(RmNetworkStruct));
  if (Network->Root eq (RmSet) Network)
   copy.Root = (RmSet) NULL;
  
  copy.Hardware.Head = 0;
 
  if (filter ne (RmFilter) NULL)
   { if (filter->SendHardware) 
      { int resets;
	Node *Reset = Network->Hardware.Head;
	for (resets = 0; !EndOfList_(Reset); resets++)
	 Reset = Reset->Next;
	SWAP(resets)
        copy.Hardware.Head = (Node *) resets;
      }
   }
  
  if (filter ne (RmFilter) NULL)
   if (filter->Network ne NULL)
    filter_result = (*(filter->Network))(Network, &copy);

  if (filter_result ne RmE_Success)
   return(filter_result);

  SWAP(type)
  SWAP(copy.DirNode.Type)
  SWAP(copy.DirNode.Flags)
  SWAP(copy.DirNode.Key)
  SWAP(copy.DirNode.Dates.Creation)
  SWAP(copy.DirNode.Dates.Access)
  SWAP(copy.DirNode.Dates.Modified)
  SWAP(copy.DirNode.Account)
  SWAP(copy.DirNode.Nentries)
  SWAP(copy.Private)
  SWAP(copy.NoTables)
  SWAP(copy.Private2)
  SWAP(copy.Errno)

  if (Write(stream, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
   return(RmErrno = RmE_BadFile);

  if (Write(stream, (BYTE *) &copy, sizeof(RmNetworkStruct), -1) ne
  		sizeof(RmNetworkStruct))
      return(RmErrno = RmE_BadFile);

  return(RmE_Success);
}

/**
*** RmWriteNetworkContents() is applied to the various entries in a network.
*** These may of course be subnets or processors.
**/
static int	RmWriteNetworkContents(RmProcessor Processor, ...)
{ va_list	args;
  Stream	*stream;
  RmFilter	filter;
    
  va_start(args, Processor);
  stream = va_arg(args, Stream *);
  filter = va_arg(args, RmFilter);
  va_end(args);
  
  if (RmIsNetwork(Processor))
   return(RmWriteNetwork(stream, (RmNetwork) Processor, filter));
  else
   return(RmWriteProcessor(stream, Processor, filter));
}

/**
*** Reset and configuration drivers. Transmitting these involves two stages.
*** First the HardwareFacility structure itself is transmitted.
*** Then a new table is allocated for all the Processors, and the Uid's
*** are put into this table. It is this table, not the table of pointers,
*** that gets transmitted.
**/
static int	RmWriteHardware(RmHardwareFacility *reset, ...)
{ RmUid		*table;
  va_list	args;
  Stream	*stream;
  int		i;
  int		rc = RmE_Success;
  word		x;

  va_start(args, reset);
  stream = va_arg(args, Stream *);
  va_end(args);
  
  if (reset->NumberProcessors eq 0) return(RmE_Success);
  table = (RmUid *) Malloc(sizeof(int) * (word) reset->NumberProcessors);
  if (table eq Null(RmUid)) return(RmErrno = RmE_NoMemory);
  for (i = 0; i < reset->NumberProcessors; i++)
  {
    table[i] = reset->Processors[i]->Uid;
    SWAP(table[i])
  }

  SWAP(reset->Type)
  SWAP(reset->NumberProcessors)
  SWAP(reset->Essential)

  x = Write(stream, (BYTE *) reset, sizeof(RmHardwareFacility), -1);
  SWAP(reset->Type)
  SWAP(reset->NumberProcessors)
  SWAP(reset->Essential)

  if (x ne sizeof(RmHardwareFacility))
   { rc = RmE_BadFile; goto done; }

  if (Write(stream, (BYTE *) table, sizeof(int) * (word) reset->NumberProcessors, -1)
  	ne (sizeof(int) * (word) reset->NumberProcessors))
   rc = RmE_BadFile;

done:
  Free(table);
  if (rc ne RmE_Success)
   RmErrno = rc;
  return(rc);
}

static int	RmWriteResets(Stream *stream, RmNetwork Network)
{ return( RmSearchHardwareFacilities(Network, &RmWriteHardware, stream));
}

/*}}}*/
/*{{{  RmReadProcessor() */

/**
*** A Processor consists of the following bits.
***
*** 1) an RmProcessorStruct
*** 2) possibly the OtherLinks
*** 3) possibly the Attributes and private attributes
***
*** The third argument to RmReadProcessor() indicates whether or not the
*** initial word giving the object type has been read yet, or not.
*** No conversion is needed for any of the connections or things like that,
*** because of the Uid mechanism.
**/

int RmReadProcessor(Stream *stream, RmProcessor *ProcessorPtr, bool recurse)
{ RmProcessor Processor = (RmProcessor)Malloc(sizeof(RmProcessorStruct));
  int rc = RmE_Success;

  if (Processor eq (RmProcessor) NULL) return(RmErrno = RmE_NoMemory);
  
  if (!recurse)
   { WORD type;
     if (FullRead(stream, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
      { rc = RmE_BadFile; goto done; }
     SWAP(type)
     if (type ne Type_Processor)
      { rc = RmE_BadFile; goto done; }
   }
   
  if (FullRead(stream, (BYTE *) Processor, sizeof(RmProcessorStruct), -1) ne
      sizeof(RmProcessorStruct))
   { rc = RmE_BadFile; goto done; }

  SWAP(Processor->ObjNode.Type)
  SWAP(Processor->ObjNode.Flags)
  SWAP(Processor->ObjNode.Key)
  SWAP(Processor->ObjNode.Dates.Creation)
  SWAP(Processor->ObjNode.Dates.Access)
  SWAP(Processor->ObjNode.Dates.Modified)
  SWAP(Processor->ObjNode.Account)
  SWAP(Processor->ObjNode.Size)
  SWAP(Processor->Private)
  SWAP(Processor->Uid)
  SWAP(Processor->Connections)
  SWAP(Processor->AttribSize)
  SWAP(Processor->AttribFree)
  SWAP(Processor->PAttribSize)
  SWAP(Processor->PAttribFree)
  SWAP(Processor->MemorySize)
  SWAP(Processor->Type)
  SWAP(Processor->MappedTo)
  SWAP(Processor->Private2)
  SWAP(Processor->Errno)
  SWAP(Processor->SessionId)
  SWAP(Processor->ApplicationId)

  InitSemaphore(&(Processor->ObjNode.Lock), 1);   
  Processor->OtherLinks = Null(RmLink);
  InitList(&(Processor->MappedTasks));
  Processor->Root		= NULL; 
  Processor->AttribData		= NULL;
  Processor->PAttribData	= NULL;
  Processor->ObjNode.Node.Next	= NULL;
  Processor->ObjNode.Node.Prev	= NULL;
  Processor->ObjNode.Parent	= NULL;
  InitList(&(Processor->ObjNode.Contents));

	/* After the 1.2 release I decided to move the Purpose field.	*/  
	/* This hack maintains binary compatibility of resource maps.	*/
  if ((Processor->ObjNode.Size & 0x0F) ne 0)
   { switch(Processor->ObjNode.Size & 0x0F)
      { case	1 : Processor->Purpose = RmP_Helios; break;
        case	2 : Processor->Purpose = RmP_System | RmP_Helios; break;
        case	3 : Processor->Purpose = RmP_IO; break;
        case	4 : Processor->Purpose = RmP_System | RmP_Native; break;
      }
     Processor->ObjNode.Size &= ~0x0F;
   }
   
  if (Processor->Connections > 4)
   { int size = (Processor->Connections - 4) * sizeof(RmLink);
     Processor->OtherLinks = (RmLink *) Malloc(size);
     if (Processor->OtherLinks eq Null(RmLink))
      { rc = RmE_NoMemory; goto done; }
     if (FullRead(stream, (BYTE *) Processor->OtherLinks, size, -1) ne size)
      { rc = RmE_BadFile; goto done; }
   }
#ifdef HOSTISBIGENDIAN
   { int i;
     for (i = 0; i < Processor->Connections; i++)
      { RmLink *link = RmFindLink(Processor, i);
        SWAP(link->Destination)
        SWAP(link->Target)
      }
   }
#endif

  if (Processor->AttribSize ne 0)
   { Processor->AttribData = (char *) Malloc(Processor->AttribSize);
     if (Processor->AttribData eq Null(char))
      { rc = RmE_NoMemory; goto done; }
     if (FullRead(stream, (BYTE *) Processor->AttribData, Processor->AttribSize,
     			-1) ne Processor->AttribSize)
      { rc = RmE_BadFile; goto done; }

   }

  if (Processor->PAttribSize ne 0)
   { Processor->PAttribData = (char *) Malloc(Processor->PAttribSize);
     if (Processor->PAttribData eq Null(char))
      { rc = RmE_NoMemory; goto done; }
     if (FullRead(stream, (BYTE *) Processor->PAttribData, Processor->PAttribSize,
     			-1) ne Processor->PAttribSize)
      { rc = RmE_BadFile; goto done; }
   }
   
done:      
  if (rc ne RmE_Success)
   { if (Processor ne (RmProcessor)NULL)
      { if (Processor->OtherLinks ne NULL)  Free(Processor->OtherLinks);
	if (Processor->AttribData ne NULL)  Free(Processor->AttribData);
	if (Processor->PAttribData ne NULL) Free(Processor->PAttribData);
        Free(Processor);
      }
     *ProcessorPtr = (RmProcessor) NULL;
     RmErrno = RmE_Success;
   }
  else
   *ProcessorPtr = Processor;
   
  return(rc);
}

/*}}}*/
/*{{{  RmWriteProcessor() */
/**
*** The inverse operation to the above, allowing for the usual filtering.
*** N.B. There is no way of filtering the OtherLinks or the Attributes.
**/
int RmWriteProcessor(Stream *stream, RmProcessor Processor, RmFilter filter)
{ RmProcessorStruct	LocalProcessor;
  int			rc;
  WORD			type;

  memcpy((void *) &LocalProcessor, (void *) Processor,
  		 sizeof(RmProcessorStruct));
  if (filter ne (RmFilter) NULL)
   if (filter->Processor ne NULL)
    { rc = (*(filter->Processor))(Processor ,&LocalProcessor);
      if (rc eq RmE_Skip)
       return(RmE_Success);
      elif (rc ne RmE_Success)
       return(RmErrno = rc);
    }

  type = Type_Processor;

  SWAP(type)
  SWAP(LocalProcessor.ObjNode.Type)
  SWAP(LocalProcessor.ObjNode.Flags)
  SWAP(LocalProcessor.ObjNode.Key)
  SWAP(LocalProcessor.ObjNode.Dates.Creation)
  SWAP(LocalProcessor.ObjNode.Dates.Access)
  SWAP(LocalProcessor.ObjNode.Dates.Modified)
  SWAP(LocalProcessor.ObjNode.Account)
  SWAP(LocalProcessor.ObjNode.Size)
  SWAP(LocalProcessor.Private)
  SWAP(LocalProcessor.Uid)
  SWAP(LocalProcessor.Connections)
  SWAP(LocalProcessor.AttribSize)
  SWAP(LocalProcessor.AttribFree)
  SWAP(LocalProcessor.PAttribSize)
  SWAP(LocalProcessor.PAttribFree)
  SWAP(LocalProcessor.MemorySize)
  SWAP(LocalProcessor.Type)
  SWAP(LocalProcessor.MappedTo)
  SWAP(LocalProcessor.Private2)
  SWAP(LocalProcessor.Errno)
  SWAP(LocalProcessor.SessionId)
  SWAP(LocalProcessor.ApplicationId)
  SWAP(LocalProcessor.DefaultLinks[0].Destination)
  SWAP(LocalProcessor.DefaultLinks[0].Target)
  SWAP(LocalProcessor.DefaultLinks[1].Destination)
  SWAP(LocalProcessor.DefaultLinks[1].Target)
  SWAP(LocalProcessor.DefaultLinks[2].Destination)
  SWAP(LocalProcessor.DefaultLinks[2].Target)
  SWAP(LocalProcessor.DefaultLinks[3].Destination)
  SWAP(LocalProcessor.DefaultLinks[3].Target)
    
  if (Write(stream, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
   return(RmErrno = RmE_BadFile);

  if (Write(stream, (BYTE *) &LocalProcessor, sizeof(RmProcessorStruct), -1)
  		ne sizeof(RmProcessorStruct))
   return(RmErrno = RmE_BadFile);

  SWAP(LocalProcessor.Connections)
  SWAP(LocalProcessor.AttribSize)
  SWAP(LocalProcessor.PAttribSize)

#ifdef HOSTISBIGENDIAN
  if (LocalProcessor.Connections > 4)
   { int	 i;
     RmLink	*link;
     for (i = 4; i < LocalProcessor.Connections; i++)
     { link = RmFindLink(Processor, i);
       SWAP(link->Destination);
       SWAP(link->Target);
     }
   }
#endif
       
  if (LocalProcessor.Connections > 4)
   { int size = (LocalProcessor.Connections - 4) * sizeof(RmLink);
     if (Write(stream, (BYTE *) LocalProcessor.OtherLinks, size, -1) ne size)
      return(RmErrno = RmE_BadFile);
   }

#ifdef HOSTISBIGENDIAN
  if (LocalProcessor.Connections > 4)
   { int		 i;
     RmLink	*link;
     for (i = 4; i < LocalProcessor.Connections; i++)
     { link = RmFindLink(Processor, i);
       SWAP(link->Destination);
       SWAP(link->Target);
     }
   }
#endif

  if (LocalProcessor.AttribSize > 0)
   if (Write(stream, LocalProcessor.AttribData, LocalProcessor.AttribSize, -1)
	ne LocalProcessor.AttribSize)
    return(RmErrno = RmE_BadFile);          

  if (LocalProcessor.PAttribSize > 0)
   if (Write(stream, LocalProcessor.PAttribData, LocalProcessor.PAttribSize, -1)
	ne LocalProcessor.PAttribSize)
    return(RmErrno = RmE_BadFile);          

  return(RmE_Success);
}
/*}}}*/
/*{{{  RmReadTaskforce() */

/**
*** RmReadTaskforce() etc. are based closely on RmReadNetwork. There is
*** no need to worry about reset drivers or anything like that.
**/
static void RmTidyTaskforceRead(RmTaskforce Taskforce);

int RmReadTaskforce(Stream *stream, RmTaskforce *TaskforcePtr, bool recursive)
{ RmTaskforce	Taskforce;
  RmSet		root;
  int	   	rc;
  int	    	i;

  if (!recursive)
   { WORD type;
     if (FullRead(stream, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
      return(RmErrno = RmE_BadFile);
     SWAP(type)
     if (type ne Type_Taskforce)
      return(RmErrno = RmE_NotTaskforce);
   }

  Taskforce = *TaskforcePtr = (RmTaskforce) Malloc(sizeof(RmTaskforceStruct));
  if (Taskforce eq (RmTaskforce) NULL) return(RmErrno = RmE_NoMemory);

  if (FullRead(stream, (BYTE *) Taskforce, sizeof(RmTaskforceStruct), -1) ne
  		sizeof(RmTaskforceStruct))
   { Free(Taskforce); return(RmErrno = RmE_BadFile); }

  SWAP(Taskforce->DirNode.Type)
  SWAP(Taskforce->DirNode.Flags)
  SWAP(Taskforce->DirNode.Key)
  SWAP(Taskforce->DirNode.Dates.Creation)
  SWAP(Taskforce->DirNode.Dates.Access)
  SWAP(Taskforce->DirNode.Dates.Modified)
  SWAP(Taskforce->DirNode.Account)
  SWAP(Taskforce->DirNode.Nentries)
  SWAP(Taskforce->Private)
  SWAP(Taskforce->NoTables)
  SWAP(Taskforce->Private2)
  SWAP(Taskforce->Errno)
  SWAP(Taskforce->ReturnCode)
  SWAP(Taskforce->State)

  InitSemaphore(&(Taskforce->DirNode.Lock), 1);
  InitList(&(Taskforce->DirNode.Entries));
  Taskforce->DirNode.Parent	= NULL;
  Taskforce->DirNode.Node.Next	= NULL;
  Taskforce->DirNode.Node.Prev	= NULL;
  root				= Taskforce->Root;
  Taskforce->Root		= NULL;
     
	/* When writing the root, the pointer is set to NULL */
	/* There is also some special work to be done to sort out the Uid */
	/* tables. */
  if (root eq (RmSet) NULL)
   { Taskforce->Root = (RmSet) Taskforce;
     if ((rc = RmReadRoot((RmSet) Taskforce)) ne RmE_Success)
      { Free(Taskforce); return(RmErrno = rc); }
   }

  for (i = 0; i < Taskforce->DirNode.Nentries; i++)
   { WORD type;
     if (FullRead(stream, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
      { rc = RmE_BadFile; Taskforce->DirNode.Nentries = i; goto error; }
     SWAP(type)

     if (type eq Type_Taskforce)
      { RmTaskforce SubTaskforce;
        if ((rc = RmReadTaskforce(stream, &SubTaskforce, TRUE)) ne RmE_Success)
         { rc = RmE_BadFile; Taskforce->DirNode.Nentries = i; goto error; }
        AddTail(&(Taskforce->DirNode.Entries), &(SubTaskforce->DirNode.Node));
        SubTaskforce->DirNode.Parent = &(Taskforce->DirNode);
      }
     elif (type eq Type_Task)
      { RmTask		Task;
        if ((rc = RmReadTask(stream, &Task, TRUE)) ne RmE_Success)
         { Taskforce->DirNode.Nentries = i; goto error; }
        AddTail(&(Taskforce->DirNode.Entries), &(Task->ObjNode.Node));
        Task->ObjNode.Parent = &(Taskforce->DirNode);
      }
     else
      { rc = RmE_BadFile; Taskforce->DirNode.Nentries = i; goto error; }
   }

  if (Taskforce->Root eq (RmSet) Taskforce)
   RmTidyTaskforceRead(Taskforce);
   
  return(RmE_Success);
  
error:
  RmFreeTaskforce(Taskforce);
  return(RmErrno = rc);
}

static  int	RmTidyTaskforceAux1(RmTask, ...);

static	void	RmTidyTaskforceRead(RmTaskforce Taskforce)
{ (void) RmApplyTaskforce(Taskforce, &RmTidyTaskforceAux1, Taskforce);
}

static	int	RmTidyTaskforceAux1(RmTask Task, ...)
{ va_list	args;
  RmTaskforce	Root;

  va_start(args, Task);
  Root	= va_arg(args, RmTaskforce);
  va_end(args);
  if (RmIsTaskforce(Task))
   { RmTaskforce Taskforce	= (RmTaskforce) Task;
     Taskforce->Root		= (RmSet) Root;  
     (void) RmApplyTaskforce(Taskforce, &RmTidyTaskforceAux1, Root);
   }
  else
   { Task->Root	= Root;
     (void) RmObtainUid((RmSet) Root, (RmObject) Task);
   }
  return(0);
}

/*}}}*/
/*{{{  RmWriteTaskforce() */

static int	RmWriteTaskforceStruct(Stream *stream, RmTaskforce Taskforce,
			RmFilter filter);
static int	RmWriteTaskforceContents(RmTask Task, ...);

int RmWriteTaskforce(Stream *stream, RmTaskforce Taskforce, RmFilter filter)
{ int	rc;

  if ((rc = RmWriteTaskforceStruct(stream, Taskforce, filter)) eq RmE_Success)
   { 
     return(RmSearchTaskforce(Taskforce, &RmWriteTaskforceContents,
     		 stream, filter));
   }
  elif (rc eq RmE_Skip)
   return(RmE_Success);
  else
   return(RmErrno = rc);
}

static int	RmWriteTaskforceStruct(Stream *stream, RmTaskforce Taskforce,
					RmFilter filter)
{ RmTaskforceStruct	copy;
  int			filter_result = RmE_Success;
  WORD			type = Type_Taskforce;
      
  memcpy((void *) &copy, (void *) Taskforce, sizeof(RmTaskforceStruct));
  if (Taskforce->Root eq (RmSet) Taskforce)
   copy.Root = (RmSet) NULL;
  
  if (filter ne (RmFilter) NULL)
   if (filter->Taskforce ne NULL)
    filter_result = (*(filter->Taskforce))(Taskforce, &copy);

  if (filter_result ne RmE_Success)
   return(RmErrno = filter_result);

  SWAP(type)
  SWAP(copy.DirNode.Type)
  SWAP(copy.DirNode.Flags)
  SWAP(copy.DirNode.Key)
  SWAP(copy.DirNode.Dates.Creation)
  SWAP(copy.DirNode.Dates.Access)
  SWAP(copy.DirNode.Dates.Modified)
  SWAP(copy.DirNode.Account)
  SWAP(copy.DirNode.Nentries)
  SWAP(copy.Private)
  SWAP(copy.NoTables)
  SWAP(copy.Private2)
  SWAP(copy.Errno)
  SWAP(copy.ReturnCode)
  SWAP(copy.State)

  if (Write(stream, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
   return(RmErrno = RmE_BadFile);

  if (Write(stream, (BYTE *) &copy, sizeof(RmTaskforceStruct), -1) ne
  		sizeof(RmTaskforceStruct))
      return(RmErrno = RmE_BadFile);

  return(RmE_Success);
}

static int	RmWriteTaskforceContents(RmTask Task, ...)
{ va_list	args;
  Stream	*stream;
  RmFilter	filter;
    
  va_start(args, Task);
  stream = va_arg(args, Stream *);
  filter = va_arg(args, RmFilter);
  va_end(args);
  
  if (RmIsTaskforce(Task))
   return(RmWriteTaskforce(stream, (RmTaskforce) Task, filter));
  else
   return(RmWriteTask(stream, Task, filter));
}

/*}}}*/
/*{{{  RmReadTask() */
int RmReadTask(Stream *stream, RmTask *TaskPtr, bool recurse)
{ RmTask Task = (RmTask)Malloc(sizeof(RmTaskStruct));
  int rc = RmE_Success;

  if (Task eq (RmTask) NULL) return(RmErrno = RmE_NoMemory);
  
  if (!recurse)
   { WORD type;
     if (FullRead(stream, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
      { rc = RmE_BadFile; goto done; }
     SWAP(type)
     if (type ne Type_Task)
      { rc = RmE_BadFile; goto done; }
   }
   
  if (FullRead(stream, (BYTE *) Task, sizeof(RmTaskStruct), -1) ne
      sizeof(RmTaskStruct))
   { rc = RmE_BadFile; goto done; }

  SWAP(Task->ObjNode.Type)
  SWAP(Task->ObjNode.Flags)
  SWAP(Task->ObjNode.Key)
  SWAP(Task->ObjNode.Dates.Creation)
  SWAP(Task->ObjNode.Dates.Access)
  SWAP(Task->ObjNode.Dates.Modified)
  SWAP(Task->ObjNode.Account)
  SWAP(Task->ObjNode.Size)
  SWAP(Task->Private)
  SWAP(Task->Uid)
  SWAP(Task->Connections)
  SWAP(Task->AttribSize)
  SWAP(Task->AttribFree)
  SWAP(Task->PAttribSize)
  SWAP(Task->PAttribFree)
  SWAP(Task->MemorySize)
  SWAP(Task->Type)
  SWAP(Task->MaxArgIndex)
  SWAP(Task->NextArgIndex)
  SWAP(Task->MaxArgStrings)
  SWAP(Task->NextArgStrings)
  SWAP(Task->MappedTo)
  SWAP(Task->MappedNode)
  SWAP(Task->Private2)
  SWAP(Task->Errno)
  SWAP(Task->ReturnCode)

  InitSemaphore(&(Task->ObjNode.Lock), 1);   
  InitList(&(Task->ObjNode.Contents));
  Task->ObjNode.Node.Next	= NULL;
  Task->ObjNode.Node.Prev	= NULL;
  Task->ObjNode.Parent		= NULL;
  Task->Root			= NULL;
  Task->OtherChannels		= NULL;
  Task->AttribData		= NULL;
  Task->PAttribData		= NULL;
  Task->ArgIndex		= NULL;
  Task->ArgStrings		= NULL;
  Task->MappedNode.Next		= NULL;
  Task->MappedNode.Prev		= NULL;

  if (Task->Connections > 4)
   { int size = (Task->Connections - 4) * sizeof(RmChannel);
     Task->OtherChannels = (RmChannel *) Malloc(size);
     if (Task->OtherChannels eq Null(RmChannel))
      { rc = RmE_NoMemory; goto done; }
     if (FullRead(stream, (BYTE *) Task->OtherChannels, size, -1) ne size)
      { rc = RmE_BadFile; goto done; }
   }

#ifdef HOSTISBIGENDIAN
   { int i;
     for (i = 0; i < Task->Connections; i++)
      { RmLink *link = RmFindLink((RmProcessor)Task, i);
        SWAP(link->Destination)
        SWAP(link->Target)
      }
   }
#endif

  if (Task->AttribSize ne 0)
   { Task->AttribData = (char *) Malloc(Task->AttribSize);
     if (Task->AttribData eq Null(char))
      { rc = RmE_NoMemory; goto done; }
     if (FullRead(stream, (BYTE *) Task->AttribData, Task->AttribSize,
     			-1) ne Task->AttribSize)
      { rc = RmE_BadFile; goto done; }
   }

  if (Task->PAttribSize ne 0)
   { Task->PAttribData = (char *) Malloc(Task->PAttribSize);
     if (Task->PAttribData eq Null(char))
      { rc = RmE_NoMemory; goto done; }
     if (FullRead(stream, (BYTE *) Task->PAttribData, Task->PAttribSize,
     			-1) ne Task->PAttribSize)
      { rc = RmE_BadFile; goto done; }
   }

  if (Task->MaxArgIndex > 0)
   { int	size = Task->MaxArgIndex * sizeof(int);
     Task->ArgIndex = (int *) Malloc(size);
     if (Task->ArgIndex eq Null(int))
      { rc = RmE_NoMemory; goto done; }
     if (FullRead(stream, (BYTE *) Task->ArgIndex, size, -1) ne size)
      { rc = RmE_BadFile; goto done; }
   }

#ifdef HOSTISBIGENDIAN
  { int i;
    for (i = 0; i < Task->MaxArgIndex; i++)
     SWAP(Task->ArgIndex[i]);
  }
#endif
  
  if (Task->MaxArgStrings > 0)
   { int	size = Task->MaxArgStrings;
     Task->ArgStrings = (char *) Malloc(size);
     if (Task->ArgStrings eq Null(char))
      { rc = RmE_NoMemory; goto done; }
     if (FullRead(stream, (BYTE *) Task->ArgStrings, size, -1) ne size)
      { rc = RmE_BadFile; goto done; }
   }
   
done:      
  if (rc ne RmE_Success)
   { if (Task ne (RmTask)NULL)
      { if (Task->OtherChannels ne NULL)	Free(Task->OtherChannels);
	if (Task->ArgIndex ne NULL)		Free(Task->ArgIndex);
	if (Task->ArgStrings ne NULL)		Free(Task->ArgStrings);
	if (Task->AttribData ne NULL)		Free(Task->AttribData);
	if (Task->PAttribData ne NULL)		Free(Task->PAttribData);
        Free(Task);
      }
     *TaskPtr = (RmTask) NULL;
     RmErrno = rc;
   }
  else
   *TaskPtr = Task;
   
  return(rc);
}
/*}}}*/
/*{{{  RmWriteTask() */
int RmWriteTask(Stream *stream, RmTask Task, RmFilter filter)
{ RmTaskStruct		LocalTask;
  int			rc;
  WORD			type;

  memcpy((void *) &LocalTask, (void *) Task, sizeof(RmTaskStruct));
  if (filter ne (RmFilter) NULL)
   if (filter->Task ne NULL)
    { rc = (*(filter->Task))(Task, &LocalTask);
      if (rc eq RmE_Skip)
       return(RmE_Success);
      elif (rc ne RmE_Success)
       return(RmErrno = rc);
    }

  type = Type_Task;
  SWAP(type)
  SWAP(LocalTask.ObjNode.Type)
  SWAP(LocalTask.ObjNode.Flags)
  SWAP(LocalTask.ObjNode.Key)
  SWAP(LocalTask.ObjNode.Dates.Creation)
  SWAP(LocalTask.ObjNode.Dates.Access)
  SWAP(LocalTask.ObjNode.Dates.Modified)
  SWAP(LocalTask.ObjNode.Account)
  SWAP(LocalTask.ObjNode.Size)
  SWAP(LocalTask.Private)
  SWAP(LocalTask.Uid)
  SWAP(LocalTask.Connections)
  SWAP(LocalTask.AttribSize)
  SWAP(LocalTask.AttribFree)
  SWAP(LocalTask.PAttribSize)
  SWAP(LocalTask.PAttribFree)
  SWAP(LocalTask.MemorySize)
  SWAP(LocalTask.Type)
  SWAP(LocalTask.MaxArgIndex)
  SWAP(LocalTask.NextArgIndex)
  SWAP(LocalTask.MaxArgStrings)
  SWAP(LocalTask.NextArgStrings)
  SWAP(LocalTask.MappedTo)
  SWAP(LocalTask.MappedNode)
  SWAP(LocalTask.Private2)
  SWAP(LocalTask.Errno)
  SWAP(LocalTask.ReturnCode)
  SWAP(LocalTask.DefaultChannels[0].Destination)
  SWAP(LocalTask.DefaultChannels[0].Target)
  SWAP(LocalTask.DefaultChannels[1].Destination)
  SWAP(LocalTask.DefaultChannels[1].Target)
  SWAP(LocalTask.DefaultChannels[2].Destination)
  SWAP(LocalTask.DefaultChannels[2].Target)
  SWAP(LocalTask.DefaultChannels[3].Destination)
  SWAP(LocalTask.DefaultChannels[3].Target)

  if (Write(stream, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
   return(RmErrno = RmE_BadFile);
  if (Write(stream, (BYTE *) &LocalTask, sizeof(RmTaskStruct), -1)
  		ne sizeof(RmTaskStruct))
   return(RmErrno = RmE_BadFile);

  SWAP(LocalTask.Connections)
  SWAP(LocalTask.AttribSize)
  SWAP(LocalTask.PAttribSize)
  SWAP(LocalTask.MaxArgIndex)
  SWAP(LocalTask.NextArgIndex)
  SWAP(LocalTask.MaxArgStrings)
  SWAP(LocalTask.NextArgStrings)

#ifdef HOSTISBIGENDIAN
  if (LocalTask.Connections > 4)
   { int	 i;
     RmLink	*link;
     for (i = 4; i < LocalTask.Connections; i++)
     { link = RmFindLink((RmProcessor) Task, i);
       SWAP(link->Destination);
       SWAP(link->Target);
     }
   }
#endif

  if (LocalTask.Connections > 4)
   { int size = (LocalTask.Connections - 4) * sizeof(RmChannel);
     if (Write(stream, (BYTE *) LocalTask.OtherChannels, size, -1) ne size)
      return(RmErrno = RmE_BadFile);
   }

#ifdef HOSTISBIGENDIAN
  if (LocalTask.Connections > 4)
   { int		 i;
     RmLink	*link;
     for (i = 4; i < LocalTask.Connections; i++)
     { link = RmFindLink((RmProcessor)Task, i);
       SWAP(link->Destination);
       SWAP(link->Target);
     }
   }
#endif

  if (LocalTask.AttribSize > 0)
   if (Write(stream, LocalTask.AttribData, LocalTask.AttribSize, -1)
	ne LocalTask.AttribSize)
    return(RmErrno = RmE_BadFile);          

  if (LocalTask.PAttribSize > 0)
   if (Write(stream, LocalTask.PAttribData, LocalTask.PAttribSize, -1)
	ne LocalTask.PAttribSize)
    return(RmErrno = RmE_BadFile);          

  if (LocalTask.MaxArgIndex > 0)

   { int size = LocalTask.MaxArgIndex * sizeof(int);
#ifdef HOSTISBIGENDIAN
     { int i;
       for (i = 0; i < LocalTask.MaxArgIndex; i++)
        SWAP(Task->ArgIndex[i]);
     }
#endif
     if (Write(stream, (BYTE *) LocalTask.ArgIndex, size, -1) ne size)
      return(RmErrno = RmE_BadFile);
#ifdef HOSTISBIGENDIAN
     { int i;
       for (i = 0; i < LocalTask.MaxArgIndex; i++)
        SWAP(Task->ArgIndex[i]);
     }
#endif
   }
  if (LocalTask.MaxArgStrings > 0)
   { int size = LocalTask.MaxArgStrings;
     if (Write(stream, (BYTE *) LocalTask.ArgStrings, size, -1) ne size)
      return(RmErrno = RmE_BadFile);
   }
  return(RmE_Success);
}
/*}}}*/
/*{{{  odds and ends */
/**-----------------------------------------------------------------------------
*** More File I/O routines, this time dealing with file descriptors rather
*** than Helios streams, to satisfy the pundits.
**/

int	RmReadfd(int fd, RmNetwork *network, RmTaskforce *taskforce)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmReadStream(str, network, taskforce));
}

int	RmReadfdNetwork(int fd, RmNetwork *network)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmReadNetwork(str, network, FALSE));
}

int	RmReadfdTaskforce(int fd, RmTaskforce *taskforce)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmReadTaskforce(str, taskforce, FALSE));
}

int	RmReadfdNetworkOnly(int fd, RmNetwork *networkptr)
{ RmNetwork	Network;
  int		rc;
  word		type;
  Stream	*str = fdstream(fd);
  
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  
  if (FullRead(str, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
   return(RmErrno = RmE_BadFile);
  SWAP(type)

  if (type ne Type_Network)
   return(RmErrno = RmE_NotNetwork);
   
  Network = *networkptr = (RmNetwork) Malloc(sizeof(RmNetworkStruct));
  if (Network eq (RmNetwork) NULL)
   return(*networkptr  = (RmNetwork) NULL, RmErrno = RmE_NoMemory);
  if (FullRead(str, (BYTE *) Network, sizeof(RmNetworkStruct), -1) ne
  	sizeof(RmNetworkStruct))
   { Free(Network);
     *networkptr = (RmNetwork) NULL;
     return(RmErrno = RmE_BadFile);
   }
  SWAP(Network->DirNode.Type)
  SWAP(Network->DirNode.Flags)
  SWAP(Network->DirNode.Key)
  SWAP(Network->DirNode.Dates.Creation)
  SWAP(Network->DirNode.Dates.Access)
  SWAP(Network->DirNode.Dates.Modified)
  SWAP(Network->DirNode.Account)
  SWAP(Network->DirNode.Nentries)
  SWAP(Network->Private)
  SWAP(Network->NoTables)
  SWAP(Network->Hardware.Head)
  SWAP(Network->Private2)
  SWAP(Network->Errno)

  InitList(&(Network->Hardware));
  InitSemaphore(&(Network->DirNode.Lock), 1);
  InitList(&(Network->DirNode.Entries));
  Network->DirNode.Parent = Null(DirNode);

	/* When writing the root, the pointer is set to NULL */
	/* There is also some special work to be done to sort out the Uid */
	/* tables. */
  if (Network->Root eq (RmSet) NULL)
   { Network->Root = (RmSet) Network;
     if ((rc = RmReadRoot((RmSet) Network)) ne RmE_Success)
      { Free(Network); return(rc); }
   }
  
  return(RmE_Success);   
}

int	RmReadfdProcessor(int fd, RmProcessor *processor)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmReadProcessor(str, processor, FALSE));
}

int	RmReadfdTask(int fd, RmTask *task)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmReadTask(str, task, FALSE));
}

int	RmReadfdTaskforceOnly(int fd, RmTaskforce *taskforceptr)
{ RmTaskforce	Taskforce;
  int		rc;
  word		type;
  Stream	*str = fdstream(fd);
  
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  
  if (FullRead(str, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
   return(RmErrno = RmE_BadFile);
  SWAP(type)
  if (type ne Type_Taskforce)
   return(RmErrno = RmE_NotNetwork);
   
  Taskforce= *taskforceptr = (RmTaskforce) Malloc(sizeof(RmTaskforceStruct));
  if (Taskforce eq (RmTaskforce) NULL)
   return(*taskforceptr  = (RmTaskforce) NULL, RmErrno = RmE_NoMemory);
  if (FullRead(str, (BYTE *) Taskforce, sizeof(RmTaskforceStruct), -1) ne
  	sizeof(RmTaskforceStruct))
   { Free(Taskforce);
     *taskforceptr = (RmTaskforce) NULL;
     return(RmErrno = RmE_BadFile);
   }
  SWAP(Taskforce->DirNode.Type)
  SWAP(Taskforce->DirNode.Flags)
  SWAP(Taskforce->DirNode.Key)
  SWAP(Taskforce->DirNode.Dates.Creation)
  SWAP(Taskforce->DirNode.Dates.Access)
  SWAP(Taskforce->DirNode.Dates.Modified)
  SWAP(Taskforce->DirNode.Account)
  SWAP(Taskforce->DirNode.Nentries)
  SWAP(Taskforce->Private)
  SWAP(Taskforce->NoTables)
  SWAP(Taskforce->Private2)
  SWAP(Taskforce->Errno)
  SWAP(Taskforce->ReturnCode)
  SWAP(Taskforce->State)

  InitSemaphore(&(Taskforce->DirNode.Lock), 1);
  InitList(&(Taskforce->DirNode.Entries));
  Taskforce->DirNode.Parent = Null(DirNode);

	/* When writing the root, the pointer is set to NULL */
	/* There is also some special work to be done to sort out the Uid */
	/* tables. */
  if (Taskforce->Root eq (RmSet) NULL)
   { Taskforce->Root = (RmSet) Taskforce;
     if ((rc = RmReadRoot((RmSet) Taskforce)) ne RmE_Success)
      { Free(Taskforce); return(rc); }
   }
  
  return(RmE_Success);   
}

int	RmWritefd(int fd, RmNetwork network, RmTaskforce taskforce)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmWriteStream(str, network, taskforce, (RmFilter) NULL));
}

int	RmWritefdNetwork(int fd, RmNetwork network)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmWriteNetwork(str, network, (RmFilter) NULL));
}

int	RmWritefdTaskforce(int fd, RmTaskforce taskforce)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmWriteTaskforce(str, taskforce, (RmFilter) NULL));
}

int	RmWritefdNetworkOnly(int fd, RmNetwork network)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmWriteNetworkStruct(str, network, (RmFilter) NULL));
}


int	RmWritefdTaskforceOnly(int fd, RmTaskforce taskforce)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmWriteTaskforceStruct(str, taskforce, (RmFilter) NULL));
}

int	RmWritefdProcessor(int fd, RmProcessor processor)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmWriteProcessor(str, processor, (RmFilter) NULL));
}

int	RmWritefdTask(int fd, RmTask task)
{ Stream	*str = fdstream(fd);
  if (str eq Null(Stream))
   return(RmErrno = RmE_BadArgument);
  else
   return(RmWriteTask(str, task, (RmFilter) NULL));
}
/*}}}*/

/*}}}*/
@


1.26
log
@fixed compile time warnings from ARM compiler
@
text
@d18 1
a18 1
/* RcsId: $Header: /hsrc/network/RCS/rmlib2.c,v 1.25 1993/08/12 11:25:36 nickc Exp nickc $*/
d468 3
a2631 2


@


1.25
log
@fixed compile time warnings
@
text
@d18 1
a18 1
/* RcsId: $Header: /hsrc/network/RCS/rmlib2.c,v 1.24 1993/08/11 11:14:35 bart Exp nickc $*/
d158 1
d230 1
d341 1
d439 1
d452 1
a452 1
{ RmJob	new_job	= Malloc(sizeof(RmJobStruct));
d550 1
d553 1
d585 1
a585 1
  server		= Malloc(sizeof(RmServerStruct));
d775 1
d778 1
d823 1
a823 1
	      data = Malloc(size);
d922 1
d925 1
d1012 1
a1012 1
      { vardata = reply->VariableData = Malloc(reply->VariableSize);
d1044 1
d1046 1
d1693 1
d1708 1
a1708 1
{ RmProcessor Processor = Malloc(sizeof(RmProcessorStruct));
d1825 1
d1937 1
d2056 1
d2059 1
d2136 1
d2140 1
a2140 1
{ RmTask Task = Malloc(sizeof(RmTaskStruct));
@


1.24
log
@Sorted out stack checking options and stack requirements
@
text
@d6 1
a6 1
--             Copyright (C) 1990, Perihelion Software Ltd.             --
d18 1
a18 1
/* RcsId: $Header: /hsrc/network/RCS/rmlib2.c,v 1.22 1993/08/05 18:34:59 bart Exp nickc $*/
d75 1
d77 1
d87 1
a87 1
  { temp = (int) Read(pipe, &(buffer[read]), (word)(amount - read), timeout);
d95 1
d335 1
d1038 1
d1255 1
d1399 1
a1399 1
     table = (int *) Malloc(sizeof(int) * Reset.NumberProcessors);
d1502 1
d1505 1
d1637 1
a1637 1
  int		x;
d1644 1
a1644 1
  table = (RmUid *) Malloc(sizeof(int) * reset->NumberProcessors);
d1664 2
a1665 2
  if (Write(stream, (BYTE *) table, sizeof(int) * reset->NumberProcessors, -1)
  	ne (sizeof(int) * reset->NumberProcessors))
d1678 1
d2609 1
@


1.23
log
@added RS6000 support
@
text
@d18 1
a19 2
/* rcsid = "$Header: /hsrc/network/RCS/rmlib2.c,v 1.22 1993/08/05 18:34:59 bart Exp nickc $ */

a22 1

d48 3
d53 1
d56 1
d59 2
a60 3
#if 1
#pragma -s1		/* disable stack checking			*/
#pragma -g0		/* remove names from code			*/
d62 1
a62 2
#pragma -s0		/* enable stack checking			*/
#pragma -g1		/* put names into code				*/
d65 6
a70 2
#ifdef RS6000
extern Environ * getenviron( void );
d637 1
a637 1
  unless(Fork(3000, RmPipeGuardian, 4, server))
d838 1
a838 1
      	(void) Fork(1000, &RmDoSynch, 4, server);
a1033 1

a1058 1

a1124 1

a2599 1

@


1.22
log
@Round and round all the bytes go, pop goes the system reliability.
(added byte swapping to all the stream I/O routines)
@
text
@d19 1
a19 1
/* rcsid = "$Header: /hsrc/network/RCS/rmlib2.c,v 1.21 1993/08/05 15:14:29 bart Exp bart $ */
d24 2
a25 1
#ifdef __SUN4
d30 1
a38 1
#include <stddef.h>
d49 1
d63 5
d1029 1
d1055 1
d1122 1
d2598 1
@


1.21
log
@Now compiles for Sun4, although it does not yet do the required byte
swapping.
@
text
@d19 1
a19 1
/* rcsid = "$Header: /hsrc/network/RCS/rmlib2.c,v 1.20 1993/04/14 16:13:05 nickc Exp bart $ */
d1029 17
d1135 2
d1193 2
d1262 1
d1274 13
d1288 1
d1297 1
a1297 1
      
d1315 1
a1315 1

d1373 1
a1373 1
    
d1378 3
d1388 6
d1481 1
a1481 1
   Table[i] = RmFindProcessor(Root, (int) Table[i]);
d1548 1
d1560 14
d1617 1
d1627 15
a1641 4
   table[i] = reset->Processors[i]->Uid;
   
  if (Write(stream, (BYTE *) reset, sizeof(RmHardwareFacility), -1) ne
  	    sizeof(RmHardwareFacility))
d1643 1
a1643 1
   
d1683 1
d1692 23
d1746 9
d1763 1
d1812 34
a1846 1
  type = Type_Processor;
d1854 5
d1860 11
d1876 12
d1890 1
a1890 1
   	     ne LocalProcessor.AttribSize)
d1895 1
a1895 1
   	     ne LocalProcessor.PAttribSize)
d1918 1
d1930 15
d1966 1
d2057 16
d2110 1
d2119 27
d2169 10
d2205 7
d2256 1
a2256 1
    
d2258 36
d2299 10
d2310 11
d2326 12
d2340 1
a2340 1
   	     ne LocalTask.AttribSize)
d2345 1
a2345 1
   	     ne LocalTask.PAttribSize)
d2349 1
d2351 6
d2359 6
d2415 2
d2429 14
d2487 1
d2500 15
@


1.20
log
@fixed for SUN4 compilation
@
text
@d19 1
a19 1
/* rcsid = "$Header: /hsrc/network/RCS/rmlib2.c,v 1.19 1993/01/13 11:07:56 bart Exp nickc $ */
d82 60
d319 1
a319 58
/*{{{  RmLookupProcessor() */
/**
*** Given a network, look up the processor. 
*** Arguments : Network, the root structure or a subnet
***             name, something like Cluster/00
*** 
*** The routine determines the last bit of the name, e.g. 00, and
*** searches the network. When a processor is reached whose ID matches
*** this last bit of the name, the search goes back up the tree trying
*** to match all the parents.
**/
static int	LookupAux1(RmProcessor, ...);

RmProcessor	RmLookupProcessor(RmNetwork Network, char *name)
{ char		*temp = name + strlen(name);

  if (*name eq '/') name++;  
  for ( ; (temp >= name) && (*temp ne '/'); temp--);

  return((RmProcessor) RmSearchProcessors(Network, &LookupAux1, name, ++temp));
}

static int LookupAux1(RmProcessor Processor, ...)
{ va_list	args;
  char		*name;
  char		*last_name;
  RmNetwork	current;
  RmNetwork	root_net;
  int		amount;
      
  va_start(args, Processor);
  name		= va_arg(args, char *);
  last_name	= va_arg(args, char *);
  va_end(args);

	/* Unless the last bit matches, do not bother to check */  
  if (strcmp(RmGetProcessorId(Processor), last_name)) return(0);

  current	= (RmNetwork) Processor;
  root_net	= RmRootNetwork(Processor);
  
  while (last_name > name)	/* If name is 00, match is immediate	*/
   { last_name--; last_name--;  /* Skip the / and get to last char	*/
     for ( amount = 0; (last_name >= name) && (*last_name ne '/'); 
           last_name--, amount++);
     last_name++;		/* should now be Cluster */
     current = RmParentNetwork((RmProcessor) current);
     if (current eq (RmNetwork) NULL) return(0);

     if ((current eq root_net) && (RmRootName ne NULL))
      { if (strncmp(RmRootName, last_name, amount)) return(0);
      }
     else
      { if (strncmp(current->DirNode.Name, last_name, amount)) return(0); 
      }
   }
  return((int) Processor);
}
d321 1
a321 1
/*}}}*/
d1020 1
@


1.19
log
@Increased priority of PipeGuardian() thread to avoid timeouts
@
text
@d19 1
a19 1
/* rcsid = "$Header: /m/giga/HeliosRoot/Helios/network/RCS/rmlib2.c,v 1.18 1993/01/08 12:33:49 bart Exp bart $ */
d24 5
@


1.18
log
@sorted out pragmas and improved handling of EOF condition in PipeGuardian
@
text
@d19 1
a19 1
/* rcsid = "$Header: /users/bart/hsrc/network/RCS/rmlib2.c,v 1.17 1992/09/09 11:44:02 bart Exp $ */
d31 1
d766 4
@


1.17
log
@The main change is support for DoDup2 requests, needed for the farm library.
Also, various minor cleanups mainly to keep the C40 compiler happier.
@
text
@d19 1
a19 1
/* rcsid = "$Header: /users/bart/hsrc/network/RCS/rmlib2.c,v 1.16 1992/08/14 17:21:19 bart Exp $ */
d44 4
d49 5
a53 3
#pragma -s1		/* disable stack checking */
#pragma -f0		/* and vector stack */
#pragma -g0		/* and do not put the names into the code */
d770 1
d815 5
a819 2
     elif ((Result2(pipe) & EC_Mask) > EC_Warn)
      break;
a998 1

a1001 1

@


1.16
log
@Exception handlers are now Fork()'ed off rather than called by the
connection guardian, to avoid deadlocks. Hence there is a new exception
stack variable.
@
text
@d19 1
a19 1
/* rcsid = "$Header: /m/giga/HeliosRoot/Helios/network/RCS/rmlib2.c,v 1.14 1992/06/08 15:27:20 bart Exp $ */
d56 3
a58 3
word FullRead(Stream *pipe, BYTE *buffer, word amount, word timeout)
{ word	read = 0;
  word	temp;
d61 1
a61 1
  { temp = Read(pipe, &(buffer[read]), amount - read, timeout);
d65 1
a65 1
    if (read >= amount) return(read);
d70 1
a70 1
/*{{{  RmMapProcessorToObject */
d72 2
a73 2
*** 1) BuildName(): given a suitable buffer of IOCDataMax bytes, and a
***    processor that is part of a network, construct the full pathname
d76 1
a76 1
static char *BuildName(char *buffer, RmProcessor processor)
d79 4
d85 5
a89 3
     for (name = processor->ObjNode.Name; *name ne '\0'; ) *buffer++ = *name++;
     *buffer = '\0';
     return(buffer);
d92 1
a92 1
   { buffer = BuildName(buffer, (RmProcessor) RmParentNetwork(processor));
d124 1
a124 1
     (void) BuildName(buf, processor);
d132 1
a132 1
  if (*((word *) cap) eq 0)
d281 1
a281 1
  
d431 1
a431 1
  
d473 2
a474 6
  if (Write(pipe, (BYTE *) &(job->Id), sizeof(WORD), -1) ne sizeof(WORD))
   { IOdebug("RmLib : internal error in RmLockWrite");
     IOdebug("RmLib : failed to write word to pipe %s, flags %x, Result2 %x",
     		pipe->Name, pipe->Flags, Result2(pipe));
     return(Null(Stream));
   }
d601 2
a602 2
  if (Write(server->Pipe_ctos, (BYTE *) &RmProgram, sizeof(WORD), 10 * OneSec)
	ne sizeof(WORD))
d605 2
a606 2
  if (Read(server->Pipe_stoc, (BYTE *) &len, sizeof(WORD), 10 * OneSec)
	ne sizeof(WORD))
d610 1
a610 1
  unless(Fork(2000, RmPipeGuardian, 4, server))
d754 1
d758 1
a758 1
  WORD	 id;
d761 1
a761 1
   { int result;
d763 1
a763 1
     result = FullRead(pipe, (BYTE *) &id, sizeof(WORD), 30 * OneSec);
d772 2
d775 1
a775 1
            { word	size;
d777 1
a777 1
	      result = FullRead(pipe, (BYTE *) &size, sizeof(WORD), 30 * OneSec);
d826 1
d830 1
a830 1
{ WORD	rc = RmR_Private + RmR_Synch;
d833 1
a833 1
  (void) Write(server->Pipe_ctos, (BYTE *) &rc, sizeof(WORD), 10 * OneSec);
d836 39
d891 3
d927 1
a927 1
{ Stream	*pipe = RmSwitchLockRead(job);
d931 5
d971 1
d979 1
d1020 1
a1020 1
   { int rc = Result2(env->Objv[0]);
d1062 2
a1063 2
   { rc = Result2(env->Objv[0]);
     if ((rc & EG_Mask) eq EG_NoMemory)
d1065 1
a1065 1
     elif ((rc & EG_Mask) eq EG_Protected)
d1089 1
a1089 1
{ WORD	junk[3];
d1094 1
a1094 1
  if (FullRead(stream, (BYTE *) junk, 3 * sizeof(WORD), -1) ne (3 * sizeof(WORD)))
d1145 1
a1145 1
{ WORD	junk[3];
d1148 1
a1148 1
  junk[0] = RmLib_Magic;
d1152 1
a1152 1
  if (Write(stream, (BYTE *) junk, 3 * sizeof(WORD), -1) ne (3 * sizeof(WORD)))
d1216 2
a1217 2
   { WORD type;
     if (FullRead(stream, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
d1254 2
a1255 2
   { WORD type;
     if (FullRead(stream, (BYTE *) &type, sizeof(WORD), -1) ne sizeof(WORD))
d1467 1
a1467 1
  WORD			type = Type_Network;
d1530 1
a1530 1
{ int		*table;
d1541 2
a1542 2
  table = (int *) Malloc(sizeof(int) * reset->NumberProcessors);
  if (table eq Null(int)) return(RmErrno = RmE_NoMemory);
@


1.15
log
@1) extended RmLookupProcessor to cope with variable root names
2) cleaned up the pointer manipulations in the communication code
@
text
@d646 9
a654 4
  Close(server->Socket_stoc);
  server->Socket_stoc	= Null(Stream);
  Close(server->Socket_ctos);
  server->Socket_ctos	= Null(Stream);
d779 6
a784 2
	       (*RmExceptionHandler)(id, size, data);
	      Free(data);
d800 1
a800 2
      { 
        if (server->Pipe_ctos eq Null(Stream)) break;
d807 1
a807 1
  (void) WalkList(&(server->Jobs), (WordFnPtr) &RmAbortJob);
@


1.14
log
@Moved the netutils routine LookupProcessor into the Resource Management
library, RmLookupProcessor()
@
text
@d19 1
a19 1
/* rcsid = "$Header: /users/bart/hsrc/network/RCS/rmlib2.c,v 1.13 1992/04/24 15:43:21 bart Exp $ */
d268 1
d280 1
d289 7
a295 1
     if (strncmp(RmGetNetworkId(current), last_name, amount)) return(0); 
d1146 5
a1150 4
{ RmNetwork Network;
  int	    rc;
  int	    i;
  int	    resets;
d1167 1
a1167 1
  resets = (int) Network->Hardware.Head;
d1169 5
a1175 1
  Network->DirNode.Parent = Null(DirNode);
d1184 1
a1184 1
  if (Network->Root eq (RmSet) NULL)
d1231 3
a1233 3
{ int 	NoTables = Set->NoTables;
  Set->NoTables = 0;
  Set->Tables   = Null(RmUidTableEntry *);
d1537 7
d1587 3
a1589 2
      { if (Processor->OtherLinks ne Null(RmLink))
         Free(Processor->OtherLinks);
d1658 1
d1679 6
a1684 2
  Taskforce->DirNode.Parent = Null(DirNode);
      
d1688 1
a1688 1
  if (Taskforce->Root eq (RmSet) NULL)
d1834 13
a1846 3
  Task->OtherChannels	= Null(RmChannel);
  Task->ArgIndex	= Null(int);
  Task->ArgStrings	= Null(char);
d1895 5
a1899 6
      { if (Task->OtherChannels ne Null(RmChannel))
         Free(Task->OtherChannels);
	if (Task->ArgIndex ne Null(int))
	 Free(Task->ArgIndex);
	if (Task->ArgStrings ne Null(char))
	 Free(Task->ArgStrings);
@


1.13
log
@When contacting the TFM the wrong capability was being used
@
text
@d19 1
a19 1
/* rcsid = "$Header: /users/bart/hsrc/network/RCS/rmlib2.c,v 1.12 1992/03/25 18:03:41 bart Exp $ */
d239 51
@


1.12
log
@Various changes including:
1) first attempt at C40 support
2) RmLib execute support (not yet fully tested)
3) faster bootstrap, taskforce load, and better mapping
@
text
@d19 1
a19 1
/* rcsid = "$Header: /users/bart/hsrc/network/RCS/rmlib2.c,v 1.11 1992/01/15 11:04:39 bart Exp $ */
d641 1
a641 1
			    for (i = 0; i < OV_TFM; i++)
d644 4
a647 3

			    cap = &(env->Objv[OV_TFM]->Access);

@


1.11
log
@Major update of networking sources, to incorporate the fault-tolerance
work as demonstrated at the IED meeting 10.1.92
@
text
@d19 1
a19 1
/* rcsid = "$Header: /usr/perihelion/Helios/network/RCS/rmlib2.c,v 1.7 90/12/01 15:37:21 bart Exp $ */
d23 1
d34 1
a34 1

d42 2
a43 1

d49 3
a51 1

d69 2
a70 1

d72 3
a74 2
*** Another little utility to map RmProcessor objects onto real
*** Helios objects.
d94 5
d136 2
a137 1

d144 24
d169 78
d338 2
a339 1

d341 1
a341 1
*** RmOpenConnection(). Given an open RmServer to the Network Server, Session
a350 2
static bool	RmOpenDefaultServer(RmServer *);

d454 2
a455 1

a472 2
static void	RmPipeGuardian(RmServer);

d671 2
a672 1

d762 2
a763 1

d874 3
a876 1

d884 1
d951 2
a952 1

d975 2
a976 1
  if (junk[0] ne 0x07)	/* new style version number */
d1025 1
a1025 1
  junk[0] = 0x07;	/* version number */
d1063 4
a1066 3
     if (RmMapTask(processor, task) ne RmE_Success)
      { IOdebug("RmLib: internal error, failed to map task onto processor");
      }
d1070 2
a1071 1
   
d1289 2
a1290 1

d1436 2
a1437 1

d1527 2
a1528 1

d1575 2
a1576 1

a1579 1
BLV TaskforcePtr should be set to NULL on failure.
d1673 2
a1674 1

d1735 2
a1736 2


d1823 2
a1824 1

d1874 2
a1875 2


d2056 2
a2059 37
/**-----------------------------------------------------------------------------
*** Error manipulation, this is about as bad a place as any to have this routine
**/
const	char	*RmMapErrorToString(int err)
{ switch(err)
   { case RmE_Success		: return("success");
     case RmE_NotProcessor	: return("NotProcessor, argument is not a valid processor");
     case RmE_NotTask		: return("NotTask, argument is not a valid task");
     case RmE_NotNetwork	: return("NotNetwork, argument is not a network");
     case RmE_NotTaskforce	: return("NotTaskforce, argument is not a taskforce");
     case RmE_WrongNetwork	: return("WrongNetwork, this network is inappropriate");
     case RmE_WrongTaskforce	: return("WrongTaskforce, this taskforce is inappropriate");
     case RmE_InUse		: return("InUse, some object is currently in use");
     case RmE_Corruption	: return("Corruption, there appears to be memory corruption");
     case RmE_ReadOnly		: return("ReadOnly, the object cannot be modified");
     case RmE_BadArgument	: return("BadArgument, one of the arguments was invalid");
     case RmE_NoMemory		: return("NoMemory, there is not enough memory on the local processor");
     case RmE_NotFound		: return("NotFound, a search failed");
     case RmE_TooLong		: return("TooLong, a string argument was too large");
     case RmE_NotRootNetwork	: return("NotRootNetwork, the operation cannot be performed on a subnet");
     case RmE_NoAccess		: return("NoAccess, the application has not obtained access");
     case RmE_OldStyle		: return("OldStyle, please recompile your resource map");
     case RmE_BadFile		: return("BadFile, the file contains invalid data");
     case RmE_CommsBreakdown	: return("CommsBreakdown, the application failed to communicate properly with a server");
     case RmE_Skip		: return("Skip, a large container for refuse etc.");
     case RmE_NotRootTaskforce	: return("NotRootTaskforce, the operation cannot be performed on a sub-taskforce");
     case RmE_MissingServer	: return("MissingServer, an essential server could not be found");
     case RmE_PartialSuccess	: return("PartialSuccess, the operation did not succeed completely");
     case RmE_BadLink		: return("BadLink, the specified link does not exist");
     case RmE_BadProcessor	: return("BadProcessor, this processor is currently unusable");
     case RmE_BadChannel	: return("BadChannel, the specified channel does not exist");
     case RmE_YouMustBeJoking	: return("YouMustBeJoking, not currently implemented");
     case RmE_ServerMemory	: return("ServerMemory, a server ran out of memory");
     case RmE_NotPossible	: return("NotPossible, hardware limitation");
     default			: return("<unknown error>");
   }
}
@


1.10
log
@Major update of networking sources, to match Helios1_2_2_native_beta
@
text
@d19 1
a19 1
/* rcsid = "$Header: /users/bart/netbak/network/RCS/rmlib2.c,v 1.2 1991/08/20 14:29:15 bart Exp $ */
a22 2
#define	PIPEGUARDIAN 1

d31 2
d70 1
a70 1
static char *BuildName(char *buffer, RmProcessor Processor)
d73 1
a73 1
  if (Processor eq (RmProcessor) RmRootNetwork(Processor))
d75 1
a75 1
     for (name = Processor->ObjNode.Name; *name ne '\0'; ) *buffer++ = *name++;
d80 1
a80 1
   { buffer = BuildName(buffer, (RmProcessor) RmParentNetwork(Processor));
d82 1
a82 1
     for (name = Processor->ObjNode.Name; *name ne '\0'; ) *buffer++ = *name++;
d88 1
a88 1
Object	*RmMapProcessorToObject(RmProcessor Processor)
d91 1
a91 1
  Capability	*Cap;
d94 1
a94 1
  CheckProcessorFail(Processor, Null(Object));  
d96 4
a99 4
  if ((Processor->StructType ne RmL_Obtained) &&
      (Processor->StructType ne RmL_Existing))
   return(RmErrno = Processor->Errno = RmE_NoAccess, Null(Object));
  Cap = &(Processor->RealCap);
d101 1
a101 1
  if (Processor->ObjNode.Parent ne Null(DirNode))
d105 1
a105 1
      return(RmErrno = Processor->Errno = RmE_NoMemory, Null(Object));
d107 1
a107 1
     (void) BuildName(buf, Processor);
d111 1
a111 1
     buf = RmGetObjectAttribute((RmObject) Processor, "PUID", TRUE);
d113 1
a113 1
      return(RmErrno = Processor->Errno = RmE_NotNetwork, Null(Object));
d115 1
a115 1
  if (*((word *) Cap) eq 0)
d118 1
a118 1
   result = NewObject(buf, Cap);
d122 1
a122 1
   RmErrno = Processor->Errno = RmE_NotFound;
d126 6
d140 1
a140 1
***			   		   (to be validated by the domain)
d143 1
a143 2
*** Application		<-> Special Server, e.g. notifyns to a remote Network
***			    Server, or one Network Server to another
d151 8
d160 7
a166 6
*** has upto three streams open : one to the Network Server, read-only,
*** to implement routines such as RmGetNetwork(); one to the Session
*** Manager; and one to the ``parent''. For the Taskforce Manager and
*** the Session Manager this parent is the Network Server. For everything
*** else this parent is the session's Taskforce Manager. The library
*** multiplexes all interactions down this stream.
a167 9
*** For now, associated with every stream is a pipe. Communication between
*** client and server actually happens by writing to and reading from this
*** pipe, which means that I do not have to worry about establishing
*** reliable communication myself. Ofcourse this is hopelessly inefficient,
*** as it means another process in both client and server, but efficiency
*** can come later. Strictly speaking pipes are uni-directional so I need
*** two pipes for every connection, but in practice pipes behave fairly
*** well in a bi-directional mode.
***
d170 1
a170 1
*** 	 If the stream has not yet been opened, this routine does so. It
a206 3
*** In fact there are two closes, one for
*** the Stream connection to the server and one for the pipe, but that
*** is a minor detail.
d238 2
a239 2
int	RmNewJob(RmServer *Server, RmJob *JobPtr)
{ RmJob	NewJob	= Malloc(sizeof(RmJobStruct));
d241 1
a241 1
  if (NewJob eq (RmJob)NULL)
d244 3
a246 3
  if (*Server eq (RmServer)NULL)
   unless(RmOpenDefaultServer(Server))
    { Free(NewJob); return(RmErrno = RmE_BadArgument); }
d248 5
a252 5
  Wait(&((*Server)->StructLock));
  NewJob->Id		= (*Server)->MaxId++;
  NewJob->Server	= *Server;
  NewJob->WriteLocked	= FALSE;
  NewJob->ReadLocked	= FALSE;
d254 4
a257 4
  InitSemaphore(&(NewJob->Wait), 0);
  AddTail(&((*Server)->Jobs), &(NewJob->Node));
  Signal(&((*Server)->StructLock));
  *JobPtr = NewJob;
d265 2
a266 2
void	RmFinishedJob(RmJob Job)
{ RmServer	Server = Job->Server;
d268 3
a270 3
  if (Job->WriteLocked)
   { IOdebug("RmLib Job Error : id %d, write still locked", Job->Id);
     Signal(&(Server->WriteLock));
d272 3
a274 3
  if (Job->ReadLocked)
   { IOdebug("RmLib Job Error : id %d, read still locked", Job->Id);
     Signal(&(Server->PipeGuardian));
d276 4
a279 4
  Wait(&(Server->StructLock));
  Remove(&(Job->Node));
  Signal(&(Server->StructLock));
  Free(Job);  
d285 3
a287 2
Stream	*RmLockWrite(RmJob Job)
{ RmServer	Server = Job->Server;
d289 3
a291 2
  Wait(&(Server->WriteLock));
  Job->WriteLocked	= TRUE;
d295 1
a295 2
  if (Write(Server->Pipe, (BYTE *) &(Job->Id), sizeof(WORD), -1) <
  		sizeof(WORD))
d298 1
a298 1
     	Server->Pipe->Name, Server->Pipe->Flags, Result2(Server->Pipe));
d302 1
a302 1
  return(Server->Pipe);
d305 4
a308 4
void	RmUnlockWrite(RmJob Job)
{ RmServer	Server = Job->Server;
  Signal(&(Server->WriteLock));
  Job->WriteLocked = FALSE;
d311 2
a312 2
Stream	*RmLockRead(RmJob Job)
{ RmServer	Server = Job->Server;
d314 3
a316 9
#ifdef PIPEGUARDIAN
  Wait(&(Job->Wait));		/* Triggered by RmPipeGuardian */
#else
  int		temp;
  (void) FullRead(Server->Pipe, (BYTE *) &temp, sizeof(word), -1);
#endif

  Job->ReadLocked = FALSE;
  return(Server->Pipe);
d319 2
a320 2
Stream	*RmSwitchLockRead(RmJob Job)
{ RmServer	Server = Job->Server;
d322 1
a322 1
  if (!Job->WriteLocked)
d325 2
a326 2
   { Signal(&(Server->WriteLock));
     Job->WriteLocked = FALSE;
d329 3
a331 10
#ifdef PIPEGUARDIAN
  Wait(&(Job->Wait));
#else  
  { int temp;
    (void) FullRead(Server->Pipe, (BYTE *) &temp, sizeof(word), -1);
  }
#endif

  Job->ReadLocked = TRUE;
  return(Server->Pipe);
d334 3
a336 3
void	RmUnlockRead(RmJob Job)
{ RmServer	Server = Job->Server;
  if (!Job->ReadLocked)
d338 2
a339 2
  Signal(&(Server->PipeGuardian));
  Job->ReadLocked = FALSE;
d343 3
a345 3
*** RmOpenServer(). This attempts to set up the basic communication stream
*** between a client and a networking server. All connections from that client
*** to that server will share this stream.
d347 6
a352 9
*** Assuming it is possible to allocate and initialise some memory, a stream
*** is opened to the specified server. The routine is passed two arguments,
*** a context object and a name. In practice one of these is likely to be
*** NULL. By default servers can greatly restrict access, for example
*** a normal application can only examine the network maintained by the
*** Network Server, not perform operations on it. Specifying a name but not
*** a Context limits access to the default, which in an un-protected
*** environment is of course unlimited. Specifying a Context but not a
*** name allows the application to use the appropriate capability.
d354 3
a356 18
*** Example : an application needs to access its Taskforce Manager.
*** There should be an object in the environment corresponding to
*** the Taskforce Manager, giving the right capability. This object should
*** be used as the context.
***
*** Example : an application needs to access the Network Server. 
*** There is no suitable object in the environment, so the context is
*** null and the name "/ns" is used.
***
*** Assuming the stream can be opened, the routine does a simple interaction
*** using the resulting message ports. This serves several purposes. It
*** identifies the client with a fair degree of security, since the
*** capability has already been validated during the Open stage. Some
*** operations only make sense in certain clients, e.g. only the mergenet
*** program can be used to perform the mergenet operation. The reply from
*** the server will contain a marshalled stream for a pipe opened by the
*** server, and the application also opens this pipe. A pipe guardian
*** process is Fork()'ed off to listen on this pipe.
d358 1
a358 1
#ifdef PIPEGUARDIAN
a359 1
#endif
d361 7
a367 9
int	RmOpenServer(Object *Context, char *name, RmServer *ServerPtr)
{ RmServer Server = (RmServer)NULL;
  Stream	*ServStream	= Null(Stream);
  Stream	*PipeStream	= Null(Stream);
  Object	*ServObj	= Null(Object);
  BYTE		*Data		= Null(BYTE);
  WORD		Control[IOCMsgMax];
  MCB		mcb;
  int		return_code	= RmE_Success;  
d369 1
a369 1
  if ((Context eq Null(Object)) && (name eq Null(char)))
d371 3
a373 1
   
d375 2
a376 9
  Server		= Malloc(sizeof(RmServerStruct));
  if (Server eq (RmServer) NULL) return(RmErrno = RmE_NoMemory);
  Server->Pipe		= Null(Stream);
  Server->Pipe2		= Null(Stream);
  InitSemaphore(&(Server->WriteLock), 1);
  Server->MaxId		= 1;
  InitSemaphore(&(Server->StructLock), 1);
  InitSemaphore(&(Server->PipeGuardian), 0);
  InitList(&(Server->Jobs));
d378 9
a386 4
	/* Space for the data vector */
  Data			= Malloc(IOCDataMax);
  if (Data eq Null(BYTE))
   { return_code = RmE_NoMemory;  goto done; }
d388 3
a390 10
	/* Pick a suitable context object */
  if (Context eq Null(Object))   
   { ServObj		= Locate(Null(Object), name);
     name		= Null(char);
   }
  else
   ServObj = Context;
   
  if (ServObj eq Null(Object))
   { return_code = RmE_NotFound; goto done; }
d392 3
a394 1
  	/* And try to open the desired stream */
d396 2
a397 3
  ServStream		= Open(ServObj, name, O_Private);
  if (ServStream eq Null(Stream))
   { return_code = RmE_NotFound; goto done; }
d399 2
a400 10
	/* Time for a simple message interaction */
  InitMCB(&mcb, MsgHdr_Flags_preserve, ServStream->Server, ServStream->Reply,
  	  FC_Private + RmC_Init);
  mcb.Control		= Control;
  mcb.Data		= Data;
  mcb.Control[0]	= RmProgram;
  mcb.MsgHdr.ContSize	= 1;
  if (PutMsg(&mcb) ne Err_Null)
   { return_code = RmE_CommsBreakdown; goto done; }
  mcb.MsgHdr.Dest = mcb.MsgHdr.Reply;
d402 7
a408 15
  if (GetMsg(&mcb) ne Err_Null)
   { return_code = RmE_CommsBreakdown; goto done; }
  
  	/* The control and data vectors now contain a marshalled Stream */
  { BYTE	*data = Data;	/* Do not zap Data, it must be freed later */
    int		mode;
    Capability	*cap;
    char	*name;
    
    	/* Unmarshal the stream, there is no library call for this */
    mode	= *((WORD *) Data);
    data	= &(data[2 * sizeof(int)]);	/* Past mode, skip Pos */
    cap		= (Capability *) data;
    data	= &(data[sizeof(Capability)]);
    name	= (char *) data;
d410 4
a413 6
	/* Try to access the pipe */
    PipeStream = NewStream(name, cap, mode);	
    if (PipeStream eq Null(Stream))
     { return_code = RmE_NoMemory; goto done; }
  }
  Server->Pipe  = PipeStream;
d415 2
a416 7
	/* Perform some simple synchronisation, one word 0 in both directions */
  { WORD x = 0x43211234;
    if (Write(PipeStream, (BYTE *) &x, sizeof(WORD), -1) < sizeof(WORD))
     { return_code = RmE_CommsBreakdown; goto done; }
    if (FullRead(PipeStream, (BYTE *) &x, sizeof(WORD), -1) < sizeof(WORD))
     { return_code = RmE_CommsBreakdown; goto done; }
  }
d418 2
a419 3
  Server->Pipe2 = CopyStream(PipeStream);
  if (Server->Pipe2 eq Null(Stream))
   { return_code = RmE_NoMemory; goto done; }
d421 15
a435 1
#ifdef PIPEGUARDIAN
d437 2
a438 3
  unless(Fork(2000, RmPipeGuardian, 4, Server))
   { return_code = RmE_NoMemory; goto done; }
#endif
d440 2
a441 2
  	/* And the connection has been made */
done:
d443 7
a449 9
  if (return_code ne RmE_Success)
   { 
     if (Server ne (RmServer)NULL)
      { if (Server->Pipe2 ne Null(Stream)) Close(Server->Pipe2);
        Free(Server); 
        Server = (RmServer) NULL; 
      }
     if (PipeStream ne Null(Stream)) Close(PipeStream);
     RmErrno = return_code;
d451 2
a452 6
  if (ServStream ne Null(Stream)) Close(ServStream);
  if (Data ne Null(BYTE)) Free(Data);
  if ((ServObj ne Null(Object)) && (ServObj ne Context))
    Close(ServObj);
  *ServerPtr = Server;
  return(return_code);
a463 1
BLV This whole piece of code needs rethinking.
d466 6
a471 2
int	RmCloseServer(RmServer Server)
{ Stream	*pipe2;
d473 6
a478 9
  if (Server eq (RmServer) NULL) return(RmE_Success);
  
  Wait(&(Server->StructLock));
  unless(EmptyList_(Server->Jobs))
   { Signal(&(Server->StructLock)); return(RmErrno = RmE_InUse); }

  pipe2 = Server->Pipe2;
  Server->Pipe2 = Null(Stream);
  Close(Server->Pipe);
a479 2
  Close(pipe2);
  Free(Server);
d490 3
a492 3
*** Network Server, and in theory a suitable object will be passed in the
*** environment. The parent for user applications is the Taskforce
*** Manager, and should again be passed in the environment.
d494 6
a499 3
static bool	RmOpenDefaultServer(RmServer *ServerPtr)
{ Object	*Context = Null(Object);
  char		*name	 = Null(char);
d501 4
a504 15
  if (ServerPtr eq &RmNetworkServer)
   { if ((RmProgram eq Rm_Session) || (RmProgram eq Rm_TFM))
      { Object *temp = Locate(Null(Object), "/ns");

        if (RmParent ne (RmServer)NULL)
         { RmNetworkServer = RmParent; return(TRUE); }

        if (temp ne Null(Object))
         { Context = NewObject(temp->Name, &RmLib_Cap);
           Close(temp);
         }
        else
         Context = Null(Object);
        name = Null(char);
      }
d506 1
a506 1
      name = "/ns";
d508 3
a510 3
  elif (ServerPtr eq &RmSessionManager)
   name = "/sm";
  elif (ServerPtr eq &RmParent)
d515 1
a515 2
      case Rm_TFM	:	/* the parent is the Network Server */
		 	  if (RmNetworkServer ne (RmServer)NULL)
d517 3
a519 11
			   
			  { Object	*temp = Locate(Null(Object), "/ns");
			    if (temp ne Null(Object))
			     { Context = NewObject(temp->Name, &RmLib_Cap);
			       Close(temp);
			     }
			    else
			     Context = Null(Object);
			    name    = Null(char);
			    break;
			  }
d522 4
a525 3
      			  { Environ *env = getenviron();
			    int	    i;
			    name	 = Null(char);
d527 2
a528 5
			    if (env eq Null(Environ))
			     { Context = Null(Object); break; }
			    if (env->Objv eq Null(Object *))
			     { Context = Null(Object); break; }
			     
d531 17
a547 3
			      { Context = Null(Object); break; }
			      
			    Context	 = env->Objv[OV_TFM];
d554 1
a554 1
  if (RmOpenServer(Context, name, ServerPtr) eq RmE_Success)
a559 1
#ifdef PIPEGUARDIAN
d571 2
a572 3
static	int	RmMatchJob(RmJob Job, int ID);
static  int	RmAbortJob(RmJob Job);
static	void	RmHandlePrivate(RmServer Server, int Fn);
d575 3
a577 4
static	void RmPipeGuardian(RmServer Server)
{ Stream *WriterPipe	= Server->Pipe;
  Stream *Pipe		= Server->Pipe2;
  WORD	 ID;
d582 1
a582 1
     result = FullRead(Pipe, (BYTE *) &ID, sizeof(WORD), 30 * OneSec);
d585 3
a587 2
        if ((ID & RmR_Private) ne 0)
         { if ((ID & ~RmR_Private) eq RmR_Terminate)
d589 1
a589 1
           elif ((ID & ~RmR_Private) eq RmR_Synch)
d592 12
a603 1
            RmHandlePrivate(Server, ID);
d606 6
a611 6
         { RmJob	Job;
           Wait(&(Server->StructLock));
	   Job = (RmJob)
	      SearchList(&(Server->Jobs), (WordFnPtr) &RmMatchJob, ID);
	   Signal(&(Server->StructLock));
	   if (Job eq (RmJob) NULL)
d613 2
a614 2
	   Signal(&(Job->Wait));
	   Wait(&(Server->PipeGuardian));
d619 2
a620 2
        if (Server->Pipe2 eq Null(Stream)) return;	/* See RmCloseServer */
      	(void) Fork(1000, &RmDoSynch, 4, Server);
d622 2
a623 16
     else  
      { if (Server->Pipe2 eq Null(Stream)) return;	/* See RmCloseServer */
        if ((Result2(Pipe) & EC_Mask) > EC_Warn)
         { 
/*
	   IOdebug("PipeGuardian : abnormal termination, Result2 %x", Result2(Pipe));
	   IOdebug("Pipe is %s, flags %x", Pipe->Name, Pipe->Flags);
*/
           Close(Pipe);
           Close(WriterPipe);
           Server->Pipe = Null(Stream);
	   Server->Pipe2 = Null(Stream);
           (void) WalkList(&(Server->Jobs), (WordFnPtr) &RmAbortJob);
           return;
         }
      }
d625 4
a628 6
/*
	IOdebug("PipeGuardian : normal termination");
	IOdebug("pipe is %s, flags %x", Pipe->Name, Pipe->Flags);
*/
  Close(Pipe);
  Close(WriterPipe);
d631 2
a632 2
static	int	RmMatchJob(RmJob Job, int ID)
{ if (Job->Id eq ID)
d638 2
a639 2
static int	RmAbortJob(RmJob Job)
{ Signal(&(Job->Wait));
d644 1
d646 1
a646 1
  (void) Write(server->Pipe, (BYTE *) &rc, sizeof(WORD), 10 * OneSec);
a650 11
*** This routine should deal with asynchronous events such as processor
*** crashes, abnormal task termination, and so on. I have not yet figured
*** out exactly how.
**/
static void	RmHandlePrivate(RmServer Server, int Fn)
{ IOdebug("RmHandlePrivate");
  Server = Server; Fn = Fn;
}
#endif

/**
d654 1
a654 1
{ Stream	*Pipe = RmLockWrite(job);
d664 1
a664 1
  if (Write(Pipe, (BYTE *) request, sizeof(RmRequest), -1) ne sizeof(RmRequest))
d669 1
a669 1
   if ((rc = RmWriteStream(Pipe, request->Network, request->Taskforce,
d674 1
a674 1
   if ((rc = RmWriteProcessor(Pipe, request->Processor, FALSE)) ne RmE_Success)
d678 1
a678 1
   if ((rc = RmWriteTask(Pipe, request->Task, FALSE)) ne RmE_Success)
d682 1
a682 1
   if (Write(Pipe, request->VariableData, request->VariableSize, -1)
d690 1
a690 1
  IOdebug("RmTx: failed to send request down pipe %s", Pipe->Name);
d697 1
a697 1
{ Stream	*Pipe = RmSwitchLockRead(job);
d701 1
a701 1
  if (FullRead(Pipe, (BYTE *) reply, sizeof(RmReply), -1) ne sizeof(RmReply))
d712 1
a712 1
   if ((rc = RmReadStream(Pipe, &(reply->Network), &(reply->Taskforce)))
d717 1
a717 1
   if ((rc = RmReadProcessor(Pipe, &(reply->Processor), FALSE))
d722 1
a722 1
   if ((rc = RmReadTask(Pipe, &(reply->Task), FALSE))
d732 1
a732 1
     if (FullRead(Pipe, vardata, reply->VariableSize, -1) ne reply->VariableSize)
d741 1
a741 1
  IOdebug("RmRx: failed to receive reply from pipe %s", Pipe->Name);
d939 2
a940 4
  if (network eq (RmNetwork) NULL)
   { task->MappedTo = RmL_NoUid;
     return(0);
   }
@


1.9
log
@Fixed bug in RmReadNetwork(), after communication failure a result
pointer was not being zapped to NULL. This could affect RmObtainNetwork().
@
text
@d19 1
a19 1
/* rcsid = "$Header: /users/bart/hsrc/network/RCS/rmlib2.c,v 1.8 1991/05/18 12:08:02 bart Exp $ */
d42 1
a44 1
#if 0
d52 1
a52 1
static word FullRead(Stream *pipe, BYTE *buffer, word amount, word timeout)
d93 3
a95 3
  
  if (Processor eq (RmProcessor) NULL) return(Null(Object));
  if (Processor->ObjNode.Type ne Type_Processor) return(Null(Object));
d98 1
a98 1
   return(Null(Object));
d104 2
a105 1
     if (buf eq Null(char)) return(Null(Object));
d112 2
a113 1
     if (buf eq Null(char)) return(Null(Object));
d121 2
d164 27
a190 21
*** 1) RmJob	RmNewJob(server);
***	If the stream has not yet been opened, this routine does so. It
***     returns a pointer to a suitable structure, useful for other routines.
*** 2) Stream	*RmLockWrite(RmJob);
***	This routine gets exclusive access to the stream, and returns it
***	for whatever the caller wants to do, e.g. write a network structure.
*** 3) void	RmUnlockWrite(RmJob);
***     This routine releases the exclusive access
*** 4) Stream	*RmLockRead(RmConn);
***	This routine is used only inside the servers, to wait for data
***	arriving on the stream.
*** 5) Stream	*RmSwitchLockRead(RmJob);
***	This routine releases the exclusive write access as before and
***	waits on a semaphore for the reply to arrive. It returns the
***	Stream pointer so that the caller can read all the reply data.
*** 6) void	RmUnlockRead(RmJob);
***	This implies that the read is finished.
*** 7) void	RmFinishJob(RmJob);
***	This routine is called once the operation has finished. It does
***	not close the Stream to the server, because that stream may be
***	shared with other jobs.
d239 2
a240 1
  if (NewJob eq (RmJob)NULL) return(RmE_NoMemory);
d244 1
a244 1
    { Free(NewJob); return(RmE_BadArgument); }
d401 1
a401 1
   return(RmE_MissingServer);
d405 1
a405 1
  if (Server eq (RmServer) NULL) return(RmE_NoMemory);
a481 3
Server->Pipe->Flags  |=  0x00200000;
Server->Pipe2->Flags |=  0x00400000;

d499 1
d518 1
a518 2
BLV - not safe, perform another message transaction. Even then there are
BLV problems because a reopen() would give a different connection...
d524 2
d528 2
a529 2
   { Signal(&(Server->StructLock)); return(RmE_InUse); }
  
d532 3
a534 3
  Close(Server->Pipe);	/* BLV - more may be needed */
  Close(Server->Pipe2);
  Delay(OneSec);
d670 2
a671 1
      { if (Server->Pipe2 eq Null(Stream)) return;	/* See RmCloseServer */
d678 2
a679 1
/*	   IOdebug("PipeGuardian : abnormal termination, Result2 %x", Result2(Pipe));
d691 3
a693 2
/*IOdebug("PipeGuardian : normal termination");
IOdebug("pipe is %s, flags %x", Pipe->Name, Pipe->Flags);
d729 111
d852 2
a853 1
  if (filename eq Null(char)) return(RmE_BadArgument);
d855 1
a855 1
   return(RmE_BadArgument);
d860 1
a860 1
      return(RmE_NoAccess);
d862 1
a862 1
      return(RmE_NoMemory);
d864 1
a864 1
      return(RmE_NotFound);
d869 1
a869 1
   return(RmE_NoMemory);
d887 2
a888 1
  if (filename eq Null(char)) return(RmE_BadArgument);
d890 1
a890 1
   return(RmE_BadArgument);
d893 1
a893 1
    return(RmE_NotNetwork);
d896 1
a896 1
    return(RmE_NotTaskforce);    
d902 1
a902 1
      return(RmE_NoMemory);
d904 1
a904 1
      return(RmE_NoAccess);
d906 1
a906 1
      return(RmE_BadFile);
d932 1
a932 1
   return(RmE_BadFile);
d934 1
a934 1
   return(RmE_OldStyle);
d936 1
a936 1
   return(RmE_BadFile);
d968 1
a968 1
        (void) RmApplyTaskforce(*Taskforce, &UpdateMapping, *Network);
d989 1
a989 1
   return(RmE_BadFile);
a1016 3
  if (RmIsTaskforce(task))
   return(RmApplyTaskforce((RmTaskforce) task, &UpdateMapping, network));

d1022 1
a1022 1
   { processor = (RmProcessor) RmFindUid((RmSet) network, task->MappedTo);
d1053 1
a1053 1
      return(RmE_BadFile);
d1055 1
a1055 1
      return(RmE_NotNetwork);
d1060 1
a1060 1
   return(RmE_NoMemory);
d1063 1
a1063 1
   { Free(Network); *NetworkPtr = NULL; return(RmE_BadFile); }
d1070 1
a1070 2

	/* BLV - safe to RmFree ??? */      
d1115 1
d1131 1
a1131 1
    return(RmE_NoMemory);
d1150 1
a1150 1
      return(RmE_BadFile);
d1153 1
a1153 1
      return(RmE_NoMemory);
d1156 1
a1156 1
      { Free(table); return(RmE_BadFile); }
d1161 1
a1161 1
      return(rc);
d1245 1
a1245 1
   Table[i] = (RmProcessor) RmFindUid((RmSet) Root, (int) Table[i]);
d1277 1
a1277 1
        return(rc);
d1283 1
a1283 1
   return(rc);
d1323 1
a1323 1
   return(RmE_BadFile);
d1327 1
a1327 1
      return(RmE_BadFile);
d1372 1
a1372 1
  if (table eq Null(int)) return(RmE_NoMemory);
d1386 3
a1388 1
  return(RmE_Success);
d1412 1
a1412 1
  if (Processor eq (RmProcessor) NULL) return(RmE_NoMemory);
d1429 13
d1477 1
d1502 1
a1502 1
       return(rc);
d1507 1
a1507 1
   return(RmE_BadFile);
d1511 1
a1511 1
   return(RmE_BadFile);
d1516 1
a1516 1
      return(RmE_BadFile);
d1522 1
a1522 1
    return(RmE_BadFile);          
d1527 1
a1527 1
    return(RmE_BadFile);          
d1535 1
a1535 1
BLV TaskforcePtr should be reset to NULL on failure
d1547 1
a1547 1
      return(RmE_BadFile);
d1549 1
a1549 1
      return(RmE_NotTaskforce);
d1553 1
a1553 1
  if (Taskforce eq (RmTaskforce) NULL) return(RmE_NoMemory);
d1557 1
a1557 1
   { Free(Taskforce); return(RmE_BadFile); }
d1569 1
a1569 1
      { Free(Taskforce); return(rc); }
d1602 1
a1602 1
  return(rc);
d1645 1
a1645 1
   return(rc);
d1663 1
a1663 1
   return(filter_result);
d1666 1
a1666 1
   return(RmE_BadFile);
d1670 1
a1670 1
      return(RmE_BadFile);
d1696 1
a1696 1
  if (Task eq (RmTask) NULL) return(RmE_NoMemory);
d1771 1
d1791 1
a1791 1
       return(rc);
d1796 1
a1796 1
   return(RmE_BadFile);
d1799 1
a1799 1
   return(RmE_BadFile);
d1803 1
a1803 1
      return(RmE_BadFile);
d1809 1
a1809 1
    return(RmE_BadFile);          
d1814 1
a1814 1
    return(RmE_BadFile);          
d1819 1
a1819 1
      return(RmE_BadFile);
d1824 1
a1824 1
      return(RmE_BadFile);
d1830 3
a1832 4
/**----------------------------------------------------------------------------
*** Actual request operations.
*** These operations require interacting with the networking software,
*** rather than just internal manipulation or sending things down pipes.
a1833 11
RmNetwork	RmGetNetwork(int *rc_ptr)
{ RmJob		Job;
  Stream	*Pipe;
  int		rc;
  RmNetwork	result		= (RmNetwork) NULL;
  bool		got_job		= FALSE;
  bool		job_locked	= FALSE;
      
  rc = RmNewJob(&RmNetworkServer, &Job);
  if (rc ne RmE_Success) goto done;
  got_job = TRUE;
d1835 6
a1840 23
  Pipe	= RmLockWrite(Job);

  rc	= RmC_GetNetwork;
  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
  Pipe = RmSwitchLockRead(Job);
  job_locked = TRUE;
  
  if (FullRead(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }

  if (rc ne RmE_Success) goto done;

  rc = RmReadStream(Pipe, &result, Null(RmTaskforce));

done:
  if (job_locked)
   RmUnlockRead(Job);  
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  if (rc_ptr ne Null(int)) *rc_ptr = rc;
  return(result);  
d1843 6
a1848 35
RmNetwork	RmGetNetworkAndHardware(int *rc_ptr)
{ RmJob		Job;
  Stream	*Pipe;
  int		rc;
  RmNetwork	result		= (RmNetwork) NULL;
  bool		got_job		= FALSE;
  bool		job_locked	= FALSE;
      
  rc = RmNewJob(&RmNetworkServer, &Job);
  if (rc ne RmE_Success) goto done;
  got_job = TRUE;

  Pipe	= RmLockWrite(Job);

  rc	= RmC_GetNetworkHardware;
  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
  Pipe = RmSwitchLockRead(Job);
  job_locked = TRUE;
  
  if (FullRead(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }

  if (rc ne RmE_Success) goto done;

  rc = RmReadStream(Pipe, &result, Null(RmTaskforce));
  
done:
  if (job_locked)
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  if (rc_ptr ne Null(int)) *rc_ptr = rc;
  return(result);  
d1851 6
a1856 35
RmNetwork	RmGetNetworkHierarchy(int *rc_ptr)
{ RmJob		Job;
  Stream	*Pipe;
  int		rc;
  RmNetwork	result		= (RmNetwork) NULL;
  bool		got_job		= FALSE;
  bool		job_locked	= FALSE;
      
  rc = RmNewJob(&RmNetworkServer, &Job);
  if (rc ne RmE_Success) goto done;
  got_job = TRUE;

  Pipe	= RmLockWrite(Job);

  rc	= RmC_GetHierarchy;
  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
  Pipe = RmSwitchLockRead(Job);
  job_locked = TRUE;
  
  if (FullRead(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }

  if (rc ne RmE_Success) goto done;

  rc = RmReadStream(Pipe, &result, Null(RmTaskforce));
  
done:
  if (job_locked)
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  if (rc_ptr ne Null(int)) *rc_ptr = rc;
  return(result);  
d1859 2
a1860 3
RmNetwork	RmGetDomain(int *rc_ptr)
{ RmJob		Job;
  Stream	*Pipe;
d1862 2
a1863 15
  RmNetwork	result		= (RmNetwork) NULL;
  bool		got_job		= FALSE;
  bool		job_locked	= FALSE;
    
  rc = RmNewJob(&RmParent, &Job);
  if (rc ne RmE_Success) goto done;
  got_job = TRUE;

  Pipe	= RmLockWrite(Job);

  rc	= RmC_GetNetwork;
  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
  Pipe = RmSwitchLockRead(Job);
  job_locked = TRUE;
d1865 2
a1866 6
  if (FullRead(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }

  if (rc ne RmE_Success) goto done;

  rc = RmReadStream(Pipe, &result, Null(RmTaskforce));
d1868 4
a1871 29
done:
  if (job_locked)
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  if (rc_ptr ne Null(int)) *rc_ptr = rc;
  return(result);  
}

/**-----------------------------------------------------------------------------
*** Get hold of some time stamps from the system
**/
int		RmLastChangeDomain(void)
{ RmJob		Job;
  int		rc;
  Stream	*Pipe;
  int		result = -1;
  bool		job_locked = FALSE;
  bool		got_job = FALSE;
      
  rc	= RmNewJob(&RmParent, &Job);
  if (rc ne RmE_Success) goto done;
  got_job = TRUE;
  Pipe	= RmLockWrite(Job);
  rc	= RmC_LastChange;

  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   goto done;
d1873 13
a1885 4
  Pipe	= RmSwitchLockRead(Job);
  job_locked = TRUE;
  if (FullRead(Pipe, (BYTE *) &result, sizeof(int), -1) ne sizeof(int))
   { result = -1; goto done; }
d1887 8
a1894 16
done:
  if (job_locked) 
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  return(result);       
}

int		RmLastChangeWholeNetwork(void)
{ RmJob		Job;
  int		rc;
  Stream	*Pipe;
  int		result = -1;
  bool		got_job = FALSE;
  bool		job_locked = FALSE;
d1896 1
a1896 22
  rc	= RmNewJob(&RmNetworkServer, &Job);
  if (rc ne RmE_Success) goto done;
  got_job = TRUE;
  
  Pipe	= RmLockWrite(Job);
  rc	= RmC_LastChange;

  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   goto done;
   
  Pipe	= RmSwitchLockRead(Job);
  job_locked = TRUE;
  if (FullRead(Pipe, (BYTE *) &result, sizeof(int), -1) ne sizeof(int))
   { result = -1; goto done; }

done:
  if (job_locked)
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  RmFinishedJob(Job);
  return(result);       
d1899 6
a1904 50
/**
*** Obtaining a processor. This involves sending a template to the
*** parent server, i.e. to the Taskforce Manager or the Network
*** server.
**/
RmProcessor	RmObtainProcessor(RmProcessor template, int *rc_ptr)
{ int		rc = RmE_Success;
  RmProcessor	result = (RmProcessor) NULL;
  RmJob		Job;
  Stream	*Pipe;
  bool		got_job = FALSE;
  bool		job_locked = FALSE;
  int		size;

  if (template eq (RmProcessor) NULL)
   { rc = RmE_NotProcessor; goto done; }
  if (template->ObjNode.Type ne Type_Processor)
   { rc = RmE_NotProcessor; goto done; }
  if ((template->StructType ne RmL_Existing) &&
      (template->StructType ne RmL_New))
   { rc = RmE_BadArgument; goto done; }

  rc = RmNewJob(&RmParent, &Job);
  if (rc ne RmE_Success) goto done;
  got_job = TRUE;
  
  Pipe 	= RmLockWrite(Job);
  
  rc	= RmC_ObtainProcessor;
  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
  rc	= RmWriteProcessor(Pipe, template, (RmFilter) NULL);
  if (rc ne RmE_Success) goto done;

  Pipe	= RmSwitchLockRead(Job);
  job_locked = TRUE;
  if (FullRead(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
  if (rc ne RmE_Success) goto done;
  rc = RmReadProcessor(Pipe, &result, FALSE);
  if (rc ne RmE_Success) goto done;

done:
  *rc_ptr = rc;
  if (job_locked)
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  return(result);
d1907 6
a1912 47
/**
*** releasing a processor. This involves sending a packet to the parent,
*** giving the processor uid and capability. Also, once the processor
*** has been released the structure type must change.
**/
int		RmReleaseProcessor(RmProcessor Processor)
{ int			rc;
  RmJob			Job;
  Stream		*Pipe;
  ProcessorDetails	details;
  bool			got_job = FALSE;
  bool			job_locked = FALSE;
    
  if (Processor eq (RmProcessor) NULL) return(RmE_NotProcessor);
  if (Processor->ObjNode.Type ne Type_Processor) return(RmE_NotProcessor);
  if (Processor->StructType ne RmL_Obtained) return(RmE_NoAccess);

  rc	= RmNewJob(&RmParent, &Job);
  if (rc ne RmE_Success) return(rc);
  got_job = TRUE;
  
  Pipe	= RmLockWrite(Job);
  rc	= RmC_ReleaseProcessor;
  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
  details.Uid	= Processor->Uid;
  details.Cap	= Processor->NsCap;
  if (Write(Pipe, (BYTE *) &details, sizeof(ProcessorDetails), -1) ne
  	sizeof(ProcessorDetails))
   { rc = RmE_CommsBreakdown; goto done; }

  Pipe	= RmSwitchLockRead(Job);
  job_locked = TRUE;
  
  if (FullRead(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   rc = RmE_CommsBreakdown;

  if (rc eq RmE_Success)
   Processor->StructType = RmL_Existing;
     
done:
  if (job_locked)
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  return(rc);
d1915 5
a1919 11
/**
*** Manipulating processor and network allocation strategies. These
*** only happen between clients and the Taskforce Manager
**/
static		int RmSetProcessorAllocation(int request, RmProcessor Processor)
{ RmJob			Job;
  int			rc;
  Stream		*Pipe;
  ProcessorDetails	details;
  bool			got_job = FALSE;
  bool			job_locked = FALSE;
d1921 2
a1922 3
  rc = RmNewJob(&RmParent, &Job);
  if (rc ne RmE_Success) return(rc);
  got_job = TRUE;
d1924 13
a1936 33
  Pipe = RmLockWrite(Job);
  rc = request;
  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
  details.Uid = Processor->Uid;
  details.Cap	= Processor->NsCap;
  if (Write(Pipe, (BYTE *) &details, sizeof(ProcessorDetails), -1) ne
  	sizeof(ProcessorDetails))
   { rc = RmE_CommsBreakdown; goto done; }

  Pipe = RmSwitchLockRead(Job);
  job_locked = TRUE;
  
  if (FullRead(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   rc = RmE_CommsBreakdown;
  
done:
  if (job_locked)
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  return(rc);     
}

int		RmSetProcessorShareable(RmProcessor Processor)
{ 
  if (Processor eq (RmProcessor) NULL) return(RmE_NotProcessor);
  if (Processor->ObjNode.Type ne Type_Processor) return(RmE_NotProcessor);
  if ((Processor->StructType eq RmL_New) || 
      (Processor->StructType eq RmL_Existing))
   { Processor->AllocationFlags &= ~RmF_Exclusive;
     return(RmE_Success);
d1938 3
a1940 2
  if (Processor->StructType ne RmL_Obtained)
   return(RmE_NoAccess);
d1942 7
a1948 11
  return(RmSetProcessorAllocation(RmC_ProcessorShareable, Processor));
}

int		RmSetProcessorExclusive(RmProcessor Processor)
{
  if (Processor eq (RmProcessor) NULL) return(RmE_NotProcessor);
  if (Processor->ObjNode.Type ne Type_Processor) return(RmE_NotProcessor);
  if ((Processor->StructType eq RmL_New) ||
      (Processor->StructType eq RmL_Existing))
   { Processor->AllocationFlags |= RmF_Exclusive;
     return(RmE_Success);
d1950 2
a1951 4
  if (Processor->StructType ne RmL_Obtained)
   return(RmE_NoAccess);

  return(RmSetProcessorAllocation(RmC_ProcessorExclusive, Processor));   
d1954 4
a1957 5
bool	RmIsProcessorShareable(RmProcessor Processor)
{ if (Processor eq (RmProcessor) NULL) return(FALSE);
  if (Processor->ObjNode.Type ne Type_Processor) return(FALSE);
  if (Processor->AllocationFlags & RmF_Exclusive)
   return(FALSE);
d1959 1
a1959 1
   return(TRUE);
d1962 4
a1965 5
bool	RmIsProcessorExclusive(RmProcessor Processor)
{ if (Processor eq (RmProcessor) NULL) return(FALSE);
  if (Processor->ObjNode.Type ne Type_Processor) return(FALSE);
  if (Processor->AllocationFlags & RmF_Exclusive)
   return(TRUE);
d1967 1
a1967 1
   return(FALSE);
d1970 4
a1973 33
int		RmSetProcessorTemporary(RmProcessor Processor)
{
  if (Processor eq (RmProcessor) NULL) return(RmE_NotProcessor);
  if (Processor->ObjNode.Type ne Type_Processor) return(RmE_NotProcessor);
  if ((Processor->StructType eq RmL_New) ||
      (Processor->StructType eq RmL_Existing))
   { Processor->AllocationFlags &= ~RmF_Permanent;
     return(RmE_Success);
   }
  if (Processor->StructType ne RmL_Obtained)
   return(RmE_NoAccess);
  return(RmSetProcessorAllocation(RmC_ProcessorTemporary, Processor));   
}

int		RmSetProcessorPermanent(RmProcessor Processor)
{
  if (Processor eq (RmProcessor) NULL) return(RmE_NotProcessor);
  if (Processor->ObjNode.Type ne Type_Processor) return(RmE_NotProcessor);
  if ((Processor->StructType eq RmL_New) ||
      (Processor->StructType eq RmL_Existing))
   { Processor->AllocationFlags |= RmF_Permanent;
     return(RmE_Success);
   }
  if (Processor->StructType ne RmL_Obtained)
   return(RmE_NoAccess);
  return(RmSetProcessorAllocation(RmC_ProcessorPermanent, Processor));   
}

bool		RmIsProcessorTemporary(RmProcessor Processor)
{ if (Processor eq (RmProcessor) NULL) return(FALSE);
  if (Processor->ObjNode.Type ne Type_Processor) return(FALSE);
  if (Processor->AllocationFlags & RmF_Permanent)
   return(FALSE);
d1975 1
a1975 1
   return(TRUE);
d1978 4
a1981 5
bool		RmIsProcessorPermanent(RmProcessor Processor)
{ if (Processor eq (RmProcessor) NULL) return(FALSE);
  if (Processor->ObjNode.Type ne Type_Processor) return(FALSE);
  if (Processor->AllocationFlags & RmF_Permanent)
   return(TRUE);
d1983 1
a1983 1
   return(FALSE);
a1985 10
static		int	RmSetNetworkAllocation(RmProcessor Processor, ...)
{ va_list	args;
  int		request;
  
  va_start(args, Processor);
  request = va_arg(args, int);
  va_end(args);
  
  if (RmIsNetwork(Processor))
   return(RmApplyNetwork((RmNetwork)Processor, &RmSetNetworkAllocation, request));
d1987 4
a1990 15
  if (Processor->StructType eq RmL_New)
   { switch(request)
      { case RmC_ProcessorShareable :
      		Processor->AllocationFlags &= ~RmF_Exclusive; break;
      	case RmC_ProcessorExclusive :
      		Processor->AllocationFlags |=  RmF_Exclusive; break;
      	case RmC_ProcessorPermanent :
      		Processor->AllocationFlags |=  RmF_Permanent; break;
      	case RmC_ProcessorTemporary :
      		Processor->AllocationFlags &= ~RmF_Permanent;
      }
     return(RmE_Success);
   }
  elif (Processor->StructType eq RmL_Obtained)
   return(RmSetProcessorAllocation(request, Processor));
d1992 1
a1992 1
   return(RmE_NoAccess);
d1995 6
a2000 5
int		RmSetNetworkShareable(RmNetwork Network)
{ if (Network eq (RmNetwork) NULL) return(RmE_NotNetwork);
  if (Network->DirNode.Type ne Type_Network) return(RmE_NotNetwork);
  return(RmApplyNetwork(Network, &RmSetNetworkAllocation, 
  		RmC_ProcessorShareable));
d2003 6
a2008 5
int		RmSetNetworkExclusive(RmNetwork Network)
{ if (Network eq (RmNetwork) NULL) return(RmE_NotNetwork);
  if (Network->DirNode.Type ne Type_Network) return(RmE_NotNetwork);
  return(RmApplyNetwork(Network, &RmSetNetworkAllocation, 
  		RmC_ProcessorExclusive));
a2010 6
int		RmSetNetworkTemporary(RmNetwork Network)
{ if (Network eq (RmNetwork) NULL) return(RmE_NotNetwork);
  if (Network->DirNode.Type ne Type_Network) return(RmE_NotNetwork);
  return(RmApplyNetwork(Network, &RmSetNetworkAllocation, 
  		RmC_ProcessorTemporary));
}
a2011 124
int		RmSetNetworkPermanent(RmNetwork Network)
{ if (Network eq (RmNetwork) NULL) return(RmE_NotNetwork);
  if (Network->DirNode.Type ne Type_Network) return(RmE_NotNetwork);
  return(RmApplyNetwork(Network, &RmSetNetworkAllocation, 
  		RmC_ProcessorPermanent));
}

/**----------------------------------------------------------------------------
*** Obtaining a network. This involves the following stages.
*** 1) check the network passed as argument. Every processor should be
***    either new or existing for now. Also, if the network is empty
***    forget it.
*** 2) start a new job. Send it the function code RmC_ObtainNetwork or
***    RmC_ObtainExactNetwork, together with the magic integer
***    RmStartSearchHere, and then the template network.
*** 3) wait around a long time for a reply. This reply may be 0 to indicate
***    complete success, RmE_PartialSuccess indicate partial success, 
***    or an error code. In the first two cases read in a network
*** 4) in the template, fill in the appropriate mapping info.
**/

static		int RmObtainAux1(RmProcessor Processor, ...);
static		int RmObtainAux2(RmProcessor Processor, ...);

RmNetwork	RmObtainNetwork(RmNetwork Network, bool exact, int *rc_ptr)
{ RmJob		Job;
  int		rc, rc2;
  RmNetwork	result = (RmNetwork) NULL;
  Stream	*Pipe;
  bool		got_job = FALSE;
  bool		job_locked = FALSE;

  if (Network eq (RmNetwork) NULL)
   { rc = RmE_NotNetwork; goto done; }
  if (Network->DirNode.Type ne Type_Network)
   { rc = RmE_NotNetwork; goto done; }
   
  rc = RmSearchNetwork(Network, &RmObtainAux1);
  if (rc ne RmE_Success) goto done;

  rc = RmNewJob(&RmParent, &Job);
  if (rc ne RmE_Success) goto done;
  got_job = TRUE;
  
  Pipe = RmLockWrite(Job);
  rc = (exact) ? RmC_ObtainExactNetwork : RmC_ObtainNetwork;
  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
  if (Write(Pipe, (BYTE *) &RmStartSearchHere, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
  rc = RmWriteStream(Pipe, Network, (RmTaskforce) NULL, (RmFilter) NULL);
  if (rc ne RmE_Success) goto done;

  Pipe = RmSwitchLockRead(Job);
  job_locked = TRUE;
  
  if (FullRead(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
  if ((rc ne RmE_Success) && (rc ne RmE_PartialSuccess)) goto done;
  
  rc2 = RmReadNetwork(Pipe, &result, FALSE);
  if (rc2 ne RmE_Success) { rc = rc2; goto done; }

  (void) RmApplyNetwork(result, &RmObtainAux2, Network);
done:
  if (job_locked)
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  *rc_ptr = rc;
  return(result);
}

static		int RmObtainAux1(RmProcessor Processor, ...)
{ 
  if (RmIsNetwork(Processor))
   return(RmSearchNetwork((RmNetwork) Processor, &RmObtainAux1));

  if ((Processor->StructType ne RmL_New) &&
      (Processor->StructType ne RmL_Existing))
   return(RmE_BadArgument);

  Processor->MappedTo = 0;  
  return(0);
}

static		int RmObtainAux2(RmProcessor Processor, ...)
{ va_list	args;
  RmNetwork	template;
  RmProcessor	match;
  
  va_start(args, Processor);
  template = va_arg(args, RmNetwork);
  va_end(args);
  if (RmIsNetwork(Processor))
   return(RmApplyNetwork((RmNetwork) Processor, &RmObtainAux2, template));

	/* it is possible to get a processor without asking */
  if (Processor->MappedTo eq 0) return(RmE_Success);

  match = (RmProcessor) RmFindUid((RmSet) template, Processor->MappedTo);
  if (match ne (RmProcessor) NULL)
   match->MappedTo = Processor->Uid;
  return(RmE_Success);
}


RmProcessor	RmFindMatchingProcessor(RmProcessor Processor,
					RmNetwork Network)
{ RmProcessor	result;

  if ((Processor eq (RmProcessor) NULL) ||
      (Network eq (RmNetwork) NULL))
   return((RmProcessor) NULL);
  if ((Processor->ObjNode.Type ne Type_Processor) ||
      (Network->DirNode.Type ne Type_Network))
   return((RmProcessor) NULL);

  if (Processor->MappedTo eq 0) return((RmProcessor) NULL);
  result = (RmProcessor) RmFindUid((RmSet) Network, Processor->MappedTo);
  return(result);   
}

d2013 1
a2013 2
*** Releasing a network. This involves sending the uid and capability for
*** every processor in the network.
d2015 32
a2046 218

static int	RmReleaseAux1(RmProcessor Processor, ...);

int		RmReleaseNetwork(RmNetwork Network) 
{ RmJob			Job;
  int			rc;
  Stream		*Pipe;
  ProcessorDetails	details;
  bool			got_job = FALSE;
  bool			job_locked = FALSE;
      
  if (Network eq (RmNetwork) NULL) return(RmE_NotNetwork);
  if (Network->DirNode.Type ne Type_Network) return(RmE_NotNetwork);

  rc	= RmNewJob(&RmParent, &Job);
  if (rc ne RmE_Success) return(rc);
  got_job = TRUE;
  Pipe	= RmLockWrite(Job);

  rc	= RmC_ReleaseNetwork;
  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
   
  rc = RmApplyNetwork(Network, &RmReleaseAux1, Pipe);
  if (rc ne RmE_Success) 
   { rc = RmE_WrongNetwork; goto done; }
   
  details.Uid	= -1;
  if (Write(Pipe, (BYTE *) &details, sizeof(ProcessorDetails), -1) ne 
  		sizeof(ProcessorDetails))
   { rc = RmE_CommsBreakdown; goto done; }
   
  Pipe = RmSwitchLockRead(Job);
  job_locked = TRUE;
  if (FullRead(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
    rc = RmE_CommsBreakdown;

done:
  if (job_locked)
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  return(rc);
}

static int RmReleaseAux1(RmProcessor Processor, ...)
{ va_list		args;
  Stream		*Pipe;
  ProcessorDetails	details;
  
  va_start(args, Processor);
  Pipe = va_arg(args, Stream *);
  va_end(args);
  
  if (RmIsNetwork(Processor))
   return(RmApplyNetwork((RmNetwork) Processor, &RmReleaseAux1, Pipe));

  if (Processor->StructType ne RmL_Obtained)
   return(RmE_NoAccess);
  details.Uid	= Processor->Uid;
  details.Cap	= Processor->NsCap;
  if (Write(Pipe, (BYTE *) &details, sizeof(ProcessorDetails), -1) ne
  	sizeof(ProcessorDetails))
   return(RmE_CommsBreakdown);

  Processor->StructType = RmL_Existing;
  return(RmE_Success);
}

/**
*** Manipulating link modes
**/
int		RmGetLinkMode(RmProcessor processor, int link, int *mode)
{ int		rc;
  Stream	*Pipe;
  LinkDetails	details;
  RmJob		Job;
  bool		got_job = FALSE;
  bool		job_locked = FALSE;
  
  if (processor eq (RmProcessor) NULL) return(RmE_NotProcessor);
  if (processor->ObjNode.Type ne Type_Processor) return(RmE_NotProcessor);
  if ((processor->StructType ne RmL_Existing) &&
      (processor->StructType ne RmL_Obtained))
   return(RmE_BadArgument);
  if ((link < 0) || (link > processor->Connections))
   return(RmE_BadArgument);
  if (mode eq Null(int))
   return(RmE_BadArgument);

  rc = RmNewJob(&RmNetworkServer, &Job);
  if (rc ne RmE_Success) return(rc);
  got_job = TRUE;
  Pipe = RmLockWrite(Job);
  
  rc = RmC_GetLinkMode;
  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }

  details.Uid		= processor->Uid;
  details.Link		= link;
  if (Write(Pipe, (BYTE *) &details, sizeof(LinkDetails), -1) ne
  	sizeof(LinkDetails))
   { rc = RmE_CommsBreakdown; goto done; }

  Pipe = RmSwitchLockRead(Job);
  job_locked = TRUE;
  if (FullRead(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   rc = RmE_CommsBreakdown;
  if (rc eq RmE_Success)
   if (FullRead(Pipe, (BYTE *) mode, sizeof(int), -1) ne sizeof(int))
    rc = RmE_CommsBreakdown;
    
done:
  if (job_locked)
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  return(rc);
}

int		RmSetLinkMode(RmProcessor processor, int link, int mode)
{ RmJob		Job = (RmJob) NULL;
  int		rc;
  Stream	*Pipe;
  LinkDetails	details;
  bool		got_job = FALSE;
  bool		job_locked = FALSE;
  
  if (processor eq (RmProcessor) NULL) return(RmE_NotProcessor);
  if (processor->ObjNode.Type ne Type_Processor) return(RmE_NotProcessor);
  if ((processor->StructType ne RmL_Existing) &&
      (processor->StructType ne RmL_Obtained))
   return(RmE_BadArgument);
  if ((link < 0) || (link > processor->Connections))
   return(RmE_BadArgument);
  if ((mode < RmL_NotConnected) || (mode > RmL_Dead))
   return(RmE_BadArgument);

  rc = RmNewJob(&RmNetworkServer, &Job);
  if (rc ne RmE_Success) return(rc);
  got_job = TRUE;
  Pipe = RmLockWrite(Job);
  
  rc = RmC_SetLinkMode;
  if (Write(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }

  details.Uid		= processor->Uid;
  details.Link		= link;
  details.Mode		= mode;
  if (Write(Pipe, (BYTE *) &details, sizeof(LinkDetails), -1) ne
  	sizeof(LinkDetails))
   { rc = RmE_CommsBreakdown; goto done; }

  Pipe = RmSwitchLockRead(Job);
  job_locked = TRUE;
  if (FullRead(Pipe, (BYTE *) &rc, sizeof(int), -1) ne sizeof(int))
   rc = RmE_CommsBreakdown;
   
done:
  if (job_locked)
   RmUnlockRead(Job);
  elif (got_job)
   RmUnlockWrite(Job);
  if (got_job) RmFinishedJob(Job);
  return(rc);
}

/**-----------------------------------------------------------------------------     
*** Coping with task mappings
**/
int RmMapTask(RmProcessor processor, RmTask task)
{
  if (processor eq (RmProcessor) NULL) return(RmE_NotProcessor);
  if (processor->ObjNode.Type ne Type_Processor) return(RmE_NotProcessor);
  if (task eq (RmTask) NULL) return(RmE_NotTask);
  if (task->ObjNode.Type ne Type_Task) return(RmE_NotTask);
  
  if (task->MappedTo ne RmL_NoUid) return(RmE_InUse);
  AddTail(&(processor->MappedTasks), &(task->MappedNode));
  task->MappedTo = processor->Uid;
  return(RmE_Success);
}

static	int	RmCheckMappedTask(RmProcessor processor, RmTask task)
{ Node	*current;
  Node	*real;
  
  if (processor eq (RmProcessor) NULL) return(RmE_NotProcessor);
  if (processor->ObjNode.Type ne Type_Processor) return(RmE_NotProcessor);
  if (task eq (RmTask) NULL) return(RmE_NotTask);
  if (task->ObjNode.Type ne Type_Task) return(RmE_NotTask);

  real = &(task->MappedNode);
  for (current = Head_(Node, processor->MappedTasks);
       !EndOfList_(current);
       current = Next_(Node, current))
   if (current eq real)
    return(RmE_Success);
    
  return(RmE_NotFound);       
}

bool		RmIsMappedTask(RmProcessor processor, RmTask task)
{ if (RmCheckMappedTask(processor, task) eq RmE_Success)
   return(TRUE);
  else
   return(FALSE);
}

int		RmUnmapTask(RmProcessor Processor, RmTask task)
{ int	x = RmCheckMappedTask(Processor, task);
  if (x eq RmE_Success)
   { Remove(&(task->MappedNode));
     task->MappedTo = RmL_NoUid;
a2047 1
  return(x);
a2048 104

RmProcessor	RmFollowTaskMapping(RmNetwork network, RmTask task)
{ RmProcessor	result;

  if ((network eq (RmNetwork) NULL) || (task eq (RmTask) NULL))
   return((RmProcessor) NULL);
  if ((network->DirNode.Type ne Type_Network) ||
      (task->ObjNode.Type ne Type_Task))
   return((RmProcessor) NULL);
  
  if (task->MappedTo eq RmL_NoUid) return((RmProcessor) NULL);
  
  result = (RmProcessor) RmFindUid((RmSet) network, task->MappedTo);
  if (result eq (RmProcessor) NULL) return((RmProcessor) NULL);

  if (RmCheckMappedTask(result, task) ne RmE_Success)
   return((RmProcessor) NULL);
  else
   return(result);     
}

int		RmApplyMappedTasks(RmProcessor Processor, int (*fn)(RmTask, ...), ...)
{ Node	*current, *next;
  RmTask	temp;
  va_list	args;
  int		arg1, arg2, arg3;
  int		result = 0; 

  if (Processor eq (RmProcessor) NULL) return(-1);
  if (Processor->ObjNode.Type ne Type_Processor) return(-1);

  va_start(args, fn);
  arg1 = va_arg(args, int);
  arg2 = va_arg(args, int);
  arg3 = va_arg(args, int);
  va_end(args);
  
  for (current = Head_(Node, Processor->MappedTasks);
       !EndOfList_(current);
       current = next )
   { next = Next_(Node, current);
     temp = (RmTask) (((BYTE *) current) - offsetof(RmTaskStruct, MappedNode));
     result += (*fn)(temp, arg1, arg2, arg3);
   }
  return(result);
}

int		RmSearchMappedTasks(RmProcessor Processor, int (*fn)(RmTask, ...), ...)
{ Node	*current, *next;
  RmTask	temp;
  va_list	args;
  int		arg1, arg2, arg3;
  int		result = 0; 

  if (Processor eq (RmProcessor) NULL) return(-1);
  if (Processor->ObjNode.Type ne Type_Processor) return(-1);

  va_start(args, fn);
  arg1 = va_arg(args, int);
  arg2 = va_arg(args, int);
  arg3 = va_arg(args, int);
  va_end(args);
  
  for (current = Head_(Node, Processor->MappedTasks);
       !EndOfList_(current);
       current = next )
   { next = Next_(Node, current);
     temp = (RmTask) (((BYTE *) current) - offsetof(RmTaskStruct, MappedNode));
     result = (*fn)(temp, arg1, arg2, arg3);
     if (result ne 0) return(result);
   }
  return(result);
}

int	RmCountMappedTasks(RmProcessor Processor)
{ int	result = 0;
  Node	*temp;
  
  if (Processor eq (RmProcessor) NULL) return(-1);
  if (Processor->ObjNode.Type ne Type_Processor) return(-1);
  
  for (temp = Head_(Node, Processor->MappedTasks);
       !EndOfList_(temp);
       temp = Next_(Node, temp))
   result++;
  return(result);
}

/**
*** Future expansion
**/
int		RmReconfigureNetwork(RmNetwork Network)
{
}

int		RmTestConfiguration(RmNetwork Network)
{
}

int		RmInstallNetwork(RmNetwork Network)
{
}


@


1.8
log
@Changed the definition of ObtainProcessor. The PUID is now already
a private attribute, and does not have to be sent separately.
@
text
@d19 1
a19 1
/* rcsid = "$Header: /giga/HeliosRoot/Helios/network/RCS/rmlib2.c,v 1.7 90/12/01 15:37:21 bart Exp $ */
d940 1
a940 1
   { Free(Network); return(RmE_BadFile); }
d947 2
a948 1
      
d959 1
a959 1
      { Free(Network); return(rc); }
d992 1
d1396 2
a1397 1
v**/
@


1.7
log
@the library must now send regular handshakes to the server, or the server
can abort the connection and reclaim resources.
@
text
@d19 1
a19 1
/* rcsid = "$Header: /usr/perihelion/Helios/network/RCS/rmlib2.c,v 1.2 90/09/20 17:43:02 bart Exp $ */
a1918 1
  char		*puid_buf;
a1946 2
  if (FullRead(Pipe, (BYTE *) &size, sizeof(int), -1) ne sizeof(int))
   { rc = RmE_CommsBreakdown; goto done; }
a1947 7
  puid_buf = Malloc(size + 6);
  strcpy(puid_buf, "PUID=");
  (void) FullRead(Pipe, (BYTE *) &(puid_buf[5]), size, -1);
  puid_buf[size+5] = '\0';
  RmAddObjectAttribute((RmObject) result, puid_buf, TRUE);
  Free(puid_buf);
  
@


1.6
log
@Added routines to map and unmap tasks onto processors. Also updated the
stream I/O routines to maintain these mappings.
@
text
@d636 1
a636 1
     result = FullRead(Pipe, (BYTE *) &ID, sizeof(WORD), 5 * 60 * OneSec);
@


1.5
log
@sources update after visit to Parsytec 22.10.90-31.10.90
@
text
@d32 1
d797 2
d842 1
d877 32
d1301 1
d1394 1
a1394 1
**/
d2501 142
a2642 1
     
@


1.4
log
@minor bug fixes in time for Helios 1.2 beta1 release
@
text
@d23 2
d43 1
d45 1
d57 1
a57 1
    if (temp < 0)
d143 1
a143 1
*** to implement routines such as RmGetWholeNetwork(); one to the Session
d166 1
a166 1
***	This routine releases the exclusive access.
d200 1
a200 1
*** Consider a vaguely typical piece of code: RmGetWholeNetwork(). This would
d204 1
a204 1
***	3) send the request code for RmGetWholeNetwork()
d235 5
a239 2
  NewJob->Id = (*Server)->MaxId++;
  NewJob->Server = *Server;
d254 8
d275 2
a276 1
		
d281 3
a283 2
   { IOdebug("RmLib : internal error 0x%E in RmLockWrite",
   		Result2(Server->Pipe));
d293 1
d298 4
d303 2
a304 2
/*  Wait(&(Job->Wait));*/		/* Triggered by RmPipeGuardian */
(void) FullRead(Server->Pipe, (BYTE *) &temp, sizeof(word), -1);
d306 1
d312 17
a328 4
  int temp;
  Signal(&(Server->WriteLock));
/*  Wait(&(Job->Wait));*/
  (void) FullRead(Server->Pipe, (BYTE *) &temp, sizeof(word), -1);
d334 2
d337 1
d374 1
d376 1
d395 1
d419 1
a420 1
  Close(ServObj);
d434 1
d452 1
a452 1
    PipeStream = NewStream(name, cap, mode);    
d456 1
a456 1
  Server->Pipe = PipeStream;
d466 8
a473 1
#if 0  
d478 1
a478 1
   
d481 1
d483 6
a488 2
   { if (Server ne (RmServer)NULL)
      { Free(Server); Server = (RmServer) NULL; }
d513 2
a514 1
{
d518 3
d522 2
d610 1
d625 1
d628 2
a629 1
{ Stream *Pipe	= Server->Pipe;
d631 1
a631 1
  
d633 3
a635 1
   { int result = FullRead(Pipe, (BYTE *) &ID, sizeof(WORD), 5 * 60 * OneSec);
d637 2
a638 1
      { if ((ID & RmR_Private) ne 0)
d641 2
d658 13
a670 4
     else
      { 
        if ((Result2(Pipe) & EG_Mask) ne EG_Timeout)
         { Close(Pipe);
d672 1
d678 5
a682 1
  Close(Pipe);        
d696 7
d712 1
d1655 1
a1655 1
RmNetwork	RmGetWholeNetwork(int *rc_ptr)
d1661 2
a1662 1
    
d1673 8
d1682 30
a1717 1
  RmUnlockRead(Job);
d1720 4
d1735 2
a1736 1
    
d1747 2
a1748 1

a1754 1
  RmUnlockRead(Job);
d1757 4
d1772 1
d1784 2
a1785 1

a1791 1
  RmUnlockRead(Job);
d1794 4
d1811 3
a1813 1
    
d1816 1
d1824 1
a1827 1
  RmFinishedJob(Job);
d1829 5
d1842 3
a1844 1
    
d1847 2
d1856 1
d1860 5
a1865 1
done:
d1880 1
d1883 1
a1883 1
      
d1897 1
d1905 1
a1905 1
  
d1923 4
d1941 3
a1943 1
  
d1950 2
d1963 2
d1970 1
a1970 1
   
d1972 5
a1976 1
  RmFinishedJob(Job);
d1989 3
a1991 1
    
d1994 2
d2000 1
a2000 1
  details.Uid	= Processor->Uid;
d2007 2
d2011 1
a2011 1

d2013 5
a2017 1
  RmFinishedJob(Job);
d2195 3
a2197 2
  bool		gotjob = FALSE;
        
d2205 1
a2205 1
  
d2208 1
a2208 1
  gotjob = TRUE;
d2218 3
a2221 1
  Pipe = RmSwitchLockRead(Job);
a2226 1
  RmUnlockRead(Job);
a2229 1
  
d2231 5
a2235 1
  if (gotjob) RmFinishedJob(Job);
d2302 3
a2304 1
    
d2310 1
d2327 1
d2330 1
a2330 1
    
d2332 5
a2336 1
  RmFinishedJob(Job);
d2362 101
@


1.3
log
@Plugged various memory leaks
@
text
@d484 15
a498 3
      if (RmParent ne (RmServer)NULL)
       { RmNetworkServer = RmParent; return(TRUE); }
     name = "/ns";
@


1.2
log
@RcsiID string clashed with string in rmlib1.c
@
text
@d19 1
a19 1
/* rcsid = "$Header: /usr/perihelion/Helios/network/RCS/rmlib2.c,v 1.1 90/09/12 14:54:08 jon Exp Locker: bart $ */
d483 5
a487 1
   name = "/ns";
d496 3
d807 2
a808 1
    
d1279 2
a1280 1
    
d1997 2
a1998 1
      
d2009 2
a2010 1

d2032 1
@


1.1
log
@Initial revision
@
text
@d19 1
a19 1
static char *rcsid = "$Header$";
@
